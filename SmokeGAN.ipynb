{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mewjFmLwP_rM",
        "outputId": "f1bbae9e-9285-4310-888e-cbf8e1518595"
      },
      "source": [
        "!git clone https://github.com/aiformankind/wildfire-smoke-dataset.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'wildfire-smoke-dataset'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 44 (delta 11), reused 10 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (44/44), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgZGdNqlQcvV"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "import torch.utils.data as data\n",
        "import torchvision.utils as vutils\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "import PIL.Image as Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHOJR4YDQwjw"
      },
      "source": [
        "!tar -xf drive/MyDrive/day_time_wildfire_v2.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6YFw7D3UH-1"
      },
      "source": [
        "transform = transforms.Compose([transforms.Resize((64, 64)), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "dset = dsets.ImageFolder(\"day_time_wildfire_v2\", transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuRiK1SAVOZW"
      },
      "source": [
        "BATCH_SIZE=32\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUJFVAMJU8JM"
      },
      "source": [
        "dataloader = data.DataLoader(dset, shuffle=True, batch_size=BATCH_SIZE)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poMCDiKw0rXd",
        "outputId": "e87ed9d2-36ea-4020-8d3b-ecd51e270b53"
      },
      "source": [
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay1vFsFsVx0j"
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sk0WZkhTWEN4"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "    self.network = nn.Sequential(nn.ConvTranspose2d(100, 512, 4, 1, 0, bias=False), \n",
        "                                 nn.BatchNorm2d(512),\n",
        "                                 nn.ReLU(True),\n",
        "                                 nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
        "                                 nn.BatchNorm2d(256),\n",
        "                                 nn.ReLU(True),\n",
        "                                 nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
        "                                 nn.BatchNorm2d(128),\n",
        "                                 nn.ReLU(True),\n",
        "                                 nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
        "                                 nn.BatchNorm2d(64),\n",
        "                                 nn.ReLU(True),\n",
        "                                 nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n",
        "                                 nn.Tanh()).to(device)\n",
        "  def forward(self, input):\n",
        "    output = self.network(input)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TPFUZIXXlqn"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.network = nn.Sequential(nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
        "                                 nn.LeakyReLU(0.2, True),\n",
        "                                 nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
        "                                 nn.BatchNorm2d(128),\n",
        "                                 nn.LeakyReLU(0.2, True),\n",
        "                                 nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
        "                                 nn.BatchNorm2d(256),\n",
        "                                 nn.LeakyReLU(0.2, True),\n",
        "                                 nn.Conv2d(256, 512, 4, 2, 1,bias=False),\n",
        "                                 nn.BatchNorm2d(512),\n",
        "                                 nn.LeakyReLU(0.2, True),\n",
        "                                 nn.Conv2d(512, 1, 4, 2, 0, bias=False),\n",
        "                                 nn.Sigmoid(),\n",
        "                                 ).to(device)\n",
        "  def forward(self, input):\n",
        "    output = self.network(input).to(device)\n",
        "    return output.view(-1) \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmBjdCA0rOQH"
      },
      "source": [
        "discriminator = Discriminator()\n",
        "generator = Generator()\n",
        "discriminator.apply(weights_init)\n",
        "generator.apply(weights_init)\n",
        "criterion = nn.BCELoss().to(device)\n",
        "optimizerDiscriminator = optim.Adam(discriminator.parameters(), lr=0.0001)\n",
        "optimizerGenerator = optim.Adam(generator.parameters(), lr=0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E83f66ZKr4Zh",
        "outputId": "13a2b7c1-d5d3-445a-ac19-92cd3c900ecb"
      },
      "source": [
        "lossGOverTime = []\n",
        "lossDOverTime = []\n",
        "for epoch in range(190, 300):\n",
        "  for (i, data) in enumerate(dataloader):\n",
        "    discriminator.zero_grad()\n",
        "    \n",
        "    real, _ = data\n",
        "    input = Variable(real).to(device)\n",
        "    target = Variable(torch.ones((real.shape[0]))).to(device)\n",
        "    output = discriminator(input)\n",
        "    lossDReal = criterion(output, target)\n",
        "\n",
        "    noise = Variable(torch.randn((real.shape[0], 100, 1, 1))).to(device)\n",
        "    fake = generator(noise)\n",
        "    target = torch.zeros((real.shape[0])).to(device)\n",
        "    output = discriminator(fake.detach())\n",
        "    lossDFake = criterion(output, target)\n",
        "\n",
        "    lossD = lossDReal + lossDFake\n",
        "    lossD.backward()\n",
        "    optimizerDiscriminator.step()\n",
        "\n",
        "    generator.zero_grad()\n",
        "\n",
        "    target = Variable(torch.ones((real.shape[0]))).to(device)\n",
        "    output = discriminator(fake)\n",
        "    lossG = criterion(output, target)\n",
        "    lossG.backward()\n",
        "    optimizerGenerator.step()\n",
        "\n",
        "    print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f' % (epoch, 25, i, len(dataloader), lossD.data, lossG.data)) \n",
        "    if i % 100 == 0: # Every 100 steps:\n",
        "      lossDOverTime.append(lossD.data)\n",
        "      lossGOverTime.append(lossG.data)\n",
        "      vutils.save_image(real, 'drive/MyDrive/SmokeGAN/real_samples.png', normalize = True) \n",
        "      fake = generator(noise) \n",
        "      vutils.save_image(fake.data, 'drive/MyDrive/SmokeGAN/128fake_samples_epoch_%03d.png' % (epoch), normalize = True)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "[227/25][37/69] Loss_D: 0.0015 Loss_G: 12.9477\n",
            "[227/25][38/69] Loss_D: 0.0194 Loss_G: 13.0114\n",
            "[227/25][39/69] Loss_D: 0.0025 Loss_G: 11.5157\n",
            "[227/25][40/69] Loss_D: 0.0003 Loss_G: 11.3723\n",
            "[227/25][41/69] Loss_D: 0.0056 Loss_G: 9.6483\n",
            "[227/25][42/69] Loss_D: 0.0012 Loss_G: 12.1004\n",
            "[227/25][43/69] Loss_D: 0.0069 Loss_G: 9.8288\n",
            "[227/25][44/69] Loss_D: 0.0064 Loss_G: 8.5735\n",
            "[227/25][45/69] Loss_D: 0.0004 Loss_G: 8.8966\n",
            "[227/25][46/69] Loss_D: 0.0004 Loss_G: 8.8309\n",
            "[227/25][47/69] Loss_D: 0.0104 Loss_G: 5.7643\n",
            "[227/25][48/69] Loss_D: 0.0034 Loss_G: 7.4587\n",
            "[227/25][49/69] Loss_D: 0.0048 Loss_G: 6.9359\n",
            "[227/25][50/69] Loss_D: 0.0117 Loss_G: 7.6163\n",
            "[227/25][51/69] Loss_D: 0.0018 Loss_G: 7.8228\n",
            "[227/25][52/69] Loss_D: 0.0024 Loss_G: 7.4566\n",
            "[227/25][53/69] Loss_D: 0.0081 Loss_G: 6.1763\n",
            "[227/25][54/69] Loss_D: 0.0026 Loss_G: 7.8984\n",
            "[227/25][55/69] Loss_D: 0.0001 Loss_G: 10.3400\n",
            "[227/25][56/69] Loss_D: 0.0003 Loss_G: 9.3055\n",
            "[227/25][57/69] Loss_D: 0.0013 Loss_G: 9.3089\n",
            "[227/25][58/69] Loss_D: 0.0074 Loss_G: 8.3337\n",
            "[227/25][59/69] Loss_D: 0.0011 Loss_G: 8.9931\n",
            "[227/25][60/69] Loss_D: 0.0005 Loss_G: 9.2112\n",
            "[227/25][61/69] Loss_D: 0.0007 Loss_G: 8.6246\n",
            "[227/25][62/69] Loss_D: 0.0002 Loss_G: 10.0825\n",
            "[227/25][63/69] Loss_D: 0.0006 Loss_G: 8.4816\n",
            "[227/25][64/69] Loss_D: 0.0015 Loss_G: 7.8221\n",
            "[227/25][65/69] Loss_D: 0.0035 Loss_G: 9.1922\n",
            "[227/25][66/69] Loss_D: 0.0003 Loss_G: 10.1189\n",
            "[227/25][67/69] Loss_D: 0.0001 Loss_G: 10.8022\n",
            "[227/25][68/69] Loss_D: 0.0012 Loss_G: 9.5496\n",
            "[228/25][0/69] Loss_D: 0.0063 Loss_G: 7.2818\n",
            "[228/25][1/69] Loss_D: 0.0061 Loss_G: 7.2077\n",
            "[228/25][2/69] Loss_D: 0.0020 Loss_G: 8.0080\n",
            "[228/25][3/69] Loss_D: 0.0046 Loss_G: 9.5920\n",
            "[228/25][4/69] Loss_D: 0.0021 Loss_G: 7.2420\n",
            "[228/25][5/69] Loss_D: 0.0017 Loss_G: 8.2481\n",
            "[228/25][6/69] Loss_D: 0.0020 Loss_G: 7.0512\n",
            "[228/25][7/69] Loss_D: 0.0041 Loss_G: 6.1898\n",
            "[228/25][8/69] Loss_D: 0.0154 Loss_G: 6.1898\n",
            "[228/25][9/69] Loss_D: 0.0025 Loss_G: 6.5641\n",
            "[228/25][10/69] Loss_D: 0.0092 Loss_G: 5.8246\n",
            "[228/25][11/69] Loss_D: 0.0048 Loss_G: 6.5539\n",
            "[228/25][12/69] Loss_D: 0.0050 Loss_G: 6.8284\n",
            "[228/25][13/69] Loss_D: 0.0007 Loss_G: 8.4425\n",
            "[228/25][14/69] Loss_D: 0.0415 Loss_G: 7.8599\n",
            "[228/25][15/69] Loss_D: 0.0002 Loss_G: 8.8584\n",
            "[228/25][16/69] Loss_D: 0.0017 Loss_G: 6.9194\n",
            "[228/25][17/69] Loss_D: 0.0020 Loss_G: 6.8220\n",
            "[228/25][18/69] Loss_D: 0.0050 Loss_G: 6.4015\n",
            "[228/25][19/69] Loss_D: 0.0048 Loss_G: 6.7920\n",
            "[228/25][20/69] Loss_D: 0.0026 Loss_G: 6.9069\n",
            "[228/25][21/69] Loss_D: 0.0039 Loss_G: 6.8219\n",
            "[228/25][22/69] Loss_D: 0.0018 Loss_G: 7.2559\n",
            "[228/25][23/69] Loss_D: 0.0008 Loss_G: 8.0716\n",
            "[228/25][24/69] Loss_D: 0.0009 Loss_G: 8.1068\n",
            "[228/25][25/69] Loss_D: 0.0006 Loss_G: 8.6654\n",
            "[228/25][26/69] Loss_D: 0.0005 Loss_G: 8.9431\n",
            "[228/25][27/69] Loss_D: 0.0009 Loss_G: 8.1161\n",
            "[228/25][28/69] Loss_D: 0.0003 Loss_G: 9.8055\n",
            "[228/25][29/69] Loss_D: 0.0003 Loss_G: 8.9478\n",
            "[228/25][30/69] Loss_D: 0.0004 Loss_G: 9.0211\n",
            "[228/25][31/69] Loss_D: 0.0775 Loss_G: 6.6763\n",
            "[228/25][32/69] Loss_D: 0.0008 Loss_G: 6.8465\n",
            "[228/25][33/69] Loss_D: 0.0064 Loss_G: 4.8309\n",
            "[228/25][34/69] Loss_D: 0.0140 Loss_G: 5.1210\n",
            "[228/25][35/69] Loss_D: 0.0820 Loss_G: 6.3453\n",
            "[228/25][36/69] Loss_D: 0.0054 Loss_G: 8.5171\n",
            "[228/25][37/69] Loss_D: 0.0006 Loss_G: 11.2561\n",
            "[228/25][38/69] Loss_D: 0.0002 Loss_G: 13.2987\n",
            "[228/25][39/69] Loss_D: 0.0006 Loss_G: 14.1691\n",
            "[228/25][40/69] Loss_D: 0.0001 Loss_G: 16.6650\n",
            "[228/25][41/69] Loss_D: 0.0035 Loss_G: 19.2702\n",
            "[228/25][42/69] Loss_D: 0.1213 Loss_G: 16.4527\n",
            "[228/25][43/69] Loss_D: 0.0006 Loss_G: 16.4537\n",
            "[228/25][44/69] Loss_D: 0.4771 Loss_G: 11.6469\n",
            "[228/25][45/69] Loss_D: 0.0062 Loss_G: 7.1456\n",
            "[228/25][46/69] Loss_D: 0.0171 Loss_G: 6.5287\n",
            "[228/25][47/69] Loss_D: 0.0484 Loss_G: 5.2527\n",
            "[228/25][48/69] Loss_D: 0.0215 Loss_G: 6.5794\n",
            "[228/25][49/69] Loss_D: 0.0158 Loss_G: 7.9020\n",
            "[228/25][50/69] Loss_D: 0.0157 Loss_G: 10.8590\n",
            "[228/25][51/69] Loss_D: 0.0138 Loss_G: 11.0362\n",
            "[228/25][52/69] Loss_D: 0.0023 Loss_G: 13.2724\n",
            "[228/25][53/69] Loss_D: 0.3172 Loss_G: 12.7806\n",
            "[228/25][54/69] Loss_D: 0.0004 Loss_G: 12.8024\n",
            "[228/25][55/69] Loss_D: 0.0008 Loss_G: 10.8910\n",
            "[228/25][56/69] Loss_D: 0.0028 Loss_G: 9.6789\n",
            "[228/25][57/69] Loss_D: 0.0059 Loss_G: 9.1981\n",
            "[228/25][58/69] Loss_D: 0.0015 Loss_G: 9.9483\n",
            "[228/25][59/69] Loss_D: 0.0011 Loss_G: 9.9726\n",
            "[228/25][60/69] Loss_D: 0.0020 Loss_G: 9.1288\n",
            "[228/25][61/69] Loss_D: 0.0019 Loss_G: 9.5343\n",
            "[228/25][62/69] Loss_D: 0.0025 Loss_G: 8.7977\n",
            "[228/25][63/69] Loss_D: 0.0017 Loss_G: 9.1762\n",
            "[228/25][64/69] Loss_D: 0.0048 Loss_G: 9.2665\n",
            "[228/25][65/69] Loss_D: 0.0378 Loss_G: 8.9583\n",
            "[228/25][66/69] Loss_D: 0.0162 Loss_G: 8.8759\n",
            "[228/25][67/69] Loss_D: 0.0017 Loss_G: 9.2035\n",
            "[228/25][68/69] Loss_D: 0.0205 Loss_G: 9.3772\n",
            "[229/25][0/69] Loss_D: 0.0047 Loss_G: 8.9610\n",
            "[229/25][1/69] Loss_D: 0.0045 Loss_G: 10.1185\n",
            "[229/25][2/69] Loss_D: 0.0108 Loss_G: 9.6505\n",
            "[229/25][3/69] Loss_D: 0.0089 Loss_G: 10.3043\n",
            "[229/25][4/69] Loss_D: 0.0002 Loss_G: 13.3008\n",
            "[229/25][5/69] Loss_D: 0.0008 Loss_G: 11.4297\n",
            "[229/25][6/69] Loss_D: 0.0002 Loss_G: 13.0527\n",
            "[229/25][7/69] Loss_D: 0.0002 Loss_G: 12.0118\n",
            "[229/25][8/69] Loss_D: 0.0000 Loss_G: 12.6100\n",
            "[229/25][9/69] Loss_D: 0.0001 Loss_G: 12.5925\n",
            "[229/25][10/69] Loss_D: 0.0003 Loss_G: 13.3224\n",
            "[229/25][11/69] Loss_D: 0.0000 Loss_G: 12.6006\n",
            "[229/25][12/69] Loss_D: 0.0001 Loss_G: 12.4667\n",
            "[229/25][13/69] Loss_D: 0.0001 Loss_G: 12.6409\n",
            "[229/25][14/69] Loss_D: 0.0005 Loss_G: 13.2229\n",
            "[229/25][15/69] Loss_D: 0.0000 Loss_G: 12.8145\n",
            "[229/25][16/69] Loss_D: 0.0015 Loss_G: 11.9482\n",
            "[229/25][17/69] Loss_D: 0.0001 Loss_G: 12.4404\n",
            "[229/25][18/69] Loss_D: 0.0057 Loss_G: 12.2989\n",
            "[229/25][19/69] Loss_D: 0.0000 Loss_G: 11.8185\n",
            "[229/25][20/69] Loss_D: 0.0002 Loss_G: 11.6033\n",
            "[229/25][21/69] Loss_D: 0.0004 Loss_G: 10.7910\n",
            "[229/25][22/69] Loss_D: 0.0016 Loss_G: 10.1901\n",
            "[229/25][23/69] Loss_D: 0.0007 Loss_G: 9.3417\n",
            "[229/25][24/69] Loss_D: 0.0015 Loss_G: 8.6046\n",
            "[229/25][25/69] Loss_D: 0.0019 Loss_G: 8.5659\n",
            "[229/25][26/69] Loss_D: 0.0003 Loss_G: 9.1081\n",
            "[229/25][27/69] Loss_D: 0.0050 Loss_G: 8.4525\n",
            "[229/25][28/69] Loss_D: 0.0010 Loss_G: 9.0552\n",
            "[229/25][29/69] Loss_D: 0.0005 Loss_G: 9.1234\n",
            "[229/25][30/69] Loss_D: 0.0006 Loss_G: 9.8351\n",
            "[229/25][31/69] Loss_D: 0.0019 Loss_G: 7.7404\n",
            "[229/25][32/69] Loss_D: 0.0069 Loss_G: 7.1725\n",
            "[229/25][33/69] Loss_D: 0.0023 Loss_G: 8.0161\n",
            "[229/25][34/69] Loss_D: 0.0007 Loss_G: 8.6055\n",
            "[229/25][35/69] Loss_D: 0.0006 Loss_G: 8.7742\n",
            "[229/25][36/69] Loss_D: 0.0007 Loss_G: 9.1937\n",
            "[229/25][37/69] Loss_D: 0.0005 Loss_G: 9.8839\n",
            "[229/25][38/69] Loss_D: 0.0012 Loss_G: 8.0760\n",
            "[229/25][39/69] Loss_D: 0.0079 Loss_G: 8.3040\n",
            "[229/25][40/69] Loss_D: 0.0012 Loss_G: 7.8963\n",
            "[229/25][41/69] Loss_D: 0.0008 Loss_G: 8.3207\n",
            "[229/25][42/69] Loss_D: 0.0011 Loss_G: 8.1005\n",
            "[229/25][43/69] Loss_D: 0.0046 Loss_G: 7.0830\n",
            "[229/25][44/69] Loss_D: 0.0308 Loss_G: 6.6754\n",
            "[229/25][45/69] Loss_D: 0.0032 Loss_G: 6.3083\n",
            "[229/25][46/69] Loss_D: 0.0052 Loss_G: 6.2843\n",
            "[229/25][47/69] Loss_D: 0.0232 Loss_G: 5.8603\n",
            "[229/25][48/69] Loss_D: 0.0035 Loss_G: 7.3339\n",
            "[229/25][49/69] Loss_D: 0.0010 Loss_G: 8.5181\n",
            "[229/25][50/69] Loss_D: 0.0010 Loss_G: 9.1229\n",
            "[229/25][51/69] Loss_D: 0.0066 Loss_G: 8.1583\n",
            "[229/25][52/69] Loss_D: 0.0018 Loss_G: 7.9458\n",
            "[229/25][53/69] Loss_D: 0.0009 Loss_G: 8.7349\n",
            "[229/25][54/69] Loss_D: 0.0007 Loss_G: 8.6184\n",
            "[229/25][55/69] Loss_D: 0.0004 Loss_G: 8.9956\n",
            "[229/25][56/69] Loss_D: 0.0007 Loss_G: 9.1527\n",
            "[229/25][57/69] Loss_D: 0.0015 Loss_G: 9.1771\n",
            "[229/25][58/69] Loss_D: 0.0014 Loss_G: 9.1846\n",
            "[229/25][59/69] Loss_D: 0.0003 Loss_G: 9.6780\n",
            "[229/25][60/69] Loss_D: 0.0010 Loss_G: 8.7248\n",
            "[229/25][61/69] Loss_D: 0.0008 Loss_G: 8.2554\n",
            "[229/25][62/69] Loss_D: 0.0008 Loss_G: 8.5505\n",
            "[229/25][63/69] Loss_D: 0.0022 Loss_G: 7.4945\n",
            "[229/25][64/69] Loss_D: 0.0009 Loss_G: 8.3331\n",
            "[229/25][65/69] Loss_D: 0.0033 Loss_G: 7.7242\n",
            "[229/25][66/69] Loss_D: 0.0011 Loss_G: 8.4010\n",
            "[229/25][67/69] Loss_D: 0.0019 Loss_G: 7.4257\n",
            "[229/25][68/69] Loss_D: 0.0028 Loss_G: 7.0234\n",
            "[230/25][0/69] Loss_D: 0.0129 Loss_G: 8.5364\n",
            "[230/25][1/69] Loss_D: 0.0042 Loss_G: 6.5186\n",
            "[230/25][2/69] Loss_D: 0.0059 Loss_G: 6.4836\n",
            "[230/25][3/69] Loss_D: 0.0031 Loss_G: 7.4619\n",
            "[230/25][4/69] Loss_D: 0.0040 Loss_G: 7.2805\n",
            "[230/25][5/69] Loss_D: 0.0011 Loss_G: 8.9786\n",
            "[230/25][6/69] Loss_D: 0.0042 Loss_G: 7.0615\n",
            "[230/25][7/69] Loss_D: 0.0027 Loss_G: 8.1680\n",
            "[230/25][8/69] Loss_D: 0.0050 Loss_G: 7.6617\n",
            "[230/25][9/69] Loss_D: 0.0241 Loss_G: 7.9743\n",
            "[230/25][10/69] Loss_D: 0.0005 Loss_G: 9.8322\n",
            "[230/25][11/69] Loss_D: 0.0002 Loss_G: 10.5955\n",
            "[230/25][12/69] Loss_D: 0.0020 Loss_G: 10.4610\n",
            "[230/25][13/69] Loss_D: 0.0014 Loss_G: 7.8415\n",
            "[230/25][14/69] Loss_D: 0.0015 Loss_G: 7.6555\n",
            "[230/25][15/69] Loss_D: 0.0020 Loss_G: 7.6207\n",
            "[230/25][16/69] Loss_D: 0.0064 Loss_G: 8.9072\n",
            "[230/25][17/69] Loss_D: 0.0003 Loss_G: 9.1054\n",
            "[230/25][18/69] Loss_D: 0.0079 Loss_G: 7.8818\n",
            "[230/25][19/69] Loss_D: 0.0026 Loss_G: 7.3069\n",
            "[230/25][20/69] Loss_D: 0.0038 Loss_G: 7.1731\n",
            "[230/25][21/69] Loss_D: 0.0028 Loss_G: 7.5259\n",
            "[230/25][22/69] Loss_D: 0.0031 Loss_G: 7.5216\n",
            "[230/25][23/69] Loss_D: 0.0015 Loss_G: 8.3779\n",
            "[230/25][24/69] Loss_D: 0.0030 Loss_G: 7.7314\n",
            "[230/25][25/69] Loss_D: 0.0041 Loss_G: 7.4609\n",
            "[230/25][26/69] Loss_D: 0.0007 Loss_G: 9.8794\n",
            "[230/25][27/69] Loss_D: 0.0014 Loss_G: 8.4321\n",
            "[230/25][28/69] Loss_D: 0.0079 Loss_G: 8.2628\n",
            "[230/25][29/69] Loss_D: 0.0003 Loss_G: 10.0265\n",
            "[230/25][30/69] Loss_D: 0.0004 Loss_G: 9.6553\n",
            "[230/25][31/69] Loss_D: 0.0002 Loss_G: 9.7407\n",
            "[230/25][32/69] Loss_D: 0.0021 Loss_G: 8.2640\n",
            "[230/25][33/69] Loss_D: 0.0009 Loss_G: 9.2504\n",
            "[230/25][34/69] Loss_D: 0.0021 Loss_G: 9.0926\n",
            "[230/25][35/69] Loss_D: 0.0003 Loss_G: 9.3206\n",
            "[230/25][36/69] Loss_D: 0.0025 Loss_G: 8.2259\n",
            "[230/25][37/69] Loss_D: 0.0008 Loss_G: 9.4665\n",
            "[230/25][38/69] Loss_D: 0.0008 Loss_G: 8.8335\n",
            "[230/25][39/69] Loss_D: 0.0021 Loss_G: 8.7135\n",
            "[230/25][40/69] Loss_D: 0.0007 Loss_G: 9.8624\n",
            "[230/25][41/69] Loss_D: 0.0043 Loss_G: 7.3665\n",
            "[230/25][42/69] Loss_D: 0.0013 Loss_G: 8.4701\n",
            "[230/25][43/69] Loss_D: 0.0008 Loss_G: 8.6869\n",
            "[230/25][44/69] Loss_D: 0.0016 Loss_G: 7.9185\n",
            "[230/25][45/69] Loss_D: 0.0009 Loss_G: 8.6623\n",
            "[230/25][46/69] Loss_D: 0.0066 Loss_G: 7.8931\n",
            "[230/25][47/69] Loss_D: 0.0026 Loss_G: 8.0416\n",
            "[230/25][48/69] Loss_D: 0.0059 Loss_G: 7.8710\n",
            "[230/25][49/69] Loss_D: 0.0004 Loss_G: 8.7803\n",
            "[230/25][50/69] Loss_D: 0.0006 Loss_G: 8.5262\n",
            "[230/25][51/69] Loss_D: 0.0008 Loss_G: 8.5144\n",
            "[230/25][52/69] Loss_D: 0.0013 Loss_G: 8.0987\n",
            "[230/25][53/69] Loss_D: 0.0034 Loss_G: 7.5268\n",
            "[230/25][54/69] Loss_D: 0.0022 Loss_G: 8.2249\n",
            "[230/25][55/69] Loss_D: 0.0014 Loss_G: 8.1460\n",
            "[230/25][56/69] Loss_D: 0.0027 Loss_G: 7.6300\n",
            "[230/25][57/69] Loss_D: 0.0014 Loss_G: 8.1762\n",
            "[230/25][58/69] Loss_D: 0.0014 Loss_G: 8.4740\n",
            "[230/25][59/69] Loss_D: 0.0009 Loss_G: 8.8502\n",
            "[230/25][60/69] Loss_D: 0.0012 Loss_G: 9.6111\n",
            "[230/25][61/69] Loss_D: 0.0005 Loss_G: 9.4398\n",
            "[230/25][62/69] Loss_D: 0.0003 Loss_G: 9.4127\n",
            "[230/25][63/69] Loss_D: 0.0010 Loss_G: 8.0830\n",
            "[230/25][64/69] Loss_D: 0.0007 Loss_G: 8.6004\n",
            "[230/25][65/69] Loss_D: 0.0216 Loss_G: 8.1009\n",
            "[230/25][66/69] Loss_D: 0.0035 Loss_G: 6.9927\n",
            "[230/25][67/69] Loss_D: 0.0011 Loss_G: 7.9957\n",
            "[230/25][68/69] Loss_D: 0.0019 Loss_G: 7.1870\n",
            "[231/25][0/69] Loss_D: 0.0029 Loss_G: 7.3171\n",
            "[231/25][1/69] Loss_D: 0.0037 Loss_G: 7.0212\n",
            "[231/25][2/69] Loss_D: 0.0031 Loss_G: 7.1496\n",
            "[231/25][3/69] Loss_D: 0.0022 Loss_G: 9.1886\n",
            "[231/25][4/69] Loss_D: 0.0025 Loss_G: 7.5883\n",
            "[231/25][5/69] Loss_D: 0.0044 Loss_G: 7.0848\n",
            "[231/25][6/69] Loss_D: 0.0022 Loss_G: 7.5612\n",
            "[231/25][7/69] Loss_D: 0.0018 Loss_G: 8.0683\n",
            "[231/25][8/69] Loss_D: 0.0043 Loss_G: 9.3837\n",
            "[231/25][9/69] Loss_D: 0.0006 Loss_G: 8.7082\n",
            "[231/25][10/69] Loss_D: 0.0011 Loss_G: 8.3169\n",
            "[231/25][11/69] Loss_D: 0.0028 Loss_G: 8.2857\n",
            "[231/25][12/69] Loss_D: 0.0013 Loss_G: 8.3797\n",
            "[231/25][13/69] Loss_D: 0.0020 Loss_G: 8.3895\n",
            "[231/25][14/69] Loss_D: 0.0009 Loss_G: 8.5384\n",
            "[231/25][15/69] Loss_D: 0.0009 Loss_G: 8.8567\n",
            "[231/25][16/69] Loss_D: 0.0008 Loss_G: 8.4142\n",
            "[231/25][17/69] Loss_D: 0.0388 Loss_G: 8.5488\n",
            "[231/25][18/69] Loss_D: 0.0072 Loss_G: 7.1640\n",
            "[231/25][19/69] Loss_D: 0.0024 Loss_G: 6.6548\n",
            "[231/25][20/69] Loss_D: 0.0036 Loss_G: 6.4165\n",
            "[231/25][21/69] Loss_D: 0.0121 Loss_G: 5.6244\n",
            "[231/25][22/69] Loss_D: 0.0072 Loss_G: 6.5061\n",
            "[231/25][23/69] Loss_D: 0.0191 Loss_G: 6.7841\n",
            "[231/25][24/69] Loss_D: 0.0077 Loss_G: 6.1339\n",
            "[231/25][25/69] Loss_D: 0.0039 Loss_G: 6.8633\n",
            "[231/25][26/69] Loss_D: 0.0028 Loss_G: 7.3097\n",
            "[231/25][27/69] Loss_D: 0.0023 Loss_G: 7.4253\n",
            "[231/25][28/69] Loss_D: 0.0018 Loss_G: 8.1186\n",
            "[231/25][29/69] Loss_D: 0.0008 Loss_G: 8.3689\n",
            "[231/25][30/69] Loss_D: 0.0008 Loss_G: 8.4696\n",
            "[231/25][31/69] Loss_D: 0.0007 Loss_G: 8.6210\n",
            "[231/25][32/69] Loss_D: 0.0003 Loss_G: 9.6028\n",
            "[231/25][33/69] Loss_D: 0.0006 Loss_G: 8.7603\n",
            "[231/25][34/69] Loss_D: 0.0004 Loss_G: 9.0070\n",
            "[231/25][35/69] Loss_D: 0.0002 Loss_G: 9.5986\n",
            "[231/25][36/69] Loss_D: 0.0001 Loss_G: 10.0706\n",
            "[231/25][37/69] Loss_D: 0.0001 Loss_G: 10.8197\n",
            "[231/25][38/69] Loss_D: 0.0003 Loss_G: 9.4195\n",
            "[231/25][39/69] Loss_D: 0.0001 Loss_G: 9.9311\n",
            "[231/25][40/69] Loss_D: 0.0001 Loss_G: 10.7318\n",
            "[231/25][41/69] Loss_D: 0.0003 Loss_G: 9.3957\n",
            "[231/25][42/69] Loss_D: 0.0001 Loss_G: 10.0491\n",
            "[231/25][43/69] Loss_D: 0.0001 Loss_G: 10.3579\n",
            "[231/25][44/69] Loss_D: 0.0003 Loss_G: 10.9432\n",
            "[231/25][45/69] Loss_D: 0.0003 Loss_G: 9.6730\n",
            "[231/25][46/69] Loss_D: 0.0003 Loss_G: 9.3715\n",
            "[231/25][47/69] Loss_D: 0.0002 Loss_G: 9.5361\n",
            "[231/25][48/69] Loss_D: 0.0001 Loss_G: 9.9020\n",
            "[231/25][49/69] Loss_D: 0.0002 Loss_G: 9.4709\n",
            "[231/25][50/69] Loss_D: 0.0002 Loss_G: 9.3033\n",
            "[231/25][51/69] Loss_D: 0.0002 Loss_G: 9.3337\n",
            "[231/25][52/69] Loss_D: 0.0005 Loss_G: 9.9029\n",
            "[231/25][53/69] Loss_D: 0.0005 Loss_G: 8.4047\n",
            "[231/25][54/69] Loss_D: 0.0010 Loss_G: 9.0923\n",
            "[231/25][55/69] Loss_D: 0.0007 Loss_G: 8.8525\n",
            "[231/25][56/69] Loss_D: 0.0002 Loss_G: 9.8026\n",
            "[231/25][57/69] Loss_D: 0.0068 Loss_G: 7.9162\n",
            "[231/25][58/69] Loss_D: 0.0003 Loss_G: 9.0293\n",
            "[231/25][59/69] Loss_D: 0.0011 Loss_G: 7.9079\n",
            "[231/25][60/69] Loss_D: 0.0006 Loss_G: 8.2444\n",
            "[231/25][61/69] Loss_D: 0.0032 Loss_G: 7.0559\n",
            "[231/25][62/69] Loss_D: 0.0020 Loss_G: 7.4004\n",
            "[231/25][63/69] Loss_D: 0.0004 Loss_G: 8.7246\n",
            "[231/25][64/69] Loss_D: 0.0010 Loss_G: 7.7507\n",
            "[231/25][65/69] Loss_D: 0.0024 Loss_G: 7.0764\n",
            "[231/25][66/69] Loss_D: 0.0008 Loss_G: 8.3015\n",
            "[231/25][67/69] Loss_D: 0.0011 Loss_G: 7.7405\n",
            "[231/25][68/69] Loss_D: 0.0012 Loss_G: 7.8523\n",
            "[232/25][0/69] Loss_D: 0.0005 Loss_G: 8.5474\n",
            "[232/25][1/69] Loss_D: 0.0022 Loss_G: 8.4388\n",
            "[232/25][2/69] Loss_D: 0.0011 Loss_G: 8.2125\n",
            "[232/25][3/69] Loss_D: 0.0017 Loss_G: 8.5971\n",
            "[232/25][4/69] Loss_D: 0.0028 Loss_G: 8.3263\n",
            "[232/25][5/69] Loss_D: 0.0008 Loss_G: 7.9326\n",
            "[232/25][6/69] Loss_D: 0.0005 Loss_G: 9.2398\n",
            "[232/25][7/69] Loss_D: 0.0019 Loss_G: 7.5491\n",
            "[232/25][8/69] Loss_D: 0.0274 Loss_G: 7.1468\n",
            "[232/25][9/69] Loss_D: 0.0008 Loss_G: 7.3407\n",
            "[232/25][10/69] Loss_D: 0.0119 Loss_G: 6.1164\n",
            "[232/25][11/69] Loss_D: 0.0048 Loss_G: 6.8809\n",
            "[232/25][12/69] Loss_D: 0.0058 Loss_G: 6.9618\n",
            "[232/25][13/69] Loss_D: 0.0042 Loss_G: 6.9019\n",
            "[232/25][14/69] Loss_D: 0.0020 Loss_G: 8.5636\n",
            "[232/25][15/69] Loss_D: 0.0002 Loss_G: 9.6687\n",
            "[232/25][16/69] Loss_D: 0.0004 Loss_G: 9.1060\n",
            "[232/25][17/69] Loss_D: 0.0013 Loss_G: 8.4801\n",
            "[232/25][18/69] Loss_D: 0.0015 Loss_G: 8.9588\n",
            "[232/25][19/69] Loss_D: 0.0009 Loss_G: 8.4552\n",
            "[232/25][20/69] Loss_D: 0.0036 Loss_G: 10.1146\n",
            "[232/25][21/69] Loss_D: 0.0004 Loss_G: 9.4891\n",
            "[232/25][22/69] Loss_D: 0.0434 Loss_G: 8.9645\n",
            "[232/25][23/69] Loss_D: 0.0014 Loss_G: 7.2620\n",
            "[232/25][24/69] Loss_D: 0.0016 Loss_G: 7.2776\n",
            "[232/25][25/69] Loss_D: 0.0036 Loss_G: 6.6594\n",
            "[232/25][26/69] Loss_D: 0.0023 Loss_G: 7.8897\n",
            "[232/25][27/69] Loss_D: 0.0105 Loss_G: 6.1295\n",
            "[232/25][28/69] Loss_D: 0.0074 Loss_G: 6.2399\n",
            "[232/25][29/69] Loss_D: 0.0035 Loss_G: 7.3702\n",
            "[232/25][30/69] Loss_D: 0.0040 Loss_G: 7.0763\n",
            "[232/25][31/69] Loss_D: 0.0030 Loss_G: 7.7187\n",
            "[232/25][32/69] Loss_D: 0.0003 Loss_G: 9.3378\n",
            "[232/25][33/69] Loss_D: 0.0015 Loss_G: 7.9863\n",
            "[232/25][34/69] Loss_D: 0.0005 Loss_G: 8.9783\n",
            "[232/25][35/69] Loss_D: 0.0002 Loss_G: 9.6430\n",
            "[232/25][36/69] Loss_D: 0.0002 Loss_G: 9.7835\n",
            "[232/25][37/69] Loss_D: 0.0005 Loss_G: 9.8051\n",
            "[232/25][38/69] Loss_D: 0.0003 Loss_G: 9.6700\n",
            "[232/25][39/69] Loss_D: 0.0001 Loss_G: 11.8738\n",
            "[232/25][40/69] Loss_D: 0.0025 Loss_G: 11.5394\n",
            "[232/25][41/69] Loss_D: 0.0002 Loss_G: 10.9165\n",
            "[232/25][42/69] Loss_D: 0.0001 Loss_G: 10.3866\n",
            "[232/25][43/69] Loss_D: 0.0013 Loss_G: 11.3537\n",
            "[232/25][44/69] Loss_D: 0.0092 Loss_G: 9.5897\n",
            "[232/25][45/69] Loss_D: 0.0079 Loss_G: 9.7969\n",
            "[232/25][46/69] Loss_D: 0.0002 Loss_G: 9.9342\n",
            "[232/25][47/69] Loss_D: 0.0001 Loss_G: 10.3557\n",
            "[232/25][48/69] Loss_D: 0.0001 Loss_G: 9.8532\n",
            "[232/25][49/69] Loss_D: 0.0003 Loss_G: 8.9011\n",
            "[232/25][50/69] Loss_D: 0.0006 Loss_G: 8.1045\n",
            "[232/25][51/69] Loss_D: 0.0007 Loss_G: 8.0337\n",
            "[232/25][52/69] Loss_D: 0.0004 Loss_G: 8.7609\n",
            "[232/25][53/69] Loss_D: 0.0021 Loss_G: 7.0437\n",
            "[232/25][54/69] Loss_D: 0.0007 Loss_G: 8.2225\n",
            "[232/25][55/69] Loss_D: 0.0009 Loss_G: 7.8265\n",
            "[232/25][56/69] Loss_D: 0.0010 Loss_G: 7.7255\n",
            "[232/25][57/69] Loss_D: 0.0005 Loss_G: 8.1759\n",
            "[232/25][58/69] Loss_D: 0.0024 Loss_G: 7.2162\n",
            "[232/25][59/69] Loss_D: 0.0036 Loss_G: 6.7469\n",
            "[232/25][60/69] Loss_D: 0.0009 Loss_G: 8.1255\n",
            "[232/25][61/69] Loss_D: 0.0006 Loss_G: 8.3664\n",
            "[232/25][62/69] Loss_D: 0.0010 Loss_G: 8.4833\n",
            "[232/25][63/69] Loss_D: 0.0063 Loss_G: 7.5999\n",
            "[232/25][64/69] Loss_D: 0.0012 Loss_G: 8.1290\n",
            "[232/25][65/69] Loss_D: 0.0005 Loss_G: 8.3189\n",
            "[232/25][66/69] Loss_D: 0.0028 Loss_G: 6.6328\n",
            "[232/25][67/69] Loss_D: 0.0014 Loss_G: 7.6186\n",
            "[232/25][68/69] Loss_D: 0.0007 Loss_G: 8.7145\n",
            "[233/25][0/69] Loss_D: 0.0003 Loss_G: 9.0144\n",
            "[233/25][1/69] Loss_D: 0.0006 Loss_G: 8.5046\n",
            "[233/25][2/69] Loss_D: 0.0011 Loss_G: 7.6550\n",
            "[233/25][3/69] Loss_D: 0.0009 Loss_G: 8.0562\n",
            "[233/25][4/69] Loss_D: 0.0009 Loss_G: 8.3377\n",
            "[233/25][5/69] Loss_D: 0.0004 Loss_G: 9.5309\n",
            "[233/25][6/69] Loss_D: 0.0016 Loss_G: 7.4225\n",
            "[233/25][7/69] Loss_D: 0.0005 Loss_G: 8.8610\n",
            "[233/25][8/69] Loss_D: 0.0016 Loss_G: 8.3082\n",
            "[233/25][9/69] Loss_D: 0.0002 Loss_G: 9.3210\n",
            "[233/25][10/69] Loss_D: 0.0002 Loss_G: 9.1539\n",
            "[233/25][11/69] Loss_D: 0.0005 Loss_G: 8.5244\n",
            "[233/25][12/69] Loss_D: 0.0005 Loss_G: 8.4330\n",
            "[233/25][13/69] Loss_D: 0.0009 Loss_G: 8.1997\n",
            "[233/25][14/69] Loss_D: 0.0004 Loss_G: 8.8166\n",
            "[233/25][15/69] Loss_D: 0.0008 Loss_G: 8.0110\n",
            "[233/25][16/69] Loss_D: 0.0013 Loss_G: 8.6326\n",
            "[233/25][17/69] Loss_D: 0.0010 Loss_G: 8.9574\n",
            "[233/25][18/69] Loss_D: 0.0011 Loss_G: 7.6509\n",
            "[233/25][19/69] Loss_D: 0.0033 Loss_G: 7.6724\n",
            "[233/25][20/69] Loss_D: 0.0325 Loss_G: 7.0132\n",
            "[233/25][21/69] Loss_D: 0.0015 Loss_G: 6.9248\n",
            "[233/25][22/69] Loss_D: 0.0051 Loss_G: 6.4176\n",
            "[233/25][23/69] Loss_D: 0.0068 Loss_G: 6.6587\n",
            "[233/25][24/69] Loss_D: 0.0253 Loss_G: 6.5734\n",
            "[233/25][25/69] Loss_D: 0.0034 Loss_G: 7.8691\n",
            "[233/25][26/69] Loss_D: 0.0034 Loss_G: 8.5118\n",
            "[233/25][27/69] Loss_D: 0.0052 Loss_G: 7.5230\n",
            "[233/25][28/69] Loss_D: 0.0006 Loss_G: 10.5380\n",
            "[233/25][29/69] Loss_D: 0.0006 Loss_G: 9.8701\n",
            "[233/25][30/69] Loss_D: 0.0069 Loss_G: 12.1085\n",
            "[233/25][31/69] Loss_D: 0.0020 Loss_G: 10.0944\n",
            "[233/25][32/69] Loss_D: 0.0010 Loss_G: 12.2615\n",
            "[233/25][33/69] Loss_D: 0.0041 Loss_G: 12.9869\n",
            "[233/25][34/69] Loss_D: 0.0003 Loss_G: 11.1223\n",
            "[233/25][35/69] Loss_D: 0.0582 Loss_G: 10.7476\n",
            "[233/25][36/69] Loss_D: 0.0005 Loss_G: 9.1604\n",
            "[233/25][37/69] Loss_D: 0.0021 Loss_G: 7.2282\n",
            "[233/25][38/69] Loss_D: 0.0053 Loss_G: 5.9374\n",
            "[233/25][39/69] Loss_D: 0.0053 Loss_G: 6.6400\n",
            "[233/25][40/69] Loss_D: 0.0398 Loss_G: 5.8117\n",
            "[233/25][41/69] Loss_D: 0.0036 Loss_G: 7.6512\n",
            "[233/25][42/69] Loss_D: 0.0006 Loss_G: 10.2070\n",
            "[233/25][43/69] Loss_D: 0.0011 Loss_G: 10.3190\n",
            "[233/25][44/69] Loss_D: 0.0094 Loss_G: 9.8051\n",
            "[233/25][45/69] Loss_D: 0.0021 Loss_G: 11.7761\n",
            "[233/25][46/69] Loss_D: 0.0747 Loss_G: 11.1680\n",
            "[233/25][47/69] Loss_D: 0.0008 Loss_G: 10.5034\n",
            "[233/25][48/69] Loss_D: 0.0003 Loss_G: 11.0430\n",
            "[233/25][49/69] Loss_D: 0.0006 Loss_G: 10.0385\n",
            "[233/25][50/69] Loss_D: 0.0007 Loss_G: 9.1912\n",
            "[233/25][51/69] Loss_D: 0.0013 Loss_G: 10.7415\n",
            "[233/25][52/69] Loss_D: 0.0012 Loss_G: 9.8810\n",
            "[233/25][53/69] Loss_D: 0.0042 Loss_G: 9.1925\n",
            "[233/25][54/69] Loss_D: 0.0067 Loss_G: 8.3869\n",
            "[233/25][55/69] Loss_D: 0.0033 Loss_G: 8.5437\n",
            "[233/25][56/69] Loss_D: 0.0023 Loss_G: 9.3917\n",
            "[233/25][57/69] Loss_D: 0.0013 Loss_G: 9.4380\n",
            "[233/25][58/69] Loss_D: 0.0004 Loss_G: 10.1223\n",
            "[233/25][59/69] Loss_D: 0.0010 Loss_G: 9.7140\n",
            "[233/25][60/69] Loss_D: 0.0019 Loss_G: 9.0568\n",
            "[233/25][61/69] Loss_D: 0.0007 Loss_G: 9.6335\n",
            "[233/25][62/69] Loss_D: 0.0009 Loss_G: 9.5680\n",
            "[233/25][63/69] Loss_D: 0.0011 Loss_G: 9.1968\n",
            "[233/25][64/69] Loss_D: 0.0005 Loss_G: 9.8092\n",
            "[233/25][65/69] Loss_D: 0.0003 Loss_G: 10.1385\n",
            "[233/25][66/69] Loss_D: 0.0008 Loss_G: 9.5615\n",
            "[233/25][67/69] Loss_D: 0.0006 Loss_G: 9.0306\n",
            "[233/25][68/69] Loss_D: 0.0007 Loss_G: 10.0225\n",
            "[234/25][0/69] Loss_D: 0.0001 Loss_G: 10.5064\n",
            "[234/25][1/69] Loss_D: 0.0004 Loss_G: 9.4554\n",
            "[234/25][2/69] Loss_D: 0.0012 Loss_G: 8.3631\n",
            "[234/25][3/69] Loss_D: 0.0009 Loss_G: 8.7915\n",
            "[234/25][4/69] Loss_D: 0.0006 Loss_G: 9.0776\n",
            "[234/25][5/69] Loss_D: 0.0014 Loss_G: 8.0372\n",
            "[234/25][6/69] Loss_D: 0.0002 Loss_G: 9.8567\n",
            "[234/25][7/69] Loss_D: 0.0003 Loss_G: 9.9090\n",
            "[234/25][8/69] Loss_D: 0.0007 Loss_G: 9.1159\n",
            "[234/25][9/69] Loss_D: 0.0003 Loss_G: 9.6911\n",
            "[234/25][10/69] Loss_D: 0.0003 Loss_G: 8.8934\n",
            "[234/25][11/69] Loss_D: 0.0005 Loss_G: 8.6396\n",
            "[234/25][12/69] Loss_D: 0.0001 Loss_G: 10.7183\n",
            "[234/25][13/69] Loss_D: 0.0015 Loss_G: 7.6813\n",
            "[234/25][14/69] Loss_D: 0.0025 Loss_G: 7.1365\n",
            "[234/25][15/69] Loss_D: 0.0008 Loss_G: 8.5043\n",
            "[234/25][16/69] Loss_D: 0.0010 Loss_G: 8.4200\n",
            "[234/25][17/69] Loss_D: 0.0006 Loss_G: 8.1862\n",
            "[234/25][18/69] Loss_D: 0.0135 Loss_G: 7.6389\n",
            "[234/25][19/69] Loss_D: 0.0008 Loss_G: 8.4551\n",
            "[234/25][20/69] Loss_D: 0.0029 Loss_G: 6.7398\n",
            "[234/25][21/69] Loss_D: 0.0033 Loss_G: 6.7202\n",
            "[234/25][22/69] Loss_D: 0.0029 Loss_G: 7.0613\n",
            "[234/25][23/69] Loss_D: 0.0041 Loss_G: 6.9388\n",
            "[234/25][24/69] Loss_D: 0.0011 Loss_G: 8.1891\n",
            "[234/25][25/69] Loss_D: 0.0045 Loss_G: 7.4158\n",
            "[234/25][26/69] Loss_D: 0.0013 Loss_G: 7.8851\n",
            "[234/25][27/69] Loss_D: 0.0007 Loss_G: 8.7332\n",
            "[234/25][28/69] Loss_D: 0.0010 Loss_G: 8.5746\n",
            "[234/25][29/69] Loss_D: 0.0037 Loss_G: 6.9688\n",
            "[234/25][30/69] Loss_D: 0.0013 Loss_G: 8.0814\n",
            "[234/25][31/69] Loss_D: 0.0019 Loss_G: 7.6489\n",
            "[234/25][32/69] Loss_D: 0.0006 Loss_G: 8.9383\n",
            "[234/25][33/69] Loss_D: 0.0003 Loss_G: 9.7251\n",
            "[234/25][34/69] Loss_D: 0.0219 Loss_G: 8.9757\n",
            "[234/25][35/69] Loss_D: 0.0028 Loss_G: 9.2844\n",
            "[234/25][36/69] Loss_D: 0.0008 Loss_G: 7.9558\n",
            "[234/25][37/69] Loss_D: 0.0014 Loss_G: 7.5761\n",
            "[234/25][38/69] Loss_D: 0.0021 Loss_G: 7.4117\n",
            "[234/25][39/69] Loss_D: 0.0036 Loss_G: 6.8324\n",
            "[234/25][40/69] Loss_D: 0.0048 Loss_G: 6.4607\n",
            "[234/25][41/69] Loss_D: 0.0058 Loss_G: 6.9206\n",
            "[234/25][42/69] Loss_D: 0.0001 Loss_G: 10.4462\n",
            "[234/25][43/69] Loss_D: 0.0011 Loss_G: 8.4541\n",
            "[234/25][44/69] Loss_D: 0.0130 Loss_G: 9.1258\n",
            "[234/25][45/69] Loss_D: 0.0016 Loss_G: 7.6486\n",
            "[234/25][46/69] Loss_D: 0.0045 Loss_G: 6.8971\n",
            "[234/25][47/69] Loss_D: 0.0007 Loss_G: 8.8588\n",
            "[234/25][48/69] Loss_D: 0.0166 Loss_G: 8.7001\n",
            "[234/25][49/69] Loss_D: 0.0028 Loss_G: 8.8624\n",
            "[234/25][50/69] Loss_D: 0.0011 Loss_G: 7.8379\n",
            "[234/25][51/69] Loss_D: 0.0055 Loss_G: 6.6094\n",
            "[234/25][52/69] Loss_D: 0.0052 Loss_G: 6.8927\n",
            "[234/25][53/69] Loss_D: 0.0020 Loss_G: 7.5015\n",
            "[234/25][54/69] Loss_D: 0.0079 Loss_G: 6.5187\n",
            "[234/25][55/69] Loss_D: 0.0051 Loss_G: 6.9212\n",
            "[234/25][56/69] Loss_D: 0.0007 Loss_G: 9.4704\n",
            "[234/25][57/69] Loss_D: 0.0052 Loss_G: 7.0062\n",
            "[234/25][58/69] Loss_D: 0.0029 Loss_G: 7.5094\n",
            "[234/25][59/69] Loss_D: 0.0006 Loss_G: 9.8442\n",
            "[234/25][60/69] Loss_D: 0.0186 Loss_G: 10.8821\n",
            "[234/25][61/69] Loss_D: 0.0003 Loss_G: 9.1775\n",
            "[234/25][62/69] Loss_D: 0.0060 Loss_G: 9.3233\n",
            "[234/25][63/69] Loss_D: 0.0003 Loss_G: 9.5746\n",
            "[234/25][64/69] Loss_D: 0.0025 Loss_G: 8.3364\n",
            "[234/25][65/69] Loss_D: 0.0081 Loss_G: 7.1000\n",
            "[234/25][66/69] Loss_D: 0.0012 Loss_G: 9.0642\n",
            "[234/25][67/69] Loss_D: 0.0012 Loss_G: 8.9978\n",
            "[234/25][68/69] Loss_D: 0.0037 Loss_G: 7.8446\n",
            "[235/25][0/69] Loss_D: 0.0015 Loss_G: 7.8192\n",
            "[235/25][1/69] Loss_D: 0.0015 Loss_G: 7.9705\n",
            "[235/25][2/69] Loss_D: 0.0010 Loss_G: 8.7286\n",
            "[235/25][3/69] Loss_D: 0.0012 Loss_G: 9.1997\n",
            "[235/25][4/69] Loss_D: 0.0009 Loss_G: 9.0666\n",
            "[235/25][5/69] Loss_D: 0.4371 Loss_G: 3.3990\n",
            "[235/25][6/69] Loss_D: 0.8774 Loss_G: 8.3147\n",
            "[235/25][7/69] Loss_D: 0.0122 Loss_G: 15.1874\n",
            "[235/25][8/69] Loss_D: 0.0075 Loss_G: 21.0063\n",
            "[235/25][9/69] Loss_D: 0.4423 Loss_G: 18.8032\n",
            "[235/25][10/69] Loss_D: 0.0602 Loss_G: 19.5695\n",
            "[235/25][11/69] Loss_D: 0.6052 Loss_G: 15.1632\n",
            "[235/25][12/69] Loss_D: 0.1087 Loss_G: 18.7075\n",
            "[235/25][13/69] Loss_D: 0.0263 Loss_G: 23.4411\n",
            "[235/25][14/69] Loss_D: 0.4766 Loss_G: 20.2596\n",
            "[235/25][15/69] Loss_D: 0.2197 Loss_G: 25.6987\n",
            "[235/25][16/69] Loss_D: 0.0176 Loss_G: 20.1455\n",
            "[235/25][17/69] Loss_D: 0.0018 Loss_G: 25.0115\n",
            "[235/25][18/69] Loss_D: 0.0793 Loss_G: 21.2575\n",
            "[235/25][19/69] Loss_D: 0.0006 Loss_G: 18.4898\n",
            "[235/25][20/69] Loss_D: 0.0007 Loss_G: 18.6164\n",
            "[235/25][21/69] Loss_D: 0.0056 Loss_G: 15.0108\n",
            "[235/25][22/69] Loss_D: 0.0556 Loss_G: 17.3625\n",
            "[235/25][23/69] Loss_D: 0.0336 Loss_G: 16.4154\n",
            "[235/25][24/69] Loss_D: 0.0017 Loss_G: 14.3759\n",
            "[235/25][25/69] Loss_D: 0.0008 Loss_G: 18.3974\n",
            "[235/25][26/69] Loss_D: 0.0013 Loss_G: 18.1263\n",
            "[235/25][27/69] Loss_D: 0.0041 Loss_G: 19.6692\n",
            "[235/25][28/69] Loss_D: 0.0368 Loss_G: 17.0832\n",
            "[235/25][29/69] Loss_D: 0.0007 Loss_G: 15.0461\n",
            "[235/25][30/69] Loss_D: 0.0030 Loss_G: 15.4251\n",
            "[235/25][31/69] Loss_D: 0.0071 Loss_G: 15.8141\n",
            "[235/25][32/69] Loss_D: 0.0142 Loss_G: 16.4397\n",
            "[235/25][33/69] Loss_D: 0.0156 Loss_G: 16.9391\n",
            "[235/25][34/69] Loss_D: 0.0224 Loss_G: 17.2129\n",
            "[235/25][35/69] Loss_D: 0.0017 Loss_G: 17.9324\n",
            "[235/25][36/69] Loss_D: 0.2946 Loss_G: 14.8937\n",
            "[235/25][37/69] Loss_D: 0.0025 Loss_G: 13.3283\n",
            "[235/25][38/69] Loss_D: 0.0451 Loss_G: 11.5984\n",
            "[235/25][39/69] Loss_D: 0.0359 Loss_G: 11.8620\n",
            "[235/25][40/69] Loss_D: 0.0308 Loss_G: 13.7489\n",
            "[235/25][41/69] Loss_D: 0.0024 Loss_G: 16.3928\n",
            "[235/25][42/69] Loss_D: 0.0008 Loss_G: 15.8492\n",
            "[235/25][43/69] Loss_D: 0.0001 Loss_G: 18.6021\n",
            "[235/25][44/69] Loss_D: 0.0000 Loss_G: 15.7558\n",
            "[235/25][45/69] Loss_D: 0.0005 Loss_G: 17.5259\n",
            "[235/25][46/69] Loss_D: 0.0000 Loss_G: 18.9748\n",
            "[235/25][47/69] Loss_D: 0.0007 Loss_G: 17.3485\n",
            "[235/25][48/69] Loss_D: 0.0034 Loss_G: 18.8740\n",
            "[235/25][49/69] Loss_D: 0.0081 Loss_G: 16.7743\n",
            "[235/25][50/69] Loss_D: 0.0617 Loss_G: 15.7102\n",
            "[235/25][51/69] Loss_D: 0.1024 Loss_G: 14.7115\n",
            "[235/25][52/69] Loss_D: 0.0191 Loss_G: 12.3836\n",
            "[235/25][53/69] Loss_D: 0.0365 Loss_G: 10.8207\n",
            "[235/25][54/69] Loss_D: 0.0269 Loss_G: 11.2504\n",
            "[235/25][55/69] Loss_D: 0.0021 Loss_G: 12.6972\n",
            "[235/25][56/69] Loss_D: 0.0040 Loss_G: 11.5435\n",
            "[235/25][57/69] Loss_D: 0.0030 Loss_G: 12.7634\n",
            "[235/25][58/69] Loss_D: 0.0002 Loss_G: 13.8327\n",
            "[235/25][59/69] Loss_D: 0.0002 Loss_G: 14.2510\n",
            "[235/25][60/69] Loss_D: 0.0008 Loss_G: 14.0344\n",
            "[235/25][61/69] Loss_D: 0.0001 Loss_G: 14.8384\n",
            "[235/25][62/69] Loss_D: 0.0001 Loss_G: 13.3053\n",
            "[235/25][63/69] Loss_D: 0.0007 Loss_G: 14.9496\n",
            "[235/25][64/69] Loss_D: 0.0183 Loss_G: 13.2931\n",
            "[235/25][65/69] Loss_D: 0.0002 Loss_G: 12.2108\n",
            "[235/25][66/69] Loss_D: 0.0004 Loss_G: 11.5235\n",
            "[235/25][67/69] Loss_D: 0.0001 Loss_G: 11.7844\n",
            "[235/25][68/69] Loss_D: 0.0003 Loss_G: 11.0163\n",
            "[236/25][0/69] Loss_D: 0.0093 Loss_G: 9.3129\n",
            "[236/25][1/69] Loss_D: 0.0057 Loss_G: 8.7325\n",
            "[236/25][2/69] Loss_D: 0.0035 Loss_G: 9.4482\n",
            "[236/25][3/69] Loss_D: 0.0011 Loss_G: 9.5576\n",
            "[236/25][4/69] Loss_D: 0.0027 Loss_G: 7.9038\n",
            "[236/25][5/69] Loss_D: 0.0538 Loss_G: 7.1726\n",
            "[236/25][6/69] Loss_D: 0.0060 Loss_G: 9.1792\n",
            "[236/25][7/69] Loss_D: 0.0007 Loss_G: 10.5193\n",
            "[236/25][8/69] Loss_D: 0.0025 Loss_G: 10.5541\n",
            "[236/25][9/69] Loss_D: 0.0003 Loss_G: 11.0152\n",
            "[236/25][10/69] Loss_D: 0.0238 Loss_G: 11.9597\n",
            "[236/25][11/69] Loss_D: 0.0161 Loss_G: 10.3580\n",
            "[236/25][12/69] Loss_D: 0.0002 Loss_G: 10.5433\n",
            "[236/25][13/69] Loss_D: 0.0484 Loss_G: 8.7908\n",
            "[236/25][14/69] Loss_D: 0.0011 Loss_G: 7.6922\n",
            "[236/25][15/69] Loss_D: 0.0026 Loss_G: 6.6105\n",
            "[236/25][16/69] Loss_D: 0.0177 Loss_G: 5.2573\n",
            "[236/25][17/69] Loss_D: 0.0163 Loss_G: 5.9069\n",
            "[236/25][18/69] Loss_D: 0.0018 Loss_G: 8.2613\n",
            "[236/25][19/69] Loss_D: 0.0055 Loss_G: 6.9627\n",
            "[236/25][20/69] Loss_D: 0.0222 Loss_G: 5.9871\n",
            "[236/25][21/69] Loss_D: 0.0066 Loss_G: 7.5293\n",
            "[236/25][22/69] Loss_D: 0.0008 Loss_G: 9.3537\n",
            "[236/25][23/69] Loss_D: 0.0009 Loss_G: 9.1579\n",
            "[236/25][24/69] Loss_D: 0.0006 Loss_G: 9.4659\n",
            "[236/25][25/69] Loss_D: 0.0005 Loss_G: 9.3183\n",
            "[236/25][26/69] Loss_D: 0.0003 Loss_G: 9.7858\n",
            "[236/25][27/69] Loss_D: 0.0002 Loss_G: 10.0125\n",
            "[236/25][28/69] Loss_D: 0.0001 Loss_G: 11.0697\n",
            "[236/25][29/69] Loss_D: 0.0007 Loss_G: 11.1520\n",
            "[236/25][30/69] Loss_D: 0.0001 Loss_G: 10.2920\n",
            "[236/25][31/69] Loss_D: 0.0002 Loss_G: 10.2910\n",
            "[236/25][32/69] Loss_D: 0.0002 Loss_G: 10.1773\n",
            "[236/25][33/69] Loss_D: 0.0020 Loss_G: 10.6495\n",
            "[236/25][34/69] Loss_D: 0.0016 Loss_G: 7.6944\n",
            "[236/25][35/69] Loss_D: 0.0006 Loss_G: 8.6139\n",
            "[236/25][36/69] Loss_D: 0.0004 Loss_G: 9.1180\n",
            "[236/25][37/69] Loss_D: 0.0019 Loss_G: 8.1616\n",
            "[236/25][38/69] Loss_D: 0.0033 Loss_G: 7.0233\n",
            "[236/25][39/69] Loss_D: 0.0521 Loss_G: 6.4115\n",
            "[236/25][40/69] Loss_D: 0.0051 Loss_G: 6.9517\n",
            "[236/25][41/69] Loss_D: 0.0560 Loss_G: 6.6359\n",
            "[236/25][42/69] Loss_D: 0.0109 Loss_G: 7.0375\n",
            "[236/25][43/69] Loss_D: 0.0036 Loss_G: 8.9439\n",
            "[236/25][44/69] Loss_D: 0.0017 Loss_G: 8.7270\n",
            "[236/25][45/69] Loss_D: 0.0018 Loss_G: 8.9801\n",
            "[236/25][46/69] Loss_D: 0.0110 Loss_G: 9.3833\n",
            "[236/25][47/69] Loss_D: 0.0004 Loss_G: 10.4961\n",
            "[236/25][48/69] Loss_D: 0.0003 Loss_G: 10.8427\n",
            "[236/25][49/69] Loss_D: 0.0009 Loss_G: 9.5169\n",
            "[236/25][50/69] Loss_D: 0.0088 Loss_G: 10.5592\n",
            "[236/25][51/69] Loss_D: 0.0003 Loss_G: 10.8972\n",
            "[236/25][52/69] Loss_D: 0.0087 Loss_G: 9.7525\n",
            "[236/25][53/69] Loss_D: 0.0026 Loss_G: 12.0545\n",
            "[236/25][54/69] Loss_D: 0.0010 Loss_G: 8.5236\n",
            "[236/25][55/69] Loss_D: 0.0021 Loss_G: 7.8899\n",
            "[236/25][56/69] Loss_D: 0.0021 Loss_G: 7.5434\n",
            "[236/25][57/69] Loss_D: 0.0022 Loss_G: 8.4194\n",
            "[236/25][58/69] Loss_D: 0.0013 Loss_G: 8.4786\n",
            "[236/25][59/69] Loss_D: 0.0015 Loss_G: 8.3569\n",
            "[236/25][60/69] Loss_D: 0.0033 Loss_G: 7.5784\n",
            "[236/25][61/69] Loss_D: 0.0019 Loss_G: 7.9892\n",
            "[236/25][62/69] Loss_D: 0.0027 Loss_G: 7.8186\n",
            "[236/25][63/69] Loss_D: 0.0019 Loss_G: 8.1327\n",
            "[236/25][64/69] Loss_D: 0.0017 Loss_G: 8.2242\n",
            "[236/25][65/69] Loss_D: 0.0039 Loss_G: 7.7252\n",
            "[236/25][66/69] Loss_D: 0.0018 Loss_G: 7.9138\n",
            "[236/25][67/69] Loss_D: 0.0011 Loss_G: 8.5366\n",
            "[236/25][68/69] Loss_D: 0.0040 Loss_G: 7.6085\n",
            "[237/25][0/69] Loss_D: 0.0013 Loss_G: 8.4114\n",
            "[237/25][1/69] Loss_D: 0.0018 Loss_G: 7.8682\n",
            "[237/25][2/69] Loss_D: 0.0029 Loss_G: 8.1177\n",
            "[237/25][3/69] Loss_D: 0.0032 Loss_G: 8.3097\n",
            "[237/25][4/69] Loss_D: 0.0024 Loss_G: 9.1465\n",
            "[237/25][5/69] Loss_D: 0.0017 Loss_G: 7.9389\n",
            "[237/25][6/69] Loss_D: 0.0022 Loss_G: 7.6935\n",
            "[237/25][7/69] Loss_D: 0.0016 Loss_G: 7.9894\n",
            "[237/25][8/69] Loss_D: 0.0125 Loss_G: 7.7660\n",
            "[237/25][9/69] Loss_D: 0.0039 Loss_G: 7.1218\n",
            "[237/25][10/69] Loss_D: 0.0022 Loss_G: 7.4987\n",
            "[237/25][11/69] Loss_D: 0.0145 Loss_G: 6.9175\n",
            "[237/25][12/69] Loss_D: 0.0014 Loss_G: 7.8564\n",
            "[237/25][13/69] Loss_D: 0.0043 Loss_G: 6.4158\n",
            "[237/25][14/69] Loss_D: 0.0080 Loss_G: 6.3334\n",
            "[237/25][15/69] Loss_D: 0.0021 Loss_G: 7.4568\n",
            "[237/25][16/69] Loss_D: 0.0019 Loss_G: 7.3961\n",
            "[237/25][17/69] Loss_D: 0.0074 Loss_G: 7.7436\n",
            "[237/25][18/69] Loss_D: 0.0021 Loss_G: 7.3829\n",
            "[237/25][19/69] Loss_D: 0.0064 Loss_G: 6.8963\n",
            "[237/25][20/69] Loss_D: 0.0048 Loss_G: 6.6099\n",
            "[237/25][21/69] Loss_D: 0.0024 Loss_G: 6.8655\n",
            "[237/25][22/69] Loss_D: 0.0097 Loss_G: 7.1356\n",
            "[237/25][23/69] Loss_D: 0.0038 Loss_G: 6.5206\n",
            "[237/25][24/69] Loss_D: 0.0025 Loss_G: 6.9307\n",
            "[237/25][25/69] Loss_D: 0.0023 Loss_G: 7.0154\n",
            "[237/25][26/69] Loss_D: 0.0036 Loss_G: 6.5841\n",
            "[237/25][27/69] Loss_D: 0.0007 Loss_G: 8.3663\n",
            "[237/25][28/69] Loss_D: 0.0021 Loss_G: 7.4462\n",
            "[237/25][29/69] Loss_D: 0.0041 Loss_G: 7.7116\n",
            "[237/25][30/69] Loss_D: 0.0016 Loss_G: 7.7579\n",
            "[237/25][31/69] Loss_D: 0.0041 Loss_G: 6.8468\n",
            "[237/25][32/69] Loss_D: 0.0013 Loss_G: 7.8298\n",
            "[237/25][33/69] Loss_D: 0.0032 Loss_G: 7.5252\n",
            "[237/25][34/69] Loss_D: 0.0008 Loss_G: 8.0573\n",
            "[237/25][35/69] Loss_D: 0.0047 Loss_G: 8.3943\n",
            "[237/25][36/69] Loss_D: 0.0042 Loss_G: 8.0657\n",
            "[237/25][37/69] Loss_D: 0.0002 Loss_G: 9.4823\n",
            "[237/25][38/69] Loss_D: 0.0014 Loss_G: 8.0594\n",
            "[237/25][39/69] Loss_D: 0.0013 Loss_G: 8.3672\n",
            "[237/25][40/69] Loss_D: 0.0020 Loss_G: 7.6052\n",
            "[237/25][41/69] Loss_D: 0.0014 Loss_G: 8.2893\n",
            "[237/25][42/69] Loss_D: 0.0020 Loss_G: 7.0134\n",
            "[237/25][43/69] Loss_D: 0.0009 Loss_G: 7.6336\n",
            "[237/25][44/69] Loss_D: 0.0015 Loss_G: 7.3117\n",
            "[237/25][45/69] Loss_D: 0.0024 Loss_G: 7.5897\n",
            "[237/25][46/69] Loss_D: 0.0046 Loss_G: 6.4974\n",
            "[237/25][47/69] Loss_D: 0.0043 Loss_G: 6.6515\n",
            "[237/25][48/69] Loss_D: 0.0020 Loss_G: 7.3876\n",
            "[237/25][49/69] Loss_D: 0.0007 Loss_G: 8.5306\n",
            "[237/25][50/69] Loss_D: 0.0011 Loss_G: 8.2326\n",
            "[237/25][51/69] Loss_D: 0.0044 Loss_G: 7.2994\n",
            "[237/25][52/69] Loss_D: 0.0007 Loss_G: 8.6539\n",
            "[237/25][53/69] Loss_D: 0.0025 Loss_G: 8.3544\n",
            "[237/25][54/69] Loss_D: 0.0013 Loss_G: 8.1878\n",
            "[237/25][55/69] Loss_D: 0.0217 Loss_G: 6.5726\n",
            "[237/25][56/69] Loss_D: 0.0022 Loss_G: 6.7996\n",
            "[237/25][57/69] Loss_D: 0.0107 Loss_G: 5.6859\n",
            "[237/25][58/69] Loss_D: 0.0113 Loss_G: 6.2691\n",
            "[237/25][59/69] Loss_D: 0.0071 Loss_G: 6.3608\n",
            "[237/25][60/69] Loss_D: 0.0105 Loss_G: 6.7807\n",
            "[237/25][61/69] Loss_D: 0.0041 Loss_G: 8.4856\n",
            "[237/25][62/69] Loss_D: 0.0009 Loss_G: 8.2369\n",
            "[237/25][63/69] Loss_D: 0.0008 Loss_G: 8.4650\n",
            "[237/25][64/69] Loss_D: 0.0384 Loss_G: 9.6053\n",
            "[237/25][65/69] Loss_D: 0.0412 Loss_G: 6.8652\n",
            "[237/25][66/69] Loss_D: 0.0132 Loss_G: 4.3526\n",
            "[237/25][67/69] Loss_D: 0.0635 Loss_G: 5.7851\n",
            "[237/25][68/69] Loss_D: 0.0093 Loss_G: 7.3496\n",
            "[238/25][0/69] Loss_D: 0.0014 Loss_G: 9.2333\n",
            "[238/25][1/69] Loss_D: 0.0002 Loss_G: 11.5892\n",
            "[238/25][2/69] Loss_D: 0.0002 Loss_G: 11.4965\n",
            "[238/25][3/69] Loss_D: 0.0002 Loss_G: 11.6673\n",
            "[238/25][4/69] Loss_D: 0.0000 Loss_G: 14.4329\n",
            "[238/25][5/69] Loss_D: 0.0046 Loss_G: 14.4081\n",
            "[238/25][6/69] Loss_D: 0.0268 Loss_G: 16.7966\n",
            "[238/25][7/69] Loss_D: 0.0002 Loss_G: 13.5947\n",
            "[238/25][8/69] Loss_D: 0.0059 Loss_G: 14.1420\n",
            "[238/25][9/69] Loss_D: 0.0001 Loss_G: 12.0792\n",
            "[238/25][10/69] Loss_D: 0.0001 Loss_G: 11.9841\n",
            "[238/25][11/69] Loss_D: 0.0002 Loss_G: 13.0174\n",
            "[238/25][12/69] Loss_D: 0.0000 Loss_G: 12.3801\n",
            "[238/25][13/69] Loss_D: 0.0002 Loss_G: 11.4333\n",
            "[238/25][14/69] Loss_D: 0.0000 Loss_G: 12.9988\n",
            "[238/25][15/69] Loss_D: 0.0006 Loss_G: 10.1734\n",
            "[238/25][16/69] Loss_D: 0.0003 Loss_G: 10.5590\n",
            "[238/25][17/69] Loss_D: 0.0014 Loss_G: 9.0013\n",
            "[238/25][18/69] Loss_D: 0.0004 Loss_G: 9.8908\n",
            "[238/25][19/69] Loss_D: 0.0011 Loss_G: 8.7890\n",
            "[238/25][20/69] Loss_D: 0.0022 Loss_G: 8.2933\n",
            "[238/25][21/69] Loss_D: 0.0039 Loss_G: 8.1121\n",
            "[238/25][22/69] Loss_D: 0.0066 Loss_G: 7.5119\n",
            "[238/25][23/69] Loss_D: 0.0005 Loss_G: 9.8936\n",
            "[238/25][24/69] Loss_D: 0.0009 Loss_G: 9.2150\n",
            "[238/25][25/69] Loss_D: 0.0024 Loss_G: 7.5772\n",
            "[238/25][26/69] Loss_D: 0.0010 Loss_G: 8.9420\n",
            "[238/25][27/69] Loss_D: 0.0024 Loss_G: 9.1607\n",
            "[238/25][28/69] Loss_D: 0.0005 Loss_G: 9.5835\n",
            "[238/25][29/69] Loss_D: 0.0010 Loss_G: 9.1410\n",
            "[238/25][30/69] Loss_D: 0.0217 Loss_G: 9.0089\n",
            "[238/25][31/69] Loss_D: 0.0050 Loss_G: 6.5344\n",
            "[238/25][32/69] Loss_D: 0.0057 Loss_G: 7.7751\n",
            "[238/25][33/69] Loss_D: 0.0199 Loss_G: 8.3370\n",
            "[238/25][34/69] Loss_D: 0.0030 Loss_G: 8.4119\n",
            "[238/25][35/69] Loss_D: 0.0002 Loss_G: 10.9382\n",
            "[238/25][36/69] Loss_D: 0.0006 Loss_G: 9.8903\n",
            "[238/25][37/69] Loss_D: 0.0003 Loss_G: 11.3220\n",
            "[238/25][38/69] Loss_D: 0.0001 Loss_G: 11.4991\n",
            "[238/25][39/69] Loss_D: 0.0213 Loss_G: 10.6153\n",
            "[238/25][40/69] Loss_D: 0.0002 Loss_G: 10.0050\n",
            "[238/25][41/69] Loss_D: 0.0074 Loss_G: 7.9279\n",
            "[238/25][42/69] Loss_D: 0.0015 Loss_G: 7.4571\n",
            "[238/25][43/69] Loss_D: 0.0033 Loss_G: 7.4749\n",
            "[238/25][44/69] Loss_D: 0.0011 Loss_G: 7.5993\n",
            "[238/25][45/69] Loss_D: 0.0033 Loss_G: 7.2033\n",
            "[238/25][46/69] Loss_D: 0.0028 Loss_G: 7.3600\n",
            "[238/25][47/69] Loss_D: 0.0034 Loss_G: 7.6343\n",
            "[238/25][48/69] Loss_D: 0.0054 Loss_G: 7.3202\n",
            "[238/25][49/69] Loss_D: 0.0113 Loss_G: 6.8587\n",
            "[238/25][50/69] Loss_D: 0.1326 Loss_G: 5.6694\n",
            "[238/25][51/69] Loss_D: 0.0438 Loss_G: 3.5579\n",
            "[238/25][52/69] Loss_D: 0.1470 Loss_G: 8.2010\n",
            "[238/25][53/69] Loss_D: 0.0014 Loss_G: 11.4863\n",
            "[238/25][54/69] Loss_D: 0.0002 Loss_G: 15.6829\n",
            "[238/25][55/69] Loss_D: 0.0112 Loss_G: 16.8042\n",
            "[238/25][56/69] Loss_D: 0.1505 Loss_G: 17.3917\n",
            "[238/25][57/69] Loss_D: 0.0011 Loss_G: 18.1301\n",
            "[238/25][58/69] Loss_D: 0.0160 Loss_G: 16.8053\n",
            "[238/25][59/69] Loss_D: 0.0002 Loss_G: 16.2509\n",
            "[238/25][60/69] Loss_D: 0.0001 Loss_G: 14.9360\n",
            "[238/25][61/69] Loss_D: 0.0002 Loss_G: 18.2616\n",
            "[238/25][62/69] Loss_D: 0.0003 Loss_G: 16.5256\n",
            "[238/25][63/69] Loss_D: 0.0006 Loss_G: 15.4208\n",
            "[238/25][64/69] Loss_D: 0.0088 Loss_G: 15.3550\n",
            "[238/25][65/69] Loss_D: 0.0009 Loss_G: 15.3587\n",
            "[238/25][66/69] Loss_D: 0.0007 Loss_G: 13.4339\n",
            "[238/25][67/69] Loss_D: 0.0047 Loss_G: 16.1329\n",
            "[238/25][68/69] Loss_D: 0.0018 Loss_G: 16.1048\n",
            "[239/25][0/69] Loss_D: 0.0050 Loss_G: 12.1577\n",
            "[239/25][1/69] Loss_D: 0.0021 Loss_G: 18.8056\n",
            "[239/25][2/69] Loss_D: 0.0022 Loss_G: 16.7931\n",
            "[239/25][3/69] Loss_D: 0.0040 Loss_G: 16.3453\n",
            "[239/25][4/69] Loss_D: 0.0016 Loss_G: 16.0222\n",
            "[239/25][5/69] Loss_D: 0.0051 Loss_G: 16.5790\n",
            "[239/25][6/69] Loss_D: 0.0007 Loss_G: 15.3414\n",
            "[239/25][7/69] Loss_D: 0.0023 Loss_G: 17.2833\n",
            "[239/25][8/69] Loss_D: 0.0021 Loss_G: 16.7095\n",
            "[239/25][9/69] Loss_D: 0.0002 Loss_G: 15.6334\n",
            "[239/25][10/69] Loss_D: 0.0053 Loss_G: 16.6077\n",
            "[239/25][11/69] Loss_D: 0.0011 Loss_G: 17.0565\n",
            "[239/25][12/69] Loss_D: 0.0583 Loss_G: 12.7053\n",
            "[239/25][13/69] Loss_D: 0.0029 Loss_G: 14.4673\n",
            "[239/25][14/69] Loss_D: 0.0084 Loss_G: 16.0147\n",
            "[239/25][15/69] Loss_D: 0.0272 Loss_G: 15.0761\n",
            "[239/25][16/69] Loss_D: 0.0049 Loss_G: 13.5991\n",
            "[239/25][17/69] Loss_D: 0.0120 Loss_G: 20.7055\n",
            "[239/25][18/69] Loss_D: 0.0066 Loss_G: 18.1344\n",
            "[239/25][19/69] Loss_D: 0.0006 Loss_G: 16.9729\n",
            "[239/25][20/69] Loss_D: 0.0004 Loss_G: 16.6658\n",
            "[239/25][21/69] Loss_D: 0.0016 Loss_G: 18.9612\n",
            "[239/25][22/69] Loss_D: 0.0003 Loss_G: 16.6681\n",
            "[239/25][23/69] Loss_D: 0.0022 Loss_G: 18.7605\n",
            "[239/25][24/69] Loss_D: 0.0013 Loss_G: 19.0025\n",
            "[239/25][25/69] Loss_D: 0.0069 Loss_G: 20.4722\n",
            "[239/25][26/69] Loss_D: 0.0026 Loss_G: 18.1638\n",
            "[239/25][27/69] Loss_D: 0.0008 Loss_G: 18.6547\n",
            "[239/25][28/69] Loss_D: 0.0015 Loss_G: 18.8962\n",
            "[239/25][29/69] Loss_D: 0.0008 Loss_G: 17.6233\n",
            "[239/25][30/69] Loss_D: 0.0003 Loss_G: 18.5096\n",
            "[239/25][31/69] Loss_D: 0.0045 Loss_G: 20.4794\n",
            "[239/25][32/69] Loss_D: 0.0026 Loss_G: 21.6816\n",
            "[239/25][33/69] Loss_D: 0.0003 Loss_G: 19.1035\n",
            "[239/25][34/69] Loss_D: 0.0002 Loss_G: 17.9372\n",
            "[239/25][35/69] Loss_D: 0.0097 Loss_G: 18.8687\n",
            "[239/25][36/69] Loss_D: 0.0013 Loss_G: 17.1626\n",
            "[239/25][37/69] Loss_D: 0.0033 Loss_G: 17.4665\n",
            "[239/25][38/69] Loss_D: 0.0192 Loss_G: 21.2581\n",
            "[239/25][39/69] Loss_D: 0.2196 Loss_G: 15.2580\n",
            "[239/25][40/69] Loss_D: 0.0122 Loss_G: 11.6203\n",
            "[239/25][41/69] Loss_D: 0.1562 Loss_G: 16.5255\n",
            "[239/25][42/69] Loss_D: 0.0059 Loss_G: 18.5216\n",
            "[239/25][43/69] Loss_D: 0.0008 Loss_G: 19.3749\n",
            "[239/25][44/69] Loss_D: 0.0004 Loss_G: 19.8461\n",
            "[239/25][45/69] Loss_D: 0.0468 Loss_G: 23.8923\n",
            "[239/25][46/69] Loss_D: 0.0453 Loss_G: 22.8538\n",
            "[239/25][47/69] Loss_D: 0.0044 Loss_G: 20.7895\n",
            "[239/25][48/69] Loss_D: 0.3757 Loss_G: 20.8576\n",
            "[239/25][49/69] Loss_D: 0.0009 Loss_G: 17.9860\n",
            "[239/25][50/69] Loss_D: 0.1867 Loss_G: 18.3111\n",
            "[239/25][51/69] Loss_D: 0.1837 Loss_G: 15.2619\n",
            "[239/25][52/69] Loss_D: 0.0943 Loss_G: 18.4101\n",
            "[239/25][53/69] Loss_D: 0.0025 Loss_G: 16.1630\n",
            "[239/25][54/69] Loss_D: 0.0023 Loss_G: 14.7938\n",
            "[239/25][55/69] Loss_D: 0.1256 Loss_G: 18.6779\n",
            "[239/25][56/69] Loss_D: 0.0009 Loss_G: 21.4072\n",
            "[239/25][57/69] Loss_D: 0.0002 Loss_G: 22.6384\n",
            "[239/25][58/69] Loss_D: 0.0007 Loss_G: 24.9043\n",
            "[239/25][59/69] Loss_D: 0.0025 Loss_G: 26.2504\n",
            "[239/25][60/69] Loss_D: 0.0241 Loss_G: 26.1573\n",
            "[239/25][61/69] Loss_D: 1.2280 Loss_G: 21.1260\n",
            "[239/25][62/69] Loss_D: 0.0002 Loss_G: 17.1288\n",
            "[239/25][63/69] Loss_D: 0.0153 Loss_G: 16.1670\n",
            "[239/25][64/69] Loss_D: 0.0219 Loss_G: 15.7088\n",
            "[239/25][65/69] Loss_D: 0.0091 Loss_G: 17.5705\n",
            "[239/25][66/69] Loss_D: 0.0005 Loss_G: 19.3451\n",
            "[239/25][67/69] Loss_D: 0.0009 Loss_G: 20.4128\n",
            "[239/25][68/69] Loss_D: 0.0001 Loss_G: 21.6046\n",
            "[240/25][0/69] Loss_D: 0.0892 Loss_G: 17.7328\n",
            "[240/25][1/69] Loss_D: 0.0474 Loss_G: 14.4332\n",
            "[240/25][2/69] Loss_D: 0.1186 Loss_G: 11.6406\n",
            "[240/25][3/69] Loss_D: 0.0210 Loss_G: 13.1492\n",
            "[240/25][4/69] Loss_D: 0.0058 Loss_G: 15.2461\n",
            "[240/25][5/69] Loss_D: 0.0163 Loss_G: 14.0977\n",
            "[240/25][6/69] Loss_D: 0.0286 Loss_G: 13.9542\n",
            "[240/25][7/69] Loss_D: 0.0115 Loss_G: 14.9639\n",
            "[240/25][8/69] Loss_D: 0.0151 Loss_G: 11.8006\n",
            "[240/25][9/69] Loss_D: 0.0028 Loss_G: 11.5542\n",
            "[240/25][10/69] Loss_D: 0.0084 Loss_G: 12.4676\n",
            "[240/25][11/69] Loss_D: 0.0207 Loss_G: 10.4109\n",
            "[240/25][12/69] Loss_D: 0.0059 Loss_G: 12.5240\n",
            "[240/25][13/69] Loss_D: 0.0292 Loss_G: 9.8545\n",
            "[240/25][14/69] Loss_D: 0.0041 Loss_G: 9.6685\n",
            "[240/25][15/69] Loss_D: 0.0065 Loss_G: 9.2632\n",
            "[240/25][16/69] Loss_D: 0.0124 Loss_G: 9.3846\n",
            "[240/25][17/69] Loss_D: 0.0041 Loss_G: 9.1348\n",
            "[240/25][18/69] Loss_D: 0.0031 Loss_G: 8.4196\n",
            "[240/25][19/69] Loss_D: 0.0013 Loss_G: 9.5240\n",
            "[240/25][20/69] Loss_D: 0.0313 Loss_G: 8.7664\n",
            "[240/25][21/69] Loss_D: 0.0043 Loss_G: 7.2097\n",
            "[240/25][22/69] Loss_D: 0.0458 Loss_G: 7.2493\n",
            "[240/25][23/69] Loss_D: 0.0136 Loss_G: 8.5623\n",
            "[240/25][24/69] Loss_D: 0.0343 Loss_G: 10.0112\n",
            "[240/25][25/69] Loss_D: 0.0074 Loss_G: 9.6324\n",
            "[240/25][26/69] Loss_D: 0.0013 Loss_G: 9.1066\n",
            "[240/25][27/69] Loss_D: 0.0038 Loss_G: 8.5151\n",
            "[240/25][28/69] Loss_D: 0.0030 Loss_G: 9.7583\n",
            "[240/25][29/69] Loss_D: 0.0081 Loss_G: 8.5356\n",
            "[240/25][30/69] Loss_D: 0.0101 Loss_G: 8.2915\n",
            "[240/25][31/69] Loss_D: 0.0040 Loss_G: 8.4565\n",
            "[240/25][32/69] Loss_D: 0.0056 Loss_G: 8.4770\n",
            "[240/25][33/69] Loss_D: 0.0033 Loss_G: 9.4109\n",
            "[240/25][34/69] Loss_D: 0.0018 Loss_G: 9.7842\n",
            "[240/25][35/69] Loss_D: 0.0025 Loss_G: 9.5883\n",
            "[240/25][36/69] Loss_D: 0.0059 Loss_G: 9.9827\n",
            "[240/25][37/69] Loss_D: 0.0103 Loss_G: 8.6345\n",
            "[240/25][38/69] Loss_D: 0.0055 Loss_G: 7.8605\n",
            "[240/25][39/69] Loss_D: 0.0051 Loss_G: 7.7714\n",
            "[240/25][40/69] Loss_D: 0.0421 Loss_G: 7.0863\n",
            "[240/25][41/69] Loss_D: 0.0074 Loss_G: 6.7942\n",
            "[240/25][42/69] Loss_D: 0.0107 Loss_G: 6.4220\n",
            "[240/25][43/69] Loss_D: 0.0248 Loss_G: 6.5946\n",
            "[240/25][44/69] Loss_D: 0.0086 Loss_G: 8.2711\n",
            "[240/25][45/69] Loss_D: 0.0018 Loss_G: 9.4253\n",
            "[240/25][46/69] Loss_D: 0.0025 Loss_G: 10.1188\n",
            "[240/25][47/69] Loss_D: 0.0003 Loss_G: 10.2701\n",
            "[240/25][48/69] Loss_D: 0.0148 Loss_G: 11.3665\n",
            "[240/25][49/69] Loss_D: 0.0049 Loss_G: 10.2546\n",
            "[240/25][50/69] Loss_D: 0.0034 Loss_G: 10.9722\n",
            "[240/25][51/69] Loss_D: 0.0003 Loss_G: 9.5436\n",
            "[240/25][52/69] Loss_D: 0.0015 Loss_G: 9.8126\n",
            "[240/25][53/69] Loss_D: 0.0004 Loss_G: 10.0706\n",
            "[240/25][54/69] Loss_D: 0.0006 Loss_G: 8.7406\n",
            "[240/25][55/69] Loss_D: 0.0019 Loss_G: 8.7310\n",
            "[240/25][56/69] Loss_D: 0.0005 Loss_G: 9.1288\n",
            "[240/25][57/69] Loss_D: 0.0009 Loss_G: 8.6668\n",
            "[240/25][58/69] Loss_D: 0.0019 Loss_G: 8.0222\n",
            "[240/25][59/69] Loss_D: 0.0008 Loss_G: 8.3980\n",
            "[240/25][60/69] Loss_D: 0.0033 Loss_G: 7.5022\n",
            "[240/25][61/69] Loss_D: 0.0011 Loss_G: 8.2619\n",
            "[240/25][62/69] Loss_D: 0.0022 Loss_G: 7.7764\n",
            "[240/25][63/69] Loss_D: 0.0024 Loss_G: 8.1636\n",
            "[240/25][64/69] Loss_D: 0.0038 Loss_G: 7.2837\n",
            "[240/25][65/69] Loss_D: 0.0018 Loss_G: 8.3939\n",
            "[240/25][66/69] Loss_D: 0.0037 Loss_G: 8.3603\n",
            "[240/25][67/69] Loss_D: 0.0012 Loss_G: 8.2703\n",
            "[240/25][68/69] Loss_D: 0.0013 Loss_G: 7.8149\n",
            "[241/25][0/69] Loss_D: 0.0374 Loss_G: 7.3490\n",
            "[241/25][1/69] Loss_D: 0.0029 Loss_G: 6.3481\n",
            "[241/25][2/69] Loss_D: 0.0093 Loss_G: 5.5785\n",
            "[241/25][3/69] Loss_D: 0.0064 Loss_G: 6.4697\n",
            "[241/25][4/69] Loss_D: 0.0087 Loss_G: 6.1593\n",
            "[241/25][5/69] Loss_D: 0.0039 Loss_G: 7.1767\n",
            "[241/25][6/69] Loss_D: 0.0034 Loss_G: 7.3521\n",
            "[241/25][7/69] Loss_D: 0.0016 Loss_G: 7.9914\n",
            "[241/25][8/69] Loss_D: 0.0034 Loss_G: 7.5823\n",
            "[241/25][9/69] Loss_D: 0.0018 Loss_G: 8.0332\n",
            "[241/25][10/69] Loss_D: 0.0009 Loss_G: 8.6935\n",
            "[241/25][11/69] Loss_D: 0.0007 Loss_G: 8.9282\n",
            "[241/25][12/69] Loss_D: 0.0009 Loss_G: 8.6969\n",
            "[241/25][13/69] Loss_D: 0.0004 Loss_G: 9.2712\n",
            "[241/25][14/69] Loss_D: 0.0001 Loss_G: 11.1787\n",
            "[241/25][15/69] Loss_D: 0.0004 Loss_G: 9.7038\n",
            "[241/25][16/69] Loss_D: 0.0002 Loss_G: 10.0091\n",
            "[241/25][17/69] Loss_D: 0.0008 Loss_G: 9.8256\n",
            "[241/25][18/69] Loss_D: 0.0005 Loss_G: 9.7247\n",
            "[241/25][19/69] Loss_D: 0.0018 Loss_G: 9.7264\n",
            "[241/25][20/69] Loss_D: 0.0010 Loss_G: 9.1564\n",
            "[241/25][21/69] Loss_D: 0.0006 Loss_G: 8.8205\n",
            "[241/25][22/69] Loss_D: 0.0004 Loss_G: 9.2197\n",
            "[241/25][23/69] Loss_D: 0.0025 Loss_G: 7.5297\n",
            "[241/25][24/69] Loss_D: 0.0011 Loss_G: 8.3447\n",
            "[241/25][25/69] Loss_D: 0.0052 Loss_G: 7.7017\n",
            "[241/25][26/69] Loss_D: 0.0033 Loss_G: 7.5391\n",
            "[241/25][27/69] Loss_D: 0.0027 Loss_G: 7.6380\n",
            "[241/25][28/69] Loss_D: 0.0007 Loss_G: 9.1298\n",
            "[241/25][29/69] Loss_D: 0.0039 Loss_G: 7.5956\n",
            "[241/25][30/69] Loss_D: 0.0011 Loss_G: 8.0944\n",
            "[241/25][31/69] Loss_D: 0.0024 Loss_G: 7.9956\n",
            "[241/25][32/69] Loss_D: 0.0072 Loss_G: 7.7208\n",
            "[241/25][33/69] Loss_D: 0.0055 Loss_G: 6.7076\n",
            "[241/25][34/69] Loss_D: 0.0041 Loss_G: 7.8110\n",
            "[241/25][35/69] Loss_D: 0.0056 Loss_G: 6.2493\n",
            "[241/25][36/69] Loss_D: 0.0172 Loss_G: 6.5631\n",
            "[241/25][37/69] Loss_D: 0.0018 Loss_G: 7.3326\n",
            "[241/25][38/69] Loss_D: 0.0030 Loss_G: 6.9994\n",
            "[241/25][39/69] Loss_D: 0.0232 Loss_G: 5.7573\n",
            "[241/25][40/69] Loss_D: 0.0042 Loss_G: 6.2712\n",
            "[241/25][41/69] Loss_D: 0.0041 Loss_G: 6.7944\n",
            "[241/25][42/69] Loss_D: 0.0034 Loss_G: 7.2722\n",
            "[241/25][43/69] Loss_D: 0.0009 Loss_G: 8.2517\n",
            "[241/25][44/69] Loss_D: 0.0039 Loss_G: 7.0744\n",
            "[241/25][45/69] Loss_D: 0.0015 Loss_G: 7.9405\n",
            "[241/25][46/69] Loss_D: 0.0009 Loss_G: 8.9564\n",
            "[241/25][47/69] Loss_D: 0.0022 Loss_G: 7.4715\n",
            "[241/25][48/69] Loss_D: 0.0029 Loss_G: 6.8663\n",
            "[241/25][49/69] Loss_D: 0.0008 Loss_G: 8.0820\n",
            "[241/25][50/69] Loss_D: 0.0013 Loss_G: 8.3612\n",
            "[241/25][51/69] Loss_D: 0.0012 Loss_G: 7.6284\n",
            "[241/25][52/69] Loss_D: 0.0020 Loss_G: 7.1395\n",
            "[241/25][53/69] Loss_D: 0.0023 Loss_G: 7.4271\n",
            "[241/25][54/69] Loss_D: 0.0014 Loss_G: 7.4633\n",
            "[241/25][55/69] Loss_D: 0.0007 Loss_G: 8.5632\n",
            "[241/25][56/69] Loss_D: 0.0687 Loss_G: 6.6862\n",
            "[241/25][57/69] Loss_D: 0.0213 Loss_G: 5.4419\n",
            "[241/25][58/69] Loss_D: 0.0342 Loss_G: 4.6018\n",
            "[241/25][59/69] Loss_D: 0.0158 Loss_G: 5.6336\n",
            "[241/25][60/69] Loss_D: 0.0037 Loss_G: 6.9029\n",
            "[241/25][61/69] Loss_D: 0.0055 Loss_G: 6.6273\n",
            "[241/25][62/69] Loss_D: 0.0033 Loss_G: 7.5952\n",
            "[241/25][63/69] Loss_D: 0.0016 Loss_G: 8.2018\n",
            "[241/25][64/69] Loss_D: 0.0015 Loss_G: 8.1908\n",
            "[241/25][65/69] Loss_D: 0.0001 Loss_G: 10.7737\n",
            "[241/25][66/69] Loss_D: 0.0005 Loss_G: 9.1261\n",
            "[241/25][67/69] Loss_D: 0.0004 Loss_G: 9.6004\n",
            "[241/25][68/69] Loss_D: 0.0000 Loss_G: 11.3595\n",
            "[242/25][0/69] Loss_D: 0.0002 Loss_G: 9.7229\n",
            "[242/25][1/69] Loss_D: 0.0003 Loss_G: 9.1385\n",
            "[242/25][2/69] Loss_D: 0.0001 Loss_G: 9.9445\n",
            "[242/25][3/69] Loss_D: 0.0004 Loss_G: 9.2570\n",
            "[242/25][4/69] Loss_D: 0.0003 Loss_G: 8.9557\n",
            "[242/25][5/69] Loss_D: 0.0003 Loss_G: 8.8037\n",
            "[242/25][6/69] Loss_D: 0.0001 Loss_G: 10.1184\n",
            "[242/25][7/69] Loss_D: 0.0005 Loss_G: 8.4848\n",
            "[242/25][8/69] Loss_D: 0.0003 Loss_G: 9.3363\n",
            "[242/25][9/69] Loss_D: 0.0020 Loss_G: 7.0408\n",
            "[242/25][10/69] Loss_D: 0.0010 Loss_G: 7.7691\n",
            "[242/25][11/69] Loss_D: 0.0007 Loss_G: 8.3750\n",
            "[242/25][12/69] Loss_D: 0.0008 Loss_G: 8.2858\n",
            "[242/25][13/69] Loss_D: 0.0024 Loss_G: 7.1040\n",
            "[242/25][14/69] Loss_D: 0.0038 Loss_G: 6.5519\n",
            "[242/25][15/69] Loss_D: 0.0012 Loss_G: 8.0400\n",
            "[242/25][16/69] Loss_D: 0.0018 Loss_G: 7.3250\n",
            "[242/25][17/69] Loss_D: 0.0018 Loss_G: 7.5467\n",
            "[242/25][18/69] Loss_D: 0.0014 Loss_G: 7.6523\n",
            "[242/25][19/69] Loss_D: 0.0016 Loss_G: 7.3960\n",
            "[242/25][20/69] Loss_D: 0.0017 Loss_G: 7.4024\n",
            "[242/25][21/69] Loss_D: 0.0097 Loss_G: 7.1574\n",
            "[242/25][22/69] Loss_D: 0.0018 Loss_G: 7.0018\n",
            "[242/25][23/69] Loss_D: 0.0023 Loss_G: 7.1313\n",
            "[242/25][24/69] Loss_D: 0.0018 Loss_G: 7.1851\n",
            "[242/25][25/69] Loss_D: 0.0020 Loss_G: 7.2367\n",
            "[242/25][26/69] Loss_D: 0.0040 Loss_G: 7.3279\n",
            "[242/25][27/69] Loss_D: 0.0057 Loss_G: 6.2110\n",
            "[242/25][28/69] Loss_D: 0.0017 Loss_G: 7.5923\n",
            "[242/25][29/69] Loss_D: 0.0007 Loss_G: 8.3985\n",
            "[242/25][30/69] Loss_D: 0.0021 Loss_G: 8.4220\n",
            "[242/25][31/69] Loss_D: 0.0033 Loss_G: 6.8306\n",
            "[242/25][32/69] Loss_D: 0.0018 Loss_G: 8.7635\n",
            "[242/25][33/69] Loss_D: 0.0030 Loss_G: 7.4643\n",
            "[242/25][34/69] Loss_D: 0.0003 Loss_G: 9.2901\n",
            "[242/25][35/69] Loss_D: 0.0009 Loss_G: 7.8331\n",
            "[242/25][36/69] Loss_D: 0.0033 Loss_G: 6.9094\n",
            "[242/25][37/69] Loss_D: 0.0007 Loss_G: 8.5436\n",
            "[242/25][38/69] Loss_D: 0.0078 Loss_G: 7.3762\n",
            "[242/25][39/69] Loss_D: 0.0010 Loss_G: 8.2129\n",
            "[242/25][40/69] Loss_D: 0.0026 Loss_G: 7.1699\n",
            "[242/25][41/69] Loss_D: 0.0031 Loss_G: 7.3581\n",
            "[242/25][42/69] Loss_D: 0.0086 Loss_G: 7.3782\n",
            "[242/25][43/69] Loss_D: 0.0032 Loss_G: 7.2995\n",
            "[242/25][44/69] Loss_D: 0.0065 Loss_G: 6.2250\n",
            "[242/25][45/69] Loss_D: 0.0031 Loss_G: 6.8793\n",
            "[242/25][46/69] Loss_D: 0.0035 Loss_G: 6.6747\n",
            "[242/25][47/69] Loss_D: 0.0132 Loss_G: 5.8856\n",
            "[242/25][48/69] Loss_D: 0.0039 Loss_G: 7.4242\n",
            "[242/25][49/69] Loss_D: 0.0163 Loss_G: 6.4751\n",
            "[242/25][50/69] Loss_D: 0.0029 Loss_G: 6.5746\n",
            "[242/25][51/69] Loss_D: 0.0016 Loss_G: 7.8288\n",
            "[242/25][52/69] Loss_D: 0.0015 Loss_G: 7.2282\n",
            "[242/25][53/69] Loss_D: 0.0032 Loss_G: 6.4574\n",
            "[242/25][54/69] Loss_D: 0.0004 Loss_G: 9.3174\n",
            "[242/25][55/69] Loss_D: 0.0587 Loss_G: 5.6261\n",
            "[242/25][56/69] Loss_D: 0.0011 Loss_G: 6.9477\n",
            "[242/25][57/69] Loss_D: 0.0075 Loss_G: 5.4192\n",
            "[242/25][58/69] Loss_D: 0.0241 Loss_G: 5.4991\n",
            "[242/25][59/69] Loss_D: 0.0086 Loss_G: 6.6200\n",
            "[242/25][60/69] Loss_D: 0.0029 Loss_G: 7.3387\n",
            "[242/25][61/69] Loss_D: 0.0007 Loss_G: 8.6252\n",
            "[242/25][62/69] Loss_D: 0.0012 Loss_G: 8.0695\n",
            "[242/25][63/69] Loss_D: 0.0011 Loss_G: 9.2352\n",
            "[242/25][64/69] Loss_D: 0.0006 Loss_G: 8.5547\n",
            "[242/25][65/69] Loss_D: 0.0004 Loss_G: 9.2208\n",
            "[242/25][66/69] Loss_D: 0.0004 Loss_G: 9.1360\n",
            "[242/25][67/69] Loss_D: 0.0003 Loss_G: 10.3474\n",
            "[242/25][68/69] Loss_D: 0.0002 Loss_G: 11.0215\n",
            "[243/25][0/69] Loss_D: 0.0095 Loss_G: 9.8188\n",
            "[243/25][1/69] Loss_D: 0.0027 Loss_G: 10.0766\n",
            "[243/25][2/69] Loss_D: 0.0012 Loss_G: 9.0256\n",
            "[243/25][3/69] Loss_D: 0.0019 Loss_G: 8.3711\n",
            "[243/25][4/69] Loss_D: 0.0009 Loss_G: 8.8975\n",
            "[243/25][5/69] Loss_D: 0.0021 Loss_G: 7.8583\n",
            "[243/25][6/69] Loss_D: 0.0021 Loss_G: 8.4264\n",
            "[243/25][7/69] Loss_D: 0.0018 Loss_G: 7.6887\n",
            "[243/25][8/69] Loss_D: 0.0018 Loss_G: 8.1305\n",
            "[243/25][9/69] Loss_D: 0.0013 Loss_G: 8.0526\n",
            "[243/25][10/69] Loss_D: 0.0007 Loss_G: 8.1283\n",
            "[243/25][11/69] Loss_D: 0.0005 Loss_G: 8.4306\n",
            "[243/25][12/69] Loss_D: 0.0010 Loss_G: 7.6228\n",
            "[243/25][13/69] Loss_D: 0.0013 Loss_G: 7.3308\n",
            "[243/25][14/69] Loss_D: 0.0006 Loss_G: 8.1356\n",
            "[243/25][15/69] Loss_D: 0.0031 Loss_G: 6.6879\n",
            "[243/25][16/69] Loss_D: 0.0011 Loss_G: 7.4974\n",
            "[243/25][17/69] Loss_D: 0.0025 Loss_G: 7.5437\n",
            "[243/25][18/69] Loss_D: 0.0024 Loss_G: 7.3334\n",
            "[243/25][19/69] Loss_D: 0.0023 Loss_G: 7.7484\n",
            "[243/25][20/69] Loss_D: 0.0014 Loss_G: 7.4545\n",
            "[243/25][21/69] Loss_D: 0.0019 Loss_G: 7.3473\n",
            "[243/25][22/69] Loss_D: 0.0017 Loss_G: 7.3966\n",
            "[243/25][23/69] Loss_D: 0.0030 Loss_G: 7.9048\n",
            "[243/25][24/69] Loss_D: 0.0003 Loss_G: 9.1545\n",
            "[243/25][25/69] Loss_D: 0.0014 Loss_G: 7.3367\n",
            "[243/25][26/69] Loss_D: 0.0006 Loss_G: 8.3097\n",
            "[243/25][27/69] Loss_D: 0.0041 Loss_G: 7.2011\n",
            "[243/25][28/69] Loss_D: 0.0056 Loss_G: 7.1579\n",
            "[243/25][29/69] Loss_D: 0.0050 Loss_G: 7.1078\n",
            "[243/25][30/69] Loss_D: 0.0010 Loss_G: 7.5408\n",
            "[243/25][31/69] Loss_D: 0.0009 Loss_G: 7.4392\n",
            "[243/25][32/69] Loss_D: 0.0017 Loss_G: 7.1764\n",
            "[243/25][33/69] Loss_D: 0.0043 Loss_G: 6.1080\n",
            "[243/25][34/69] Loss_D: 0.0051 Loss_G: 6.0932\n",
            "[243/25][35/69] Loss_D: 0.0032 Loss_G: 6.6182\n",
            "[243/25][36/69] Loss_D: 0.0051 Loss_G: 7.7395\n",
            "[243/25][37/69] Loss_D: 0.0011 Loss_G: 7.7044\n",
            "[243/25][38/69] Loss_D: 0.0019 Loss_G: 7.4774\n",
            "[243/25][39/69] Loss_D: 0.0030 Loss_G: 7.7989\n",
            "[243/25][40/69] Loss_D: 0.0031 Loss_G: 9.0603\n",
            "[243/25][41/69] Loss_D: 0.0012 Loss_G: 7.4449\n",
            "[243/25][42/69] Loss_D: 0.0008 Loss_G: 8.0957\n",
            "[243/25][43/69] Loss_D: 0.0015 Loss_G: 7.2895\n",
            "[243/25][44/69] Loss_D: 0.0016 Loss_G: 7.1884\n",
            "[243/25][45/69] Loss_D: 0.0017 Loss_G: 7.9383\n",
            "[243/25][46/69] Loss_D: 0.0019 Loss_G: 7.5480\n",
            "[243/25][47/69] Loss_D: 0.0017 Loss_G: 7.4800\n",
            "[243/25][48/69] Loss_D: 0.0060 Loss_G: 7.4051\n",
            "[243/25][49/69] Loss_D: 0.0077 Loss_G: 6.8046\n",
            "[243/25][50/69] Loss_D: 0.0013 Loss_G: 7.5205\n",
            "[243/25][51/69] Loss_D: 0.0014 Loss_G: 7.3501\n",
            "[243/25][52/69] Loss_D: 0.0015 Loss_G: 7.0510\n",
            "[243/25][53/69] Loss_D: 0.0014 Loss_G: 7.3892\n",
            "[243/25][54/69] Loss_D: 0.0047 Loss_G: 6.1559\n",
            "[243/25][55/69] Loss_D: 0.0015 Loss_G: 7.2114\n",
            "[243/25][56/69] Loss_D: 0.0013 Loss_G: 7.6657\n",
            "[243/25][57/69] Loss_D: 0.0021 Loss_G: 7.0948\n",
            "[243/25][58/69] Loss_D: 0.0029 Loss_G: 6.8723\n",
            "[243/25][59/69] Loss_D: 0.0034 Loss_G: 8.1565\n",
            "[243/25][60/69] Loss_D: 0.0013 Loss_G: 7.4451\n",
            "[243/25][61/69] Loss_D: 0.0034 Loss_G: 7.6394\n",
            "[243/25][62/69] Loss_D: 0.0012 Loss_G: 7.8370\n",
            "[243/25][63/69] Loss_D: 0.0009 Loss_G: 7.7282\n",
            "[243/25][64/69] Loss_D: 0.0009 Loss_G: 8.1867\n",
            "[243/25][65/69] Loss_D: 0.0030 Loss_G: 8.6401\n",
            "[243/25][66/69] Loss_D: 0.0021 Loss_G: 7.4735\n",
            "[243/25][67/69] Loss_D: 0.0003 Loss_G: 9.1085\n",
            "[243/25][68/69] Loss_D: 0.0004 Loss_G: 8.6853\n",
            "[244/25][0/69] Loss_D: 0.0015 Loss_G: 7.2442\n",
            "[244/25][1/69] Loss_D: 0.0021 Loss_G: 7.6320\n",
            "[244/25][2/69] Loss_D: 0.0054 Loss_G: 7.9699\n",
            "[244/25][3/69] Loss_D: 0.0029 Loss_G: 7.7825\n",
            "[244/25][4/69] Loss_D: 0.0017 Loss_G: 7.1362\n",
            "[244/25][5/69] Loss_D: 0.0011 Loss_G: 7.4809\n",
            "[244/25][6/69] Loss_D: 0.0029 Loss_G: 6.5750\n",
            "[244/25][7/69] Loss_D: 0.0013 Loss_G: 7.3082\n",
            "[244/25][8/69] Loss_D: 0.0061 Loss_G: 6.0671\n",
            "[244/25][9/69] Loss_D: 0.1518 Loss_G: 3.5976\n",
            "[244/25][10/69] Loss_D: 0.0665 Loss_G: 3.8767\n",
            "[244/25][11/69] Loss_D: 0.0420 Loss_G: 5.7712\n",
            "[244/25][12/69] Loss_D: 0.0046 Loss_G: 7.7837\n",
            "[244/25][13/69] Loss_D: 0.0017 Loss_G: 8.9970\n",
            "[244/25][14/69] Loss_D: 0.0011 Loss_G: 10.7655\n",
            "[244/25][15/69] Loss_D: 0.0002 Loss_G: 11.8832\n",
            "[244/25][16/69] Loss_D: 0.0001 Loss_G: 12.2562\n",
            "[244/25][17/69] Loss_D: 0.0006 Loss_G: 12.5298\n",
            "[244/25][18/69] Loss_D: 0.0011 Loss_G: 14.4054\n",
            "[244/25][19/69] Loss_D: 0.0009 Loss_G: 14.6573\n",
            "[244/25][20/69] Loss_D: 0.0005 Loss_G: 13.5980\n",
            "[244/25][21/69] Loss_D: 0.0001 Loss_G: 14.9708\n",
            "[244/25][22/69] Loss_D: 0.0000 Loss_G: 14.9080\n",
            "[244/25][23/69] Loss_D: 0.0002 Loss_G: 14.5804\n",
            "[244/25][24/69] Loss_D: 0.0001 Loss_G: 13.5225\n",
            "[244/25][25/69] Loss_D: 0.0035 Loss_G: 12.9443\n",
            "[244/25][26/69] Loss_D: 0.0048 Loss_G: 12.6518\n",
            "[244/25][27/69] Loss_D: 0.0000 Loss_G: 12.4916\n",
            "[244/25][28/69] Loss_D: 0.0028 Loss_G: 11.4329\n",
            "[244/25][29/69] Loss_D: 0.0051 Loss_G: 11.3516\n",
            "[244/25][30/69] Loss_D: 0.0126 Loss_G: 11.2674\n",
            "[244/25][31/69] Loss_D: 0.0036 Loss_G: 11.3294\n",
            "[244/25][32/69] Loss_D: 0.0002 Loss_G: 11.7847\n",
            "[244/25][33/69] Loss_D: 0.0001 Loss_G: 11.3708\n",
            "[244/25][34/69] Loss_D: 0.0046 Loss_G: 10.5790\n",
            "[244/25][35/69] Loss_D: 0.0010 Loss_G: 10.8603\n",
            "[244/25][36/69] Loss_D: 0.0001 Loss_G: 10.3792\n",
            "[244/25][37/69] Loss_D: 0.0003 Loss_G: 10.3897\n",
            "[244/25][38/69] Loss_D: 0.0016 Loss_G: 9.2014\n",
            "[244/25][39/69] Loss_D: 0.0048 Loss_G: 8.1207\n",
            "[244/25][40/69] Loss_D: 0.0056 Loss_G: 8.7578\n",
            "[244/25][41/69] Loss_D: 0.0014 Loss_G: 9.0765\n",
            "[244/25][42/69] Loss_D: 0.0019 Loss_G: 8.4005\n",
            "[244/25][43/69] Loss_D: 0.0017 Loss_G: 8.3806\n",
            "[244/25][44/69] Loss_D: 0.0132 Loss_G: 8.3939\n",
            "[244/25][45/69] Loss_D: 0.0031 Loss_G: 8.6608\n",
            "[244/25][46/69] Loss_D: 0.0014 Loss_G: 7.8054\n",
            "[244/25][47/69] Loss_D: 0.0020 Loss_G: 8.0377\n",
            "[244/25][48/69] Loss_D: 0.0057 Loss_G: 8.0948\n",
            "[244/25][49/69] Loss_D: 0.0033 Loss_G: 7.8448\n",
            "[244/25][50/69] Loss_D: 0.0040 Loss_G: 6.9215\n",
            "[244/25][51/69] Loss_D: 0.0046 Loss_G: 8.3625\n",
            "[244/25][52/69] Loss_D: 0.0014 Loss_G: 7.8119\n",
            "[244/25][53/69] Loss_D: 0.0027 Loss_G: 7.5614\n",
            "[244/25][54/69] Loss_D: 0.0066 Loss_G: 6.4717\n",
            "[244/25][55/69] Loss_D: 0.0029 Loss_G: 7.8550\n",
            "[244/25][56/69] Loss_D: 0.0018 Loss_G: 7.8965\n",
            "[244/25][57/69] Loss_D: 0.0041 Loss_G: 7.7136\n",
            "[244/25][58/69] Loss_D: 0.0011 Loss_G: 8.6351\n",
            "[244/25][59/69] Loss_D: 0.0004 Loss_G: 9.5864\n",
            "[244/25][60/69] Loss_D: 0.0096 Loss_G: 7.7301\n",
            "[244/25][61/69] Loss_D: 0.0012 Loss_G: 8.3004\n",
            "[244/25][62/69] Loss_D: 0.0012 Loss_G: 9.0486\n",
            "[244/25][63/69] Loss_D: 0.0018 Loss_G: 7.3828\n",
            "[244/25][64/69] Loss_D: 0.0044 Loss_G: 7.2782\n",
            "[244/25][65/69] Loss_D: 0.0006 Loss_G: 8.7908\n",
            "[244/25][66/69] Loss_D: 0.0013 Loss_G: 7.9077\n",
            "[244/25][67/69] Loss_D: 0.0058 Loss_G: 6.4835\n",
            "[244/25][68/69] Loss_D: 0.0008 Loss_G: 8.9342\n",
            "[245/25][0/69] Loss_D: 0.0021 Loss_G: 8.2875\n",
            "[245/25][1/69] Loss_D: 0.0020 Loss_G: 9.4870\n",
            "[245/25][2/69] Loss_D: 0.0006 Loss_G: 8.7402\n",
            "[245/25][3/69] Loss_D: 0.0026 Loss_G: 7.9719\n",
            "[245/25][4/69] Loss_D: 0.0011 Loss_G: 9.8599\n",
            "[245/25][5/69] Loss_D: 0.0175 Loss_G: 7.6537\n",
            "[245/25][6/69] Loss_D: 0.0014 Loss_G: 7.8571\n",
            "[245/25][7/69] Loss_D: 0.0033 Loss_G: 6.3015\n",
            "[245/25][8/69] Loss_D: 0.0807 Loss_G: 5.1222\n",
            "[245/25][9/69] Loss_D: 0.0123 Loss_G: 4.2324\n",
            "[245/25][10/69] Loss_D: 0.0281 Loss_G: 4.7694\n",
            "[245/25][11/69] Loss_D: 0.0451 Loss_G: 6.3105\n",
            "[245/25][12/69] Loss_D: 0.0053 Loss_G: 8.6688\n",
            "[245/25][13/69] Loss_D: 0.0014 Loss_G: 9.4180\n",
            "[245/25][14/69] Loss_D: 0.0002 Loss_G: 11.3818\n",
            "[245/25][15/69] Loss_D: 0.0134 Loss_G: 12.7398\n",
            "[245/25][16/69] Loss_D: 0.0003 Loss_G: 13.8920\n",
            "[245/25][17/69] Loss_D: 0.0001 Loss_G: 14.2580\n",
            "[245/25][18/69] Loss_D: 0.0004 Loss_G: 14.9342\n",
            "[245/25][19/69] Loss_D: 0.0007 Loss_G: 16.2900\n",
            "[245/25][20/69] Loss_D: 0.0002 Loss_G: 17.1157\n",
            "[245/25][21/69] Loss_D: 0.0004 Loss_G: 16.2023\n",
            "[245/25][22/69] Loss_D: 0.0442 Loss_G: 14.6110\n",
            "[245/25][23/69] Loss_D: 0.0009 Loss_G: 13.8138\n",
            "[245/25][24/69] Loss_D: 0.0006 Loss_G: 12.6722\n",
            "[245/25][25/69] Loss_D: 0.0006 Loss_G: 10.6911\n",
            "[245/25][26/69] Loss_D: 0.0004 Loss_G: 11.0947\n",
            "[245/25][27/69] Loss_D: 0.0007 Loss_G: 10.3605\n",
            "[245/25][28/69] Loss_D: 0.0192 Loss_G: 8.8997\n",
            "[245/25][29/69] Loss_D: 0.0020 Loss_G: 8.9494\n",
            "[245/25][30/69] Loss_D: 0.0008 Loss_G: 9.3167\n",
            "[245/25][31/69] Loss_D: 0.0026 Loss_G: 8.8953\n",
            "[245/25][32/69] Loss_D: 0.0019 Loss_G: 9.7194\n",
            "[245/25][33/69] Loss_D: 0.0008 Loss_G: 9.7182\n",
            "[245/25][34/69] Loss_D: 0.0001 Loss_G: 11.5835\n",
            "[245/25][35/69] Loss_D: 0.0005 Loss_G: 10.0885\n",
            "[245/25][36/69] Loss_D: 0.0005 Loss_G: 10.4858\n",
            "[245/25][37/69] Loss_D: 0.0028 Loss_G: 9.1681\n",
            "[245/25][38/69] Loss_D: 0.0070 Loss_G: 10.0267\n",
            "[245/25][39/69] Loss_D: 0.0135 Loss_G: 9.5794\n",
            "[245/25][40/69] Loss_D: 0.0009 Loss_G: 10.4705\n",
            "[245/25][41/69] Loss_D: 0.0030 Loss_G: 7.8273\n",
            "[245/25][42/69] Loss_D: 0.0033 Loss_G: 7.6426\n",
            "[245/25][43/69] Loss_D: 0.0017 Loss_G: 8.1131\n",
            "[245/25][44/69] Loss_D: 0.0011 Loss_G: 8.2397\n",
            "[245/25][45/69] Loss_D: 0.0022 Loss_G: 8.3558\n",
            "[245/25][46/69] Loss_D: 0.0018 Loss_G: 7.3182\n",
            "[245/25][47/69] Loss_D: 0.0009 Loss_G: 8.2937\n",
            "[245/25][48/69] Loss_D: 0.0007 Loss_G: 8.5055\n",
            "[245/25][49/69] Loss_D: 0.0008 Loss_G: 8.1883\n",
            "[245/25][50/69] Loss_D: 0.0010 Loss_G: 8.4609\n",
            "[245/25][51/69] Loss_D: 0.0009 Loss_G: 8.2761\n",
            "[245/25][52/69] Loss_D: 0.0004 Loss_G: 9.0717\n",
            "[245/25][53/69] Loss_D: 0.0014 Loss_G: 7.6407\n",
            "[245/25][54/69] Loss_D: 0.0004 Loss_G: 8.7691\n",
            "[245/25][55/69] Loss_D: 0.0009 Loss_G: 8.8750\n",
            "[245/25][56/69] Loss_D: 0.0006 Loss_G: 8.8686\n",
            "[245/25][57/69] Loss_D: 0.0034 Loss_G: 7.8976\n",
            "[245/25][58/69] Loss_D: 0.0026 Loss_G: 7.8887\n",
            "[245/25][59/69] Loss_D: 0.0005 Loss_G: 8.4130\n",
            "[245/25][60/69] Loss_D: 0.0026 Loss_G: 6.9141\n",
            "[245/25][61/69] Loss_D: 0.0026 Loss_G: 7.8967\n",
            "[245/25][62/69] Loss_D: 0.0005 Loss_G: 8.5921\n",
            "[245/25][63/69] Loss_D: 0.0026 Loss_G: 7.1491\n",
            "[245/25][64/69] Loss_D: 0.0012 Loss_G: 7.9904\n",
            "[245/25][65/69] Loss_D: 0.0027 Loss_G: 6.9410\n",
            "[245/25][66/69] Loss_D: 0.0033 Loss_G: 6.8383\n",
            "[245/25][67/69] Loss_D: 0.0048 Loss_G: 7.1013\n",
            "[245/25][68/69] Loss_D: 0.0043 Loss_G: 6.4041\n",
            "[246/25][0/69] Loss_D: 0.0010 Loss_G: 8.1440\n",
            "[246/25][1/69] Loss_D: 0.0028 Loss_G: 7.2814\n",
            "[246/25][2/69] Loss_D: 0.0038 Loss_G: 7.0776\n",
            "[246/25][3/69] Loss_D: 0.0031 Loss_G: 7.3575\n",
            "[246/25][4/69] Loss_D: 0.0016 Loss_G: 7.9508\n",
            "[246/25][5/69] Loss_D: 0.1164 Loss_G: 6.0685\n",
            "[246/25][6/69] Loss_D: 0.0087 Loss_G: 3.7420\n",
            "[246/25][7/69] Loss_D: 0.0427 Loss_G: 4.0568\n",
            "[246/25][8/69] Loss_D: 0.0611 Loss_G: 5.9018\n",
            "[246/25][9/69] Loss_D: 0.0088 Loss_G: 8.2538\n",
            "[246/25][10/69] Loss_D: 0.0004 Loss_G: 11.8262\n",
            "[246/25][11/69] Loss_D: 0.0737 Loss_G: 8.4176\n",
            "[246/25][12/69] Loss_D: 0.0004 Loss_G: 9.4805\n",
            "[246/25][13/69] Loss_D: 0.0009 Loss_G: 8.9394\n",
            "[246/25][14/69] Loss_D: 0.0024 Loss_G: 7.5338\n",
            "[246/25][15/69] Loss_D: 0.0019 Loss_G: 7.6195\n",
            "[246/25][16/69] Loss_D: 0.0024 Loss_G: 7.5529\n",
            "[246/25][17/69] Loss_D: 0.0121 Loss_G: 7.0457\n",
            "[246/25][18/69] Loss_D: 0.0043 Loss_G: 7.2451\n",
            "[246/25][19/69] Loss_D: 0.0002 Loss_G: 10.9131\n",
            "[246/25][20/69] Loss_D: 0.0103 Loss_G: 10.1991\n",
            "[246/25][21/69] Loss_D: 0.0008 Loss_G: 9.0149\n",
            "[246/25][22/69] Loss_D: 0.0030 Loss_G: 9.1692\n",
            "[246/25][23/69] Loss_D: 0.0020 Loss_G: 7.3178\n",
            "[246/25][24/69] Loss_D: 0.0012 Loss_G: 7.7294\n",
            "[246/25][25/69] Loss_D: 0.0193 Loss_G: 6.6750\n",
            "[246/25][26/69] Loss_D: 0.0024 Loss_G: 7.2938\n",
            "[246/25][27/69] Loss_D: 0.0010 Loss_G: 8.3069\n",
            "[246/25][28/69] Loss_D: 0.0065 Loss_G: 6.9200\n",
            "[246/25][29/69] Loss_D: 0.0005 Loss_G: 9.5688\n",
            "[246/25][30/69] Loss_D: 0.0035 Loss_G: 7.8604\n",
            "[246/25][31/69] Loss_D: 0.0017 Loss_G: 8.8201\n",
            "[246/25][32/69] Loss_D: 0.0071 Loss_G: 6.7897\n",
            "[246/25][33/69] Loss_D: 0.0023 Loss_G: 8.6482\n",
            "[246/25][34/69] Loss_D: 0.0021 Loss_G: 8.5525\n",
            "[246/25][35/69] Loss_D: 0.0017 Loss_G: 8.3163\n",
            "[246/25][36/69] Loss_D: 0.0012 Loss_G: 9.0716\n",
            "[246/25][37/69] Loss_D: 0.0007 Loss_G: 9.2600\n",
            "[246/25][38/69] Loss_D: 0.0270 Loss_G: 9.0109\n",
            "[246/25][39/69] Loss_D: 0.0023 Loss_G: 7.1318\n",
            "[246/25][40/69] Loss_D: 0.0032 Loss_G: 6.5122\n",
            "[246/25][41/69] Loss_D: 0.0021 Loss_G: 6.8992\n",
            "[246/25][42/69] Loss_D: 0.0027 Loss_G: 6.9464\n",
            "[246/25][43/69] Loss_D: 0.0029 Loss_G: 8.3617\n",
            "[246/25][44/69] Loss_D: 0.0017 Loss_G: 7.2080\n",
            "[246/25][45/69] Loss_D: 0.0067 Loss_G: 6.2931\n",
            "[246/25][46/69] Loss_D: 0.0035 Loss_G: 7.2498\n",
            "[246/25][47/69] Loss_D: 0.0013 Loss_G: 8.1978\n",
            "[246/25][48/69] Loss_D: 0.0031 Loss_G: 10.1358\n",
            "[246/25][49/69] Loss_D: 0.0003 Loss_G: 9.7732\n",
            "[246/25][50/69] Loss_D: 0.0114 Loss_G: 7.1582\n",
            "[246/25][51/69] Loss_D: 0.0069 Loss_G: 8.1341\n",
            "[246/25][52/69] Loss_D: 0.0036 Loss_G: 6.7180\n",
            "[246/25][53/69] Loss_D: 0.0037 Loss_G: 6.4549\n",
            "[246/25][54/69] Loss_D: 0.0047 Loss_G: 6.8130\n",
            "[246/25][55/69] Loss_D: 0.0045 Loss_G: 7.0218\n",
            "[246/25][56/69] Loss_D: 0.0046 Loss_G: 6.6100\n",
            "[246/25][57/69] Loss_D: 0.0023 Loss_G: 8.5089\n",
            "[246/25][58/69] Loss_D: 0.0021 Loss_G: 7.6049\n",
            "[246/25][59/69] Loss_D: 0.0125 Loss_G: 7.8843\n",
            "[246/25][60/69] Loss_D: 0.0014 Loss_G: 7.4547\n",
            "[246/25][61/69] Loss_D: 0.0012 Loss_G: 7.4716\n",
            "[246/25][62/69] Loss_D: 0.0010 Loss_G: 7.6635\n",
            "[246/25][63/69] Loss_D: 0.0011 Loss_G: 8.0629\n",
            "[246/25][64/69] Loss_D: 0.0020 Loss_G: 7.9838\n",
            "[246/25][65/69] Loss_D: 0.0031 Loss_G: 6.9766\n",
            "[246/25][66/69] Loss_D: 0.0028 Loss_G: 7.0741\n",
            "[246/25][67/69] Loss_D: 0.0047 Loss_G: 6.7278\n",
            "[246/25][68/69] Loss_D: 0.0007 Loss_G: 9.1215\n",
            "[247/25][0/69] Loss_D: 0.0017 Loss_G: 7.6906\n",
            "[247/25][1/69] Loss_D: 0.0005 Loss_G: 8.4892\n",
            "[247/25][2/69] Loss_D: 0.0027 Loss_G: 9.2043\n",
            "[247/25][3/69] Loss_D: 0.0013 Loss_G: 9.5822\n",
            "[247/25][4/69] Loss_D: 0.0008 Loss_G: 9.0000\n",
            "[247/25][5/69] Loss_D: 0.0012 Loss_G: 8.4249\n",
            "[247/25][6/69] Loss_D: 0.0027 Loss_G: 7.7534\n",
            "[247/25][7/69] Loss_D: 0.0012 Loss_G: 8.7752\n",
            "[247/25][8/69] Loss_D: 0.0031 Loss_G: 7.3153\n",
            "[247/25][9/69] Loss_D: 0.0018 Loss_G: 7.2722\n",
            "[247/25][10/69] Loss_D: 0.0017 Loss_G: 7.9802\n",
            "[247/25][11/69] Loss_D: 0.0013 Loss_G: 8.3067\n",
            "[247/25][12/69] Loss_D: 0.0022 Loss_G: 7.4113\n",
            "[247/25][13/69] Loss_D: 0.0038 Loss_G: 7.4715\n",
            "[247/25][14/69] Loss_D: 0.0006 Loss_G: 9.5044\n",
            "[247/25][15/69] Loss_D: 0.0023 Loss_G: 7.0189\n",
            "[247/25][16/69] Loss_D: 0.0011 Loss_G: 7.7370\n",
            "[247/25][17/69] Loss_D: 0.0047 Loss_G: 6.7682\n",
            "[247/25][18/69] Loss_D: 0.0257 Loss_G: 8.1786\n",
            "[247/25][19/69] Loss_D: 0.0044 Loss_G: 5.5978\n",
            "[247/25][20/69] Loss_D: 0.0051 Loss_G: 6.2657\n",
            "[247/25][21/69] Loss_D: 0.0107 Loss_G: 5.6028\n",
            "[247/25][22/69] Loss_D: 0.0092 Loss_G: 6.0347\n",
            "[247/25][23/69] Loss_D: 0.0064 Loss_G: 6.3343\n",
            "[247/25][24/69] Loss_D: 0.0009 Loss_G: 8.7479\n",
            "[247/25][25/69] Loss_D: 0.0035 Loss_G: 6.7568\n",
            "[247/25][26/69] Loss_D: 0.0056 Loss_G: 8.5936\n",
            "[247/25][27/69] Loss_D: 0.0003 Loss_G: 9.3666\n",
            "[247/25][28/69] Loss_D: 0.0019 Loss_G: 8.8555\n",
            "[247/25][29/69] Loss_D: 0.0082 Loss_G: 10.1117\n",
            "[247/25][30/69] Loss_D: 0.0009 Loss_G: 8.5775\n",
            "[247/25][31/69] Loss_D: 0.0016 Loss_G: 7.4440\n",
            "[247/25][32/69] Loss_D: 0.0018 Loss_G: 9.0456\n",
            "[247/25][33/69] Loss_D: 0.0327 Loss_G: 6.9979\n",
            "[247/25][34/69] Loss_D: 0.0051 Loss_G: 5.7180\n",
            "[247/25][35/69] Loss_D: 0.0021 Loss_G: 6.3056\n",
            "[247/25][36/69] Loss_D: 0.0069 Loss_G: 5.6471\n",
            "[247/25][37/69] Loss_D: 0.0393 Loss_G: 5.6489\n",
            "[247/25][38/69] Loss_D: 0.0011 Loss_G: 8.6011\n",
            "[247/25][39/69] Loss_D: 0.0016 Loss_G: 8.1800\n",
            "[247/25][40/69] Loss_D: 0.0007 Loss_G: 9.5394\n",
            "[247/25][41/69] Loss_D: 0.0012 Loss_G: 9.0198\n",
            "[247/25][42/69] Loss_D: 0.0003 Loss_G: 13.0333\n",
            "[247/25][43/69] Loss_D: 0.0002 Loss_G: 11.7461\n",
            "[247/25][44/69] Loss_D: 0.0003 Loss_G: 11.2925\n",
            "[247/25][45/69] Loss_D: 0.0018 Loss_G: 12.5252\n",
            "[247/25][46/69] Loss_D: 0.0005 Loss_G: 12.4088\n",
            "[247/25][47/69] Loss_D: 0.0031 Loss_G: 13.2023\n",
            "[247/25][48/69] Loss_D: 0.0004 Loss_G: 15.1655\n",
            "[247/25][49/69] Loss_D: 0.0829 Loss_G: 11.5800\n",
            "[247/25][50/69] Loss_D: 0.0018 Loss_G: 8.5310\n",
            "[247/25][51/69] Loss_D: 0.0011 Loss_G: 8.1693\n",
            "[247/25][52/69] Loss_D: 0.0005 Loss_G: 8.4474\n",
            "[247/25][53/69] Loss_D: 0.0021 Loss_G: 6.5129\n",
            "[247/25][54/69] Loss_D: 0.0155 Loss_G: 5.2803\n",
            "[247/25][55/69] Loss_D: 0.0059 Loss_G: 5.8919\n",
            "[247/25][56/69] Loss_D: 0.0178 Loss_G: 5.4638\n",
            "[247/25][57/69] Loss_D: 0.0139 Loss_G: 6.4223\n",
            "[247/25][58/69] Loss_D: 0.0034 Loss_G: 7.8304\n",
            "[247/25][59/69] Loss_D: 0.0013 Loss_G: 9.1330\n",
            "[247/25][60/69] Loss_D: 0.0004 Loss_G: 9.9379\n",
            "[247/25][61/69] Loss_D: 0.0159 Loss_G: 10.1163\n",
            "[247/25][62/69] Loss_D: 0.0013 Loss_G: 9.3293\n",
            "[247/25][63/69] Loss_D: 0.0056 Loss_G: 10.6508\n",
            "[247/25][64/69] Loss_D: 0.0006 Loss_G: 9.2739\n",
            "[247/25][65/69] Loss_D: 0.0023 Loss_G: 9.1443\n",
            "[247/25][66/69] Loss_D: 0.0056 Loss_G: 8.0803\n",
            "[247/25][67/69] Loss_D: 0.0007 Loss_G: 9.5662\n",
            "[247/25][68/69] Loss_D: 0.0017 Loss_G: 8.8104\n",
            "[248/25][0/69] Loss_D: 0.0013 Loss_G: 8.6608\n",
            "[248/25][1/69] Loss_D: 0.0011 Loss_G: 9.0290\n",
            "[248/25][2/69] Loss_D: 0.0019 Loss_G: 9.0976\n",
            "[248/25][3/69] Loss_D: 0.0028 Loss_G: 8.7846\n",
            "[248/25][4/69] Loss_D: 0.0082 Loss_G: 8.1763\n",
            "[248/25][5/69] Loss_D: 0.0020 Loss_G: 8.5379\n",
            "[248/25][6/69] Loss_D: 0.0019 Loss_G: 7.9576\n",
            "[248/25][7/69] Loss_D: 0.0010 Loss_G: 8.9593\n",
            "[248/25][8/69] Loss_D: 0.0002 Loss_G: 9.8818\n",
            "[248/25][9/69] Loss_D: 0.0016 Loss_G: 7.7482\n",
            "[248/25][10/69] Loss_D: 0.0023 Loss_G: 9.0669\n",
            "[248/25][11/69] Loss_D: 0.0012 Loss_G: 8.4753\n",
            "[248/25][12/69] Loss_D: 0.0025 Loss_G: 7.2687\n",
            "[248/25][13/69] Loss_D: 0.0045 Loss_G: 7.8608\n",
            "[248/25][14/69] Loss_D: 0.0083 Loss_G: 7.5639\n",
            "[248/25][15/69] Loss_D: 0.0011 Loss_G: 7.7452\n",
            "[248/25][16/69] Loss_D: 0.0008 Loss_G: 8.2175\n",
            "[248/25][17/69] Loss_D: 0.0041 Loss_G: 6.8120\n",
            "[248/25][18/69] Loss_D: 0.0012 Loss_G: 8.1029\n",
            "[248/25][19/69] Loss_D: 0.0005 Loss_G: 8.7877\n",
            "[248/25][20/69] Loss_D: 0.0059 Loss_G: 7.7605\n",
            "[248/25][21/69] Loss_D: 0.0005 Loss_G: 9.0122\n",
            "[248/25][22/69] Loss_D: 0.0021 Loss_G: 7.3018\n",
            "[248/25][23/69] Loss_D: 0.0045 Loss_G: 7.6397\n",
            "[248/25][24/69] Loss_D: 0.0018 Loss_G: 7.1443\n",
            "[248/25][25/69] Loss_D: 0.0015 Loss_G: 7.8531\n",
            "[248/25][26/69] Loss_D: 0.0013 Loss_G: 7.7788\n",
            "[248/25][27/69] Loss_D: 0.0077 Loss_G: 6.7530\n",
            "[248/25][28/69] Loss_D: 0.0022 Loss_G: 7.2735\n",
            "[248/25][29/69] Loss_D: 0.0006 Loss_G: 8.9944\n",
            "[248/25][30/69] Loss_D: 0.0010 Loss_G: 8.4220\n",
            "[248/25][31/69] Loss_D: 0.0010 Loss_G: 8.4848\n",
            "[248/25][32/69] Loss_D: 0.0010 Loss_G: 8.3368\n",
            "[248/25][33/69] Loss_D: 0.0012 Loss_G: 8.9431\n",
            "[248/25][34/69] Loss_D: 0.0002 Loss_G: 9.6398\n",
            "[248/25][35/69] Loss_D: 0.0004 Loss_G: 9.3288\n",
            "[248/25][36/69] Loss_D: 0.0002 Loss_G: 9.7992\n",
            "[248/25][37/69] Loss_D: 0.0008 Loss_G: 8.0060\n",
            "[248/25][38/69] Loss_D: 0.0012 Loss_G: 8.8280\n",
            "[248/25][39/69] Loss_D: 0.0051 Loss_G: 9.5785\n",
            "[248/25][40/69] Loss_D: 0.0025 Loss_G: 9.8160\n",
            "[248/25][41/69] Loss_D: 0.0007 Loss_G: 8.9591\n",
            "[248/25][42/69] Loss_D: 0.0004 Loss_G: 8.6709\n",
            "[248/25][43/69] Loss_D: 0.0006 Loss_G: 9.6342\n",
            "[248/25][44/69] Loss_D: 0.0007 Loss_G: 8.2779\n",
            "[248/25][45/69] Loss_D: 0.0011 Loss_G: 7.6986\n",
            "[248/25][46/69] Loss_D: 0.0017 Loss_G: 7.2690\n",
            "[248/25][47/69] Loss_D: 0.0041 Loss_G: 6.9548\n",
            "[248/25][48/69] Loss_D: 0.0009 Loss_G: 8.2296\n",
            "[248/25][49/69] Loss_D: 0.0028 Loss_G: 6.6500\n",
            "[248/25][50/69] Loss_D: 0.0014 Loss_G: 7.6047\n",
            "[248/25][51/69] Loss_D: 0.0014 Loss_G: 8.0810\n",
            "[248/25][52/69] Loss_D: 0.0483 Loss_G: 6.7063\n",
            "[248/25][53/69] Loss_D: 0.0042 Loss_G: 5.5421\n",
            "[248/25][54/69] Loss_D: 0.0033 Loss_G: 5.8642\n",
            "[248/25][55/69] Loss_D: 0.0450 Loss_G: 4.9932\n",
            "[248/25][56/69] Loss_D: 0.0023 Loss_G: 8.0276\n",
            "[248/25][57/69] Loss_D: 0.0019 Loss_G: 8.4041\n",
            "[248/25][58/69] Loss_D: 0.0046 Loss_G: 9.6837\n",
            "[248/25][59/69] Loss_D: 0.0001 Loss_G: 10.8517\n",
            "[248/25][60/69] Loss_D: 0.0012 Loss_G: 10.1053\n",
            "[248/25][61/69] Loss_D: 0.0006 Loss_G: 9.8348\n",
            "[248/25][62/69] Loss_D: 0.0011 Loss_G: 11.5111\n",
            "[248/25][63/69] Loss_D: 0.0007 Loss_G: 12.4514\n",
            "[248/25][64/69] Loss_D: 0.0020 Loss_G: 12.1109\n",
            "[248/25][65/69] Loss_D: 0.0100 Loss_G: 10.6510\n",
            "[248/25][66/69] Loss_D: 0.0043 Loss_G: 11.3207\n",
            "[248/25][67/69] Loss_D: 0.0005 Loss_G: 10.3150\n",
            "[248/25][68/69] Loss_D: 0.0004 Loss_G: 9.1575\n",
            "[249/25][0/69] Loss_D: 0.0031 Loss_G: 10.5787\n",
            "[249/25][1/69] Loss_D: 0.0004 Loss_G: 9.9000\n",
            "[249/25][2/69] Loss_D: 0.0003 Loss_G: 10.2370\n",
            "[249/25][3/69] Loss_D: 0.0051 Loss_G: 8.4240\n",
            "[249/25][4/69] Loss_D: 0.0029 Loss_G: 9.4559\n",
            "[249/25][5/69] Loss_D: 0.0014 Loss_G: 8.0247\n",
            "[249/25][6/69] Loss_D: 0.0035 Loss_G: 7.0848\n",
            "[249/25][7/69] Loss_D: 0.0054 Loss_G: 6.6460\n",
            "[249/25][8/69] Loss_D: 0.0011 Loss_G: 9.4454\n",
            "[249/25][9/69] Loss_D: 0.0020 Loss_G: 7.8634\n",
            "[249/25][10/69] Loss_D: 0.0014 Loss_G: 7.9594\n",
            "[249/25][11/69] Loss_D: 0.0021 Loss_G: 7.6228\n",
            "[249/25][12/69] Loss_D: 0.0016 Loss_G: 7.8275\n",
            "[249/25][13/69] Loss_D: 0.0026 Loss_G: 7.4118\n",
            "[249/25][14/69] Loss_D: 0.0015 Loss_G: 7.9878\n",
            "[249/25][15/69] Loss_D: 0.0005 Loss_G: 9.2381\n",
            "[249/25][16/69] Loss_D: 0.0008 Loss_G: 8.3857\n",
            "[249/25][17/69] Loss_D: 0.0005 Loss_G: 8.6314\n",
            "[249/25][18/69] Loss_D: 0.0017 Loss_G: 7.8927\n",
            "[249/25][19/69] Loss_D: 0.0016 Loss_G: 8.9053\n",
            "[249/25][20/69] Loss_D: 0.0021 Loss_G: 10.1965\n",
            "[249/25][21/69] Loss_D: 0.0010 Loss_G: 8.6967\n",
            "[249/25][22/69] Loss_D: 0.0008 Loss_G: 8.9122\n",
            "[249/25][23/69] Loss_D: 0.0016 Loss_G: 7.9745\n",
            "[249/25][24/69] Loss_D: 0.0008 Loss_G: 8.5278\n",
            "[249/25][25/69] Loss_D: 0.0008 Loss_G: 8.2458\n",
            "[249/25][26/69] Loss_D: 0.0005 Loss_G: 8.3309\n",
            "[249/25][27/69] Loss_D: 0.0023 Loss_G: 8.5096\n",
            "[249/25][28/69] Loss_D: 0.0041 Loss_G: 6.9745\n",
            "[249/25][29/69] Loss_D: 0.0008 Loss_G: 8.3904\n",
            "[249/25][30/69] Loss_D: 0.0011 Loss_G: 8.7488\n",
            "[249/25][31/69] Loss_D: 0.0007 Loss_G: 8.6707\n",
            "[249/25][32/69] Loss_D: 0.0019 Loss_G: 7.5969\n",
            "[249/25][33/69] Loss_D: 0.0027 Loss_G: 9.0729\n",
            "[249/25][34/69] Loss_D: 0.0009 Loss_G: 8.7722\n",
            "[249/25][35/69] Loss_D: 0.0012 Loss_G: 8.9292\n",
            "[249/25][36/69] Loss_D: 0.0003 Loss_G: 9.1019\n",
            "[249/25][37/69] Loss_D: 0.0060 Loss_G: 7.2972\n",
            "[249/25][38/69] Loss_D: 0.0015 Loss_G: 8.1185\n",
            "[249/25][39/69] Loss_D: 0.0064 Loss_G: 8.2884\n",
            "[249/25][40/69] Loss_D: 0.0013 Loss_G: 7.9274\n",
            "[249/25][41/69] Loss_D: 0.0008 Loss_G: 7.9000\n",
            "[249/25][42/69] Loss_D: 0.0036 Loss_G: 8.4502\n",
            "[249/25][43/69] Loss_D: 0.0051 Loss_G: 7.2343\n",
            "[249/25][44/69] Loss_D: 0.0029 Loss_G: 6.9363\n",
            "[249/25][45/69] Loss_D: 0.0034 Loss_G: 7.2436\n",
            "[249/25][46/69] Loss_D: 0.0022 Loss_G: 8.9685\n",
            "[249/25][47/69] Loss_D: 0.0086 Loss_G: 6.1165\n",
            "[249/25][48/69] Loss_D: 0.0051 Loss_G: 6.9092\n",
            "[249/25][49/69] Loss_D: 0.0029 Loss_G: 7.5368\n",
            "[249/25][50/69] Loss_D: 0.0016 Loss_G: 8.3087\n",
            "[249/25][51/69] Loss_D: 0.0075 Loss_G: 8.0456\n",
            "[249/25][52/69] Loss_D: 0.0010 Loss_G: 8.5229\n",
            "[249/25][53/69] Loss_D: 0.0065 Loss_G: 8.7445\n",
            "[249/25][54/69] Loss_D: 0.0190 Loss_G: 8.2694\n",
            "[249/25][55/69] Loss_D: 0.0025 Loss_G: 6.5162\n",
            "[249/25][56/69] Loss_D: 0.0025 Loss_G: 6.4214\n",
            "[249/25][57/69] Loss_D: 0.0019 Loss_G: 7.3208\n",
            "[249/25][58/69] Loss_D: 0.0066 Loss_G: 6.0710\n",
            "[249/25][59/69] Loss_D: 0.0049 Loss_G: 6.3737\n",
            "[249/25][60/69] Loss_D: 0.0034 Loss_G: 7.1169\n",
            "[249/25][61/69] Loss_D: 0.0022 Loss_G: 7.2142\n",
            "[249/25][62/69] Loss_D: 0.0041 Loss_G: 7.2520\n",
            "[249/25][63/69] Loss_D: 0.0016 Loss_G: 7.9166\n",
            "[249/25][64/69] Loss_D: 0.0117 Loss_G: 7.6877\n",
            "[249/25][65/69] Loss_D: 0.0008 Loss_G: 7.7611\n",
            "[249/25][66/69] Loss_D: 0.0029 Loss_G: 6.6612\n",
            "[249/25][67/69] Loss_D: 0.0037 Loss_G: 6.9630\n",
            "[249/25][68/69] Loss_D: 0.0021 Loss_G: 7.9925\n",
            "[250/25][0/69] Loss_D: 0.0009 Loss_G: 8.0809\n",
            "[250/25][1/69] Loss_D: 0.0014 Loss_G: 8.1180\n",
            "[250/25][2/69] Loss_D: 0.0033 Loss_G: 8.5447\n",
            "[250/25][3/69] Loss_D: 0.0013 Loss_G: 9.1287\n",
            "[250/25][4/69] Loss_D: 0.0006 Loss_G: 9.1309\n",
            "[250/25][5/69] Loss_D: 0.0006 Loss_G: 8.8289\n",
            "[250/25][6/69] Loss_D: 0.0098 Loss_G: 7.9450\n",
            "[250/25][7/69] Loss_D: 0.0007 Loss_G: 8.2525\n",
            "[250/25][8/69] Loss_D: 0.0011 Loss_G: 7.7155\n",
            "[250/25][9/69] Loss_D: 0.0022 Loss_G: 7.4647\n",
            "[250/25][10/69] Loss_D: 0.0004 Loss_G: 9.2073\n",
            "[250/25][11/69] Loss_D: 0.0010 Loss_G: 7.8972\n",
            "[250/25][12/69] Loss_D: 0.0031 Loss_G: 7.8074\n",
            "[250/25][13/69] Loss_D: 0.0004 Loss_G: 9.0776\n",
            "[250/25][14/69] Loss_D: 0.0024 Loss_G: 7.8978\n",
            "[250/25][15/69] Loss_D: 0.0037 Loss_G: 7.0246\n",
            "[250/25][16/69] Loss_D: 0.0008 Loss_G: 8.4861\n",
            "[250/25][17/69] Loss_D: 0.0004 Loss_G: 8.9450\n",
            "[250/25][18/69] Loss_D: 0.0033 Loss_G: 7.3927\n",
            "[250/25][19/69] Loss_D: 0.0007 Loss_G: 9.0436\n",
            "[250/25][20/69] Loss_D: 0.0010 Loss_G: 8.4680\n",
            "[250/25][21/69] Loss_D: 0.0031 Loss_G: 7.6845\n",
            "[250/25][22/69] Loss_D: 0.0016 Loss_G: 7.9355\n",
            "[250/25][23/69] Loss_D: 0.0075 Loss_G: 7.8063\n",
            "[250/25][24/69] Loss_D: 0.0149 Loss_G: 7.9734\n",
            "[250/25][25/69] Loss_D: 0.0010 Loss_G: 7.7760\n",
            "[250/25][26/69] Loss_D: 0.0019 Loss_G: 6.8374\n",
            "[250/25][27/69] Loss_D: 0.0023 Loss_G: 7.3708\n",
            "[250/25][28/69] Loss_D: 0.0020 Loss_G: 7.5569\n",
            "[250/25][29/69] Loss_D: 0.0036 Loss_G: 7.0786\n",
            "[250/25][30/69] Loss_D: 0.0028 Loss_G: 7.6521\n",
            "[250/25][31/69] Loss_D: 0.0032 Loss_G: 7.4465\n",
            "[250/25][32/69] Loss_D: 0.0033 Loss_G: 6.9970\n",
            "[250/25][33/69] Loss_D: 0.0006 Loss_G: 8.8609\n",
            "[250/25][34/69] Loss_D: 0.0017 Loss_G: 7.8175\n",
            "[250/25][35/69] Loss_D: 0.0056 Loss_G: 6.9295\n",
            "[250/25][36/69] Loss_D: 0.0006 Loss_G: 8.8840\n",
            "[250/25][37/69] Loss_D: 0.0084 Loss_G: 9.0715\n",
            "[250/25][38/69] Loss_D: 0.0010 Loss_G: 8.1996\n",
            "[250/25][39/69] Loss_D: 0.0307 Loss_G: 6.6652\n",
            "[250/25][40/69] Loss_D: 0.0025 Loss_G: 6.5137\n",
            "[250/25][41/69] Loss_D: 0.0017 Loss_G: 6.8511\n",
            "[250/25][42/69] Loss_D: 0.0009 Loss_G: 7.5313\n",
            "[250/25][43/69] Loss_D: 0.0077 Loss_G: 6.1304\n",
            "[250/25][44/69] Loss_D: 0.0178 Loss_G: 6.1469\n",
            "[250/25][45/69] Loss_D: 0.0048 Loss_G: 7.2494\n",
            "[250/25][46/69] Loss_D: 0.0006 Loss_G: 8.9988\n",
            "[250/25][47/69] Loss_D: 0.0005 Loss_G: 8.9036\n",
            "[250/25][48/69] Loss_D: 0.0012 Loss_G: 8.9389\n",
            "[250/25][49/69] Loss_D: 0.0009 Loss_G: 9.1672\n",
            "[250/25][50/69] Loss_D: 0.0027 Loss_G: 9.5817\n",
            "[250/25][51/69] Loss_D: 0.0042 Loss_G: 10.1507\n",
            "[250/25][52/69] Loss_D: 0.0006 Loss_G: 10.0399\n",
            "[250/25][53/69] Loss_D: 0.0012 Loss_G: 11.4724\n",
            "[250/25][54/69] Loss_D: 0.0023 Loss_G: 10.1291\n",
            "[250/25][55/69] Loss_D: 0.0004 Loss_G: 9.5367\n",
            "[250/25][56/69] Loss_D: 0.0347 Loss_G: 8.3902\n",
            "[250/25][57/69] Loss_D: 0.0033 Loss_G: 6.4107\n",
            "[250/25][58/69] Loss_D: 0.0037 Loss_G: 6.4777\n",
            "[250/25][59/69] Loss_D: 0.0013 Loss_G: 7.2279\n",
            "[250/25][60/69] Loss_D: 0.0103 Loss_G: 6.7634\n",
            "[250/25][61/69] Loss_D: 0.0107 Loss_G: 6.3279\n",
            "[250/25][62/69] Loss_D: 0.0085 Loss_G: 7.2020\n",
            "[250/25][63/69] Loss_D: 0.0223 Loss_G: 7.1254\n",
            "[250/25][64/69] Loss_D: 0.0107 Loss_G: 6.8723\n",
            "[250/25][65/69] Loss_D: 0.0043 Loss_G: 7.6993\n",
            "[250/25][66/69] Loss_D: 0.0017 Loss_G: 8.9343\n",
            "[250/25][67/69] Loss_D: 0.0002 Loss_G: 10.9038\n",
            "[250/25][68/69] Loss_D: 0.0089 Loss_G: 15.0722\n",
            "[251/25][0/69] Loss_D: 0.0011 Loss_G: 12.6444\n",
            "[251/25][1/69] Loss_D: 0.0024 Loss_G: 12.7435\n",
            "[251/25][2/69] Loss_D: 0.0001 Loss_G: 13.0895\n",
            "[251/25][3/69] Loss_D: 0.0167 Loss_G: 11.0179\n",
            "[251/25][4/69] Loss_D: 0.0006 Loss_G: 11.5888\n",
            "[251/25][5/69] Loss_D: 0.0008 Loss_G: 11.4115\n",
            "[251/25][6/69] Loss_D: 0.0016 Loss_G: 11.9181\n",
            "[251/25][7/69] Loss_D: 0.0010 Loss_G: 10.1463\n",
            "[251/25][8/69] Loss_D: 0.0027 Loss_G: 10.6961\n",
            "[251/25][9/69] Loss_D: 0.0163 Loss_G: 10.2723\n",
            "[251/25][10/69] Loss_D: 0.0007 Loss_G: 9.6094\n",
            "[251/25][11/69] Loss_D: 0.0004 Loss_G: 10.9981\n",
            "[251/25][12/69] Loss_D: 0.0002 Loss_G: 10.1045\n",
            "[251/25][13/69] Loss_D: 0.0021 Loss_G: 8.5603\n",
            "[251/25][14/69] Loss_D: 0.0304 Loss_G: 6.3436\n",
            "[251/25][15/69] Loss_D: 0.0044 Loss_G: 8.6812\n",
            "[251/25][16/69] Loss_D: 0.0017 Loss_G: 8.5379\n",
            "[251/25][17/69] Loss_D: 0.0009 Loss_G: 9.5539\n",
            "[251/25][18/69] Loss_D: 0.0012 Loss_G: 9.5202\n",
            "[251/25][19/69] Loss_D: 0.0005 Loss_G: 10.2484\n",
            "[251/25][20/69] Loss_D: 0.0008 Loss_G: 10.6565\n",
            "[251/25][21/69] Loss_D: 0.0003 Loss_G: 12.2003\n",
            "[251/25][22/69] Loss_D: 0.0007 Loss_G: 12.3260\n",
            "[251/25][23/69] Loss_D: 0.0013 Loss_G: 12.6914\n",
            "[251/25][24/69] Loss_D: 0.0184 Loss_G: 11.1845\n",
            "[251/25][25/69] Loss_D: 0.0073 Loss_G: 13.4395\n",
            "[251/25][26/69] Loss_D: 0.0011 Loss_G: 11.0904\n",
            "[251/25][27/69] Loss_D: 0.0007 Loss_G: 9.5520\n",
            "[251/25][28/69] Loss_D: 0.0006 Loss_G: 10.1239\n",
            "[251/25][29/69] Loss_D: 0.0001 Loss_G: 10.5465\n",
            "[251/25][30/69] Loss_D: 0.0126 Loss_G: 9.6884\n",
            "[251/25][31/69] Loss_D: 0.0004 Loss_G: 8.2181\n",
            "[251/25][32/69] Loss_D: 0.0029 Loss_G: 7.1931\n",
            "[251/25][33/69] Loss_D: 0.0004 Loss_G: 8.9516\n",
            "[251/25][34/69] Loss_D: 0.0072 Loss_G: 6.2427\n",
            "[251/25][35/69] Loss_D: 0.0039 Loss_G: 7.1999\n",
            "[251/25][36/69] Loss_D: 0.0017 Loss_G: 7.7768\n",
            "[251/25][37/69] Loss_D: 0.0013 Loss_G: 7.8965\n",
            "[251/25][38/69] Loss_D: 0.0036 Loss_G: 7.4101\n",
            "[251/25][39/69] Loss_D: 0.0021 Loss_G: 7.1470\n",
            "[251/25][40/69] Loss_D: 0.0029 Loss_G: 7.2977\n",
            "[251/25][41/69] Loss_D: 0.0004 Loss_G: 11.6016\n",
            "[251/25][42/69] Loss_D: 0.0013 Loss_G: 7.6758\n",
            "[251/25][43/69] Loss_D: 0.0013 Loss_G: 8.8051\n",
            "[251/25][44/69] Loss_D: 0.0006 Loss_G: 8.9950\n",
            "[251/25][45/69] Loss_D: 0.0016 Loss_G: 8.8042\n",
            "[251/25][46/69] Loss_D: 0.0013 Loss_G: 9.1443\n",
            "[251/25][47/69] Loss_D: 0.0008 Loss_G: 8.6641\n",
            "[251/25][48/69] Loss_D: 0.0002 Loss_G: 10.2840\n",
            "[251/25][49/69] Loss_D: 0.0005 Loss_G: 9.2895\n",
            "[251/25][50/69] Loss_D: 0.0003 Loss_G: 9.3597\n",
            "[251/25][51/69] Loss_D: 0.0008 Loss_G: 8.4088\n",
            "[251/25][52/69] Loss_D: 0.0004 Loss_G: 9.5081\n",
            "[251/25][53/69] Loss_D: 0.0004 Loss_G: 10.1599\n",
            "[251/25][54/69] Loss_D: 0.0004 Loss_G: 9.3650\n",
            "[251/25][55/69] Loss_D: 0.0008 Loss_G: 12.0279\n",
            "[251/25][56/69] Loss_D: 0.0012 Loss_G: 7.8187\n",
            "[251/25][57/69] Loss_D: 0.0002 Loss_G: 9.5410\n",
            "[251/25][58/69] Loss_D: 0.0249 Loss_G: 7.4015\n",
            "[251/25][59/69] Loss_D: 0.0007 Loss_G: 7.4951\n",
            "[251/25][60/69] Loss_D: 0.0008 Loss_G: 7.7256\n",
            "[251/25][61/69] Loss_D: 0.0011 Loss_G: 7.5486\n",
            "[251/25][62/69] Loss_D: 0.0032 Loss_G: 6.4811\n",
            "[251/25][63/69] Loss_D: 0.0075 Loss_G: 6.2340\n",
            "[251/25][64/69] Loss_D: 0.0028 Loss_G: 7.1503\n",
            "[251/25][65/69] Loss_D: 0.0110 Loss_G: 6.0386\n",
            "[251/25][66/69] Loss_D: 0.0015 Loss_G: 8.4471\n",
            "[251/25][67/69] Loss_D: 0.0008 Loss_G: 8.7393\n",
            "[251/25][68/69] Loss_D: 0.0008 Loss_G: 11.6377\n",
            "[252/25][0/69] Loss_D: 0.0006 Loss_G: 9.2587\n",
            "[252/25][1/69] Loss_D: 0.0007 Loss_G: 9.5716\n",
            "[252/25][2/69] Loss_D: 0.0017 Loss_G: 9.7369\n",
            "[252/25][3/69] Loss_D: 0.0010 Loss_G: 10.8500\n",
            "[252/25][4/69] Loss_D: 0.0004 Loss_G: 9.7968\n",
            "[252/25][5/69] Loss_D: 0.0004 Loss_G: 11.1259\n",
            "[252/25][6/69] Loss_D: 0.0021 Loss_G: 11.5597\n",
            "[252/25][7/69] Loss_D: 0.0030 Loss_G: 11.3469\n",
            "[252/25][8/69] Loss_D: 0.0007 Loss_G: 10.3294\n",
            "[252/25][9/69] Loss_D: 0.0027 Loss_G: 10.6319\n",
            "[252/25][10/69] Loss_D: 0.0010 Loss_G: 13.4733\n",
            "[252/25][11/69] Loss_D: 0.0020 Loss_G: 11.1727\n",
            "[252/25][12/69] Loss_D: 0.0025 Loss_G: 9.7825\n",
            "[252/25][13/69] Loss_D: 0.0012 Loss_G: 10.4985\n",
            "[252/25][14/69] Loss_D: 0.0461 Loss_G: 10.4540\n",
            "[252/25][15/69] Loss_D: 0.0019 Loss_G: 6.3265\n",
            "[252/25][16/69] Loss_D: 0.0007 Loss_G: 7.8442\n",
            "[252/25][17/69] Loss_D: 0.0085 Loss_G: 5.3824\n",
            "[252/25][18/69] Loss_D: 0.0120 Loss_G: 5.4740\n",
            "[252/25][19/69] Loss_D: 0.0075 Loss_G: 6.3042\n",
            "[252/25][20/69] Loss_D: 0.0062 Loss_G: 7.1023\n",
            "[252/25][21/69] Loss_D: 0.0012 Loss_G: 8.6451\n",
            "[252/25][22/69] Loss_D: 0.0019 Loss_G: 8.3388\n",
            "[252/25][23/69] Loss_D: 0.0015 Loss_G: 8.7236\n",
            "[252/25][24/69] Loss_D: 0.0006 Loss_G: 9.2236\n",
            "[252/25][25/69] Loss_D: 0.0006 Loss_G: 9.2010\n",
            "[252/25][26/69] Loss_D: 0.0019 Loss_G: 9.8340\n",
            "[252/25][27/69] Loss_D: 0.0004 Loss_G: 9.8505\n",
            "[252/25][28/69] Loss_D: 0.0119 Loss_G: 11.8651\n",
            "[252/25][29/69] Loss_D: 0.0001 Loss_G: 11.5645\n",
            "[252/25][30/69] Loss_D: 0.0017 Loss_G: 9.2453\n",
            "[252/25][31/69] Loss_D: 0.0015 Loss_G: 8.6228\n",
            "[252/25][32/69] Loss_D: 0.0038 Loss_G: 8.7786\n",
            "[252/25][33/69] Loss_D: 0.0044 Loss_G: 7.6593\n",
            "[252/25][34/69] Loss_D: 0.0138 Loss_G: 8.9790\n",
            "[252/25][35/69] Loss_D: 0.0025 Loss_G: 8.7382\n",
            "[252/25][36/69] Loss_D: 0.0014 Loss_G: 10.2534\n",
            "[252/25][37/69] Loss_D: 0.0036 Loss_G: 8.0260\n",
            "[252/25][38/69] Loss_D: 0.0080 Loss_G: 8.1110\n",
            "[252/25][39/69] Loss_D: 0.0063 Loss_G: 7.3526\n",
            "[252/25][40/69] Loss_D: 0.0016 Loss_G: 8.4310\n",
            "[252/25][41/69] Loss_D: 0.0004 Loss_G: 9.5591\n",
            "[252/25][42/69] Loss_D: 0.0003 Loss_G: 9.3764\n",
            "[252/25][43/69] Loss_D: 0.0001 Loss_G: 10.3484\n",
            "[252/25][44/69] Loss_D: 0.0004 Loss_G: 9.3891\n",
            "[252/25][45/69] Loss_D: 0.0002 Loss_G: 10.1280\n",
            "[252/25][46/69] Loss_D: 0.0009 Loss_G: 10.7132\n",
            "[252/25][47/69] Loss_D: 0.0004 Loss_G: 10.4298\n",
            "[252/25][48/69] Loss_D: 0.0002 Loss_G: 10.4936\n",
            "[252/25][49/69] Loss_D: 0.0082 Loss_G: 9.2125\n",
            "[252/25][50/69] Loss_D: 0.0019 Loss_G: 10.0452\n",
            "[252/25][51/69] Loss_D: 0.0324 Loss_G: 9.4151\n",
            "[252/25][52/69] Loss_D: 0.0004 Loss_G: 8.5926\n",
            "[252/25][53/69] Loss_D: 0.0007 Loss_G: 8.0114\n",
            "[252/25][54/69] Loss_D: 0.0010 Loss_G: 8.0353\n",
            "[252/25][55/69] Loss_D: 0.0030 Loss_G: 7.5002\n",
            "[252/25][56/69] Loss_D: 0.0292 Loss_G: 6.8831\n",
            "[252/25][57/69] Loss_D: 0.0197 Loss_G: 7.0478\n",
            "[252/25][58/69] Loss_D: 0.0001 Loss_G: 10.8382\n",
            "[252/25][59/69] Loss_D: 0.0003 Loss_G: 10.6992\n",
            "[252/25][60/69] Loss_D: 0.0001 Loss_G: 11.6103\n",
            "[252/25][61/69] Loss_D: 0.0004 Loss_G: 11.5321\n",
            "[252/25][62/69] Loss_D: 0.0001 Loss_G: 12.1982\n",
            "[252/25][63/69] Loss_D: 0.0026 Loss_G: 12.1546\n",
            "[252/25][64/69] Loss_D: 0.0066 Loss_G: 13.0611\n",
            "[252/25][65/69] Loss_D: 0.0071 Loss_G: 13.6834\n",
            "[252/25][66/69] Loss_D: 0.0099 Loss_G: 14.8918\n",
            "[252/25][67/69] Loss_D: 0.0074 Loss_G: 11.2414\n",
            "[252/25][68/69] Loss_D: 0.0006 Loss_G: 11.3273\n",
            "[253/25][0/69] Loss_D: 0.0002 Loss_G: 10.6539\n",
            "[253/25][1/69] Loss_D: 0.0004 Loss_G: 9.4897\n",
            "[253/25][2/69] Loss_D: 0.0041 Loss_G: 10.5067\n",
            "[253/25][3/69] Loss_D: 0.0006 Loss_G: 9.8105\n",
            "[253/25][4/69] Loss_D: 0.0002 Loss_G: 10.1952\n",
            "[253/25][5/69] Loss_D: 0.0001 Loss_G: 9.9726\n",
            "[253/25][6/69] Loss_D: 0.0009 Loss_G: 8.7110\n",
            "[253/25][7/69] Loss_D: 0.0010 Loss_G: 8.4682\n",
            "[253/25][8/69] Loss_D: 0.0004 Loss_G: 9.0731\n",
            "[253/25][9/69] Loss_D: 0.0014 Loss_G: 8.2139\n",
            "[253/25][10/69] Loss_D: 0.0022 Loss_G: 7.2500\n",
            "[253/25][11/69] Loss_D: 0.0017 Loss_G: 7.3943\n",
            "[253/25][12/69] Loss_D: 0.0009 Loss_G: 8.0152\n",
            "[253/25][13/69] Loss_D: 0.0012 Loss_G: 8.1905\n",
            "[253/25][14/69] Loss_D: 0.0049 Loss_G: 6.6078\n",
            "[253/25][15/69] Loss_D: 0.0024 Loss_G: 7.6347\n",
            "[253/25][16/69] Loss_D: 0.0015 Loss_G: 7.7570\n",
            "[253/25][17/69] Loss_D: 0.0086 Loss_G: 6.4384\n",
            "[253/25][18/69] Loss_D: 0.0039 Loss_G: 7.3244\n",
            "[253/25][19/69] Loss_D: 0.0024 Loss_G: 8.4598\n",
            "[253/25][20/69] Loss_D: 0.0007 Loss_G: 9.1667\n",
            "[253/25][21/69] Loss_D: 0.0012 Loss_G: 9.6504\n",
            "[253/25][22/69] Loss_D: 0.0003 Loss_G: 10.1656\n",
            "[253/25][23/69] Loss_D: 0.0010 Loss_G: 9.4511\n",
            "[253/25][24/69] Loss_D: 0.0005 Loss_G: 9.7812\n",
            "[253/25][25/69] Loss_D: 0.0004 Loss_G: 9.3752\n",
            "[253/25][26/69] Loss_D: 0.0001 Loss_G: 10.3879\n",
            "[253/25][27/69] Loss_D: 0.0040 Loss_G: 11.5956\n",
            "[253/25][28/69] Loss_D: 0.0044 Loss_G: 8.0084\n",
            "[253/25][29/69] Loss_D: 0.0048 Loss_G: 9.3670\n",
            "[253/25][30/69] Loss_D: 0.0544 Loss_G: 5.5685\n",
            "[253/25][31/69] Loss_D: 0.0034 Loss_G: 5.8532\n",
            "[253/25][32/69] Loss_D: 0.0158 Loss_G: 5.4508\n",
            "[253/25][33/69] Loss_D: 0.0067 Loss_G: 6.5599\n",
            "[253/25][34/69] Loss_D: 0.0476 Loss_G: 6.6767\n",
            "[253/25][35/69] Loss_D: 0.0001 Loss_G: 11.9154\n",
            "[253/25][36/69] Loss_D: 0.0024 Loss_G: 12.4404\n",
            "[253/25][37/69] Loss_D: 0.0161 Loss_G: 10.0870\n",
            "[253/25][38/69] Loss_D: 0.0475 Loss_G: 13.6197\n",
            "[253/25][39/69] Loss_D: 0.0007 Loss_G: 11.2054\n",
            "[253/25][40/69] Loss_D: 0.0008 Loss_G: 10.5660\n",
            "[253/25][41/69] Loss_D: 0.0003 Loss_G: 11.0366\n",
            "[253/25][42/69] Loss_D: 0.0013 Loss_G: 9.1668\n",
            "[253/25][43/69] Loss_D: 0.0062 Loss_G: 9.5411\n",
            "[253/25][44/69] Loss_D: 0.0202 Loss_G: 9.4170\n",
            "[253/25][45/69] Loss_D: 0.0078 Loss_G: 9.3872\n",
            "[253/25][46/69] Loss_D: 0.0011 Loss_G: 10.5828\n",
            "[253/25][47/69] Loss_D: 0.0020 Loss_G: 12.7397\n",
            "[253/25][48/69] Loss_D: 0.0001 Loss_G: 11.9122\n",
            "[253/25][49/69] Loss_D: 0.0001 Loss_G: 13.5763\n",
            "[253/25][50/69] Loss_D: 0.0013 Loss_G: 11.3438\n",
            "[253/25][51/69] Loss_D: 0.0001 Loss_G: 13.7092\n",
            "[253/25][52/69] Loss_D: 0.0003 Loss_G: 14.3523\n",
            "[253/25][53/69] Loss_D: 0.0011 Loss_G: 13.3675\n",
            "[253/25][54/69] Loss_D: 0.0013 Loss_G: 12.2145\n",
            "[253/25][55/69] Loss_D: 0.0004 Loss_G: 11.8384\n",
            "[253/25][56/69] Loss_D: 0.0004 Loss_G: 11.6982\n",
            "[253/25][57/69] Loss_D: 0.0028 Loss_G: 12.1739\n",
            "[253/25][58/69] Loss_D: 0.0028 Loss_G: 10.1914\n",
            "[253/25][59/69] Loss_D: 0.0035 Loss_G: 10.6659\n",
            "[253/25][60/69] Loss_D: 0.0077 Loss_G: 11.2744\n",
            "[253/25][61/69] Loss_D: 0.0015 Loss_G: 9.7138\n",
            "[253/25][62/69] Loss_D: 0.0032 Loss_G: 9.8534\n",
            "[253/25][63/69] Loss_D: 0.0018 Loss_G: 8.9957\n",
            "[253/25][64/69] Loss_D: 0.0144 Loss_G: 9.8560\n",
            "[253/25][65/69] Loss_D: 0.0009 Loss_G: 9.7475\n",
            "[253/25][66/69] Loss_D: 0.0023 Loss_G: 9.1746\n",
            "[253/25][67/69] Loss_D: 0.0044 Loss_G: 8.2646\n",
            "[253/25][68/69] Loss_D: 0.0064 Loss_G: 8.0702\n",
            "[254/25][0/69] Loss_D: 0.0014 Loss_G: 9.2287\n",
            "[254/25][1/69] Loss_D: 0.0021 Loss_G: 8.2844\n",
            "[254/25][2/69] Loss_D: 0.0006 Loss_G: 9.8684\n",
            "[254/25][3/69] Loss_D: 0.0003 Loss_G: 10.0615\n",
            "[254/25][4/69] Loss_D: 0.0009 Loss_G: 9.5094\n",
            "[254/25][5/69] Loss_D: 0.0003 Loss_G: 9.9529\n",
            "[254/25][6/69] Loss_D: 0.0005 Loss_G: 11.0343\n",
            "[254/25][7/69] Loss_D: 0.0004 Loss_G: 9.9272\n",
            "[254/25][8/69] Loss_D: 0.0004 Loss_G: 12.2097\n",
            "[254/25][9/69] Loss_D: 0.0003 Loss_G: 9.8622\n",
            "[254/25][10/69] Loss_D: 0.0023 Loss_G: 9.0302\n",
            "[254/25][11/69] Loss_D: 0.0035 Loss_G: 8.1334\n",
            "[254/25][12/69] Loss_D: 0.0236 Loss_G: 8.8964\n",
            "[254/25][13/69] Loss_D: 0.0004 Loss_G: 8.0518\n",
            "[254/25][14/69] Loss_D: 0.0012 Loss_G: 7.6967\n",
            "[254/25][15/69] Loss_D: 0.0040 Loss_G: 6.9010\n",
            "[254/25][16/69] Loss_D: 0.0045 Loss_G: 6.6534\n",
            "[254/25][17/69] Loss_D: 0.0041 Loss_G: 7.6303\n",
            "[254/25][18/69] Loss_D: 0.0102 Loss_G: 6.7368\n",
            "[254/25][19/69] Loss_D: 0.0013 Loss_G: 8.2110\n",
            "[254/25][20/69] Loss_D: 0.0027 Loss_G: 7.3279\n",
            "[254/25][21/69] Loss_D: 0.0005 Loss_G: 8.9040\n",
            "[254/25][22/69] Loss_D: 0.0011 Loss_G: 8.4716\n",
            "[254/25][23/69] Loss_D: 0.0002 Loss_G: 10.1838\n",
            "[254/25][24/69] Loss_D: 0.0004 Loss_G: 8.9918\n",
            "[254/25][25/69] Loss_D: 0.0866 Loss_G: 6.6791\n",
            "[254/25][26/69] Loss_D: 0.0055 Loss_G: 4.8283\n",
            "[254/25][27/69] Loss_D: 0.0034 Loss_G: 5.7983\n",
            "[254/25][28/69] Loss_D: 0.0782 Loss_G: 6.0799\n",
            "[254/25][29/69] Loss_D: 0.0032 Loss_G: 9.0622\n",
            "[254/25][30/69] Loss_D: 0.0015 Loss_G: 9.5904\n",
            "[254/25][31/69] Loss_D: 0.0005 Loss_G: 11.3466\n",
            "[254/25][32/69] Loss_D: 0.0299 Loss_G: 11.5221\n",
            "[254/25][33/69] Loss_D: 0.0019 Loss_G: 13.7284\n",
            "[254/25][34/69] Loss_D: 0.0004 Loss_G: 13.2451\n",
            "[254/25][35/69] Loss_D: 0.0030 Loss_G: 12.6142\n",
            "[254/25][36/69] Loss_D: 0.0069 Loss_G: 12.7796\n",
            "[254/25][37/69] Loss_D: 0.0694 Loss_G: 10.7186\n",
            "[254/25][38/69] Loss_D: 0.0018 Loss_G: 7.3789\n",
            "[254/25][39/69] Loss_D: 0.0126 Loss_G: 5.8649\n",
            "[254/25][40/69] Loss_D: 0.0243 Loss_G: 7.4751\n",
            "[254/25][41/69] Loss_D: 0.0322 Loss_G: 9.4038\n",
            "[254/25][42/69] Loss_D: 0.0004 Loss_G: 13.0792\n",
            "[254/25][43/69] Loss_D: 0.0103 Loss_G: 11.3906\n",
            "[254/25][44/69] Loss_D: 0.0003 Loss_G: 12.3644\n",
            "[254/25][45/69] Loss_D: 0.0011 Loss_G: 12.2148\n",
            "[254/25][46/69] Loss_D: 0.0016 Loss_G: 11.5247\n",
            "[254/25][47/69] Loss_D: 0.0669 Loss_G: 11.2827\n",
            "[254/25][48/69] Loss_D: 0.0072 Loss_G: 9.2613\n",
            "[254/25][49/69] Loss_D: 0.0339 Loss_G: 9.1672\n",
            "[254/25][50/69] Loss_D: 0.0011 Loss_G: 11.2904\n",
            "[254/25][51/69] Loss_D: 0.0009 Loss_G: 11.7405\n",
            "[254/25][52/69] Loss_D: 0.0047 Loss_G: 12.4263\n",
            "[254/25][53/69] Loss_D: 0.0028 Loss_G: 11.2496\n",
            "[254/25][54/69] Loss_D: 0.0087 Loss_G: 12.3684\n",
            "[254/25][55/69] Loss_D: 0.0092 Loss_G: 13.0110\n",
            "[254/25][56/69] Loss_D: 0.0901 Loss_G: 10.2661\n",
            "[254/25][57/69] Loss_D: 0.0097 Loss_G: 8.6748\n",
            "[254/25][58/69] Loss_D: 0.0092 Loss_G: 8.3976\n",
            "[254/25][59/69] Loss_D: 0.0060 Loss_G: 8.2052\n",
            "[254/25][60/69] Loss_D: 0.0019 Loss_G: 8.9995\n",
            "[254/25][61/69] Loss_D: 0.0084 Loss_G: 7.4226\n",
            "[254/25][62/69] Loss_D: 0.0015 Loss_G: 9.4116\n",
            "[254/25][63/69] Loss_D: 0.0036 Loss_G: 9.2783\n",
            "[254/25][64/69] Loss_D: 0.0048 Loss_G: 9.4150\n",
            "[254/25][65/69] Loss_D: 0.0034 Loss_G: 9.1058\n",
            "[254/25][66/69] Loss_D: 0.0012 Loss_G: 9.8966\n",
            "[254/25][67/69] Loss_D: 0.0010 Loss_G: 10.0147\n",
            "[254/25][68/69] Loss_D: 0.4125 Loss_G: 3.8505\n",
            "[255/25][0/69] Loss_D: 0.1513 Loss_G: 3.7139\n",
            "[255/25][1/69] Loss_D: 0.2832 Loss_G: 10.7506\n",
            "[255/25][2/69] Loss_D: 0.0006 Loss_G: 19.1004\n",
            "[255/25][3/69] Loss_D: 0.0206 Loss_G: 25.2774\n",
            "[255/25][4/69] Loss_D: 0.2549 Loss_G: 25.6259\n",
            "[255/25][5/69] Loss_D: 0.0060 Loss_G: 24.6383\n",
            "[255/25][6/69] Loss_D: 0.1675 Loss_G: 21.3019\n",
            "[255/25][7/69] Loss_D: 0.0000 Loss_G: 18.2748\n",
            "[255/25][8/69] Loss_D: 0.0000 Loss_G: 14.7977\n",
            "[255/25][9/69] Loss_D: 0.0000 Loss_G: 14.9321\n",
            "[255/25][10/69] Loss_D: 0.0003 Loss_G: 15.8184\n",
            "[255/25][11/69] Loss_D: 0.0008 Loss_G: 10.7634\n",
            "[255/25][12/69] Loss_D: 0.0019 Loss_G: 11.1813\n",
            "[255/25][13/69] Loss_D: 0.0082 Loss_G: 9.5516\n",
            "[255/25][14/69] Loss_D: 0.0039 Loss_G: 11.5116\n",
            "[255/25][15/69] Loss_D: 0.0720 Loss_G: 9.4051\n",
            "[255/25][16/69] Loss_D: 0.0004 Loss_G: 14.6959\n",
            "[255/25][17/69] Loss_D: 0.1102 Loss_G: 11.9607\n",
            "[255/25][18/69] Loss_D: 0.0012 Loss_G: 11.7934\n",
            "[255/25][19/69] Loss_D: 0.0009 Loss_G: 11.9472\n",
            "[255/25][20/69] Loss_D: 0.0195 Loss_G: 10.2400\n",
            "[255/25][21/69] Loss_D: 0.0442 Loss_G: 11.1946\n",
            "[255/25][22/69] Loss_D: 0.3512 Loss_G: 8.9434\n",
            "[255/25][23/69] Loss_D: 0.0048 Loss_G: 7.8289\n",
            "[255/25][24/69] Loss_D: 0.0023 Loss_G: 7.6250\n",
            "[255/25][25/69] Loss_D: 0.1246 Loss_G: 7.7204\n",
            "[255/25][26/69] Loss_D: 0.0055 Loss_G: 9.6864\n",
            "[255/25][27/69] Loss_D: 0.0022 Loss_G: 10.4401\n",
            "[255/25][28/69] Loss_D: 0.0238 Loss_G: 10.6910\n",
            "[255/25][29/69] Loss_D: 0.0051 Loss_G: 11.7700\n",
            "[255/25][30/69] Loss_D: 0.0211 Loss_G: 10.5798\n",
            "[255/25][31/69] Loss_D: 0.1822 Loss_G: 9.4349\n",
            "[255/25][32/69] Loss_D: 0.0076 Loss_G: 8.6416\n",
            "[255/25][33/69] Loss_D: 0.0275 Loss_G: 7.9025\n",
            "[255/25][34/69] Loss_D: 0.0164 Loss_G: 8.0934\n",
            "[255/25][35/69] Loss_D: 0.0025 Loss_G: 9.3654\n",
            "[255/25][36/69] Loss_D: 0.0035 Loss_G: 10.3311\n",
            "[255/25][37/69] Loss_D: 0.0141 Loss_G: 10.2017\n",
            "[255/25][38/69] Loss_D: 0.0012 Loss_G: 10.9385\n",
            "[255/25][39/69] Loss_D: 0.0101 Loss_G: 11.2313\n",
            "[255/25][40/69] Loss_D: 0.0253 Loss_G: 10.2572\n",
            "[255/25][41/69] Loss_D: 0.0018 Loss_G: 10.6944\n",
            "[255/25][42/69] Loss_D: 0.0025 Loss_G: 9.3192\n",
            "[255/25][43/69] Loss_D: 0.0037 Loss_G: 8.8479\n",
            "[255/25][44/69] Loss_D: 0.0078 Loss_G: 8.3468\n",
            "[255/25][45/69] Loss_D: 0.0030 Loss_G: 8.2700\n",
            "[255/25][46/69] Loss_D: 0.0166 Loss_G: 8.0786\n",
            "[255/25][47/69] Loss_D: 0.0023 Loss_G: 8.9078\n",
            "[255/25][48/69] Loss_D: 0.0037 Loss_G: 8.5079\n",
            "[255/25][49/69] Loss_D: 0.0012 Loss_G: 9.5587\n",
            "[255/25][50/69] Loss_D: 0.0024 Loss_G: 9.0619\n",
            "[255/25][51/69] Loss_D: 0.0047 Loss_G: 10.3568\n",
            "[255/25][52/69] Loss_D: 0.6270 Loss_G: 3.5127\n",
            "[255/25][53/69] Loss_D: 0.2048 Loss_G: 5.1852\n",
            "[255/25][54/69] Loss_D: 0.0114 Loss_G: 7.6278\n",
            "[255/25][55/69] Loss_D: 0.0156 Loss_G: 7.9975\n",
            "[255/25][56/69] Loss_D: 0.0023 Loss_G: 10.3161\n",
            "[255/25][57/69] Loss_D: 0.0002 Loss_G: 13.2897\n",
            "[255/25][58/69] Loss_D: 0.0004 Loss_G: 12.4034\n",
            "[255/25][59/69] Loss_D: 0.0003 Loss_G: 13.0442\n",
            "[255/25][60/69] Loss_D: 0.0004 Loss_G: 12.7433\n",
            "[255/25][61/69] Loss_D: 0.0013 Loss_G: 12.0968\n",
            "[255/25][62/69] Loss_D: 0.0004 Loss_G: 12.8198\n",
            "[255/25][63/69] Loss_D: 0.0006 Loss_G: 12.1535\n",
            "[255/25][64/69] Loss_D: 0.0004 Loss_G: 12.8823\n",
            "[255/25][65/69] Loss_D: 0.0078 Loss_G: 8.5763\n",
            "[255/25][66/69] Loss_D: 0.0053 Loss_G: 9.4062\n",
            "[255/25][67/69] Loss_D: 0.0010 Loss_G: 10.7054\n",
            "[255/25][68/69] Loss_D: 0.0359 Loss_G: 8.2891\n",
            "[256/25][0/69] Loss_D: 0.0040 Loss_G: 9.6234\n",
            "[256/25][1/69] Loss_D: 0.0320 Loss_G: 11.1966\n",
            "[256/25][2/69] Loss_D: 0.0312 Loss_G: 8.8946\n",
            "[256/25][3/69] Loss_D: 0.0052 Loss_G: 8.3714\n",
            "[256/25][4/69] Loss_D: 0.0117 Loss_G: 7.4301\n",
            "[256/25][5/69] Loss_D: 0.0151 Loss_G: 8.5197\n",
            "[256/25][6/69] Loss_D: 0.0393 Loss_G: 8.6195\n",
            "[256/25][7/69] Loss_D: 0.0007 Loss_G: 12.0330\n",
            "[256/25][8/69] Loss_D: 0.0007 Loss_G: 11.9714\n",
            "[256/25][9/69] Loss_D: 0.0001 Loss_G: 13.0899\n",
            "[256/25][10/69] Loss_D: 0.0000 Loss_G: 14.8712\n",
            "[256/25][11/69] Loss_D: 0.0009 Loss_G: 14.2100\n",
            "[256/25][12/69] Loss_D: 0.0042 Loss_G: 11.8866\n",
            "[256/25][13/69] Loss_D: 0.0628 Loss_G: 14.5807\n",
            "[256/25][14/69] Loss_D: 0.0001 Loss_G: 11.6632\n",
            "[256/25][15/69] Loss_D: 0.0001 Loss_G: 11.1021\n",
            "[256/25][16/69] Loss_D: 0.0023 Loss_G: 9.4847\n",
            "[256/25][17/69] Loss_D: 0.0004 Loss_G: 9.5894\n",
            "[256/25][18/69] Loss_D: 0.0016 Loss_G: 9.9457\n",
            "[256/25][19/69] Loss_D: 0.0006 Loss_G: 9.5090\n",
            "[256/25][20/69] Loss_D: 0.0113 Loss_G: 7.1960\n",
            "[256/25][21/69] Loss_D: 0.0132 Loss_G: 7.3425\n",
            "[256/25][22/69] Loss_D: 0.0025 Loss_G: 8.3454\n",
            "[256/25][23/69] Loss_D: 0.0025 Loss_G: 8.6144\n",
            "[256/25][24/69] Loss_D: 0.0004 Loss_G: 9.5175\n",
            "[256/25][25/69] Loss_D: 0.0015 Loss_G: 8.1276\n",
            "[256/25][26/69] Loss_D: 0.0014 Loss_G: 8.2454\n",
            "[256/25][27/69] Loss_D: 0.0023 Loss_G: 8.2520\n",
            "[256/25][28/69] Loss_D: 0.0156 Loss_G: 7.2704\n",
            "[256/25][29/69] Loss_D: 0.0089 Loss_G: 7.2495\n",
            "[256/25][30/69] Loss_D: 0.0129 Loss_G: 7.6382\n",
            "[256/25][31/69] Loss_D: 0.0033 Loss_G: 7.9738\n",
            "[256/25][32/69] Loss_D: 0.0027 Loss_G: 8.9163\n",
            "[256/25][33/69] Loss_D: 0.0021 Loss_G: 8.3686\n",
            "[256/25][34/69] Loss_D: 0.0012 Loss_G: 10.7627\n",
            "[256/25][35/69] Loss_D: 0.0007 Loss_G: 10.0350\n",
            "[256/25][36/69] Loss_D: 0.0035 Loss_G: 9.4420\n",
            "[256/25][37/69] Loss_D: 0.0004 Loss_G: 10.3820\n",
            "[256/25][38/69] Loss_D: 0.0055 Loss_G: 8.2184\n",
            "[256/25][39/69] Loss_D: 0.0011 Loss_G: 8.5306\n",
            "[256/25][40/69] Loss_D: 0.0028 Loss_G: 7.1997\n",
            "[256/25][41/69] Loss_D: 0.0499 Loss_G: 5.5376\n",
            "[256/25][42/69] Loss_D: 0.0126 Loss_G: 4.9980\n",
            "[256/25][43/69] Loss_D: 0.0148 Loss_G: 5.4390\n",
            "[256/25][44/69] Loss_D: 0.0153 Loss_G: 5.9555\n",
            "[256/25][45/69] Loss_D: 0.0367 Loss_G: 6.2179\n",
            "[256/25][46/69] Loss_D: 0.0010 Loss_G: 10.1888\n",
            "[256/25][47/69] Loss_D: 0.0068 Loss_G: 10.4429\n",
            "[256/25][48/69] Loss_D: 0.0014 Loss_G: 9.3931\n",
            "[256/25][49/69] Loss_D: 0.0100 Loss_G: 9.2742\n",
            "[256/25][50/69] Loss_D: 0.0001 Loss_G: 11.0351\n",
            "[256/25][51/69] Loss_D: 0.0889 Loss_G: 8.5381\n",
            "[256/25][52/69] Loss_D: 0.0034 Loss_G: 7.5477\n",
            "[256/25][53/69] Loss_D: 0.0641 Loss_G: 8.2851\n",
            "[256/25][54/69] Loss_D: 0.0009 Loss_G: 9.8110\n",
            "[256/25][55/69] Loss_D: 0.0018 Loss_G: 8.7469\n",
            "[256/25][56/69] Loss_D: 0.0011 Loss_G: 9.1801\n",
            "[256/25][57/69] Loss_D: 0.0013 Loss_G: 8.5288\n",
            "[256/25][58/69] Loss_D: 0.0029 Loss_G: 9.2801\n",
            "[256/25][59/69] Loss_D: 0.0030 Loss_G: 8.0770\n",
            "[256/25][60/69] Loss_D: 0.0021 Loss_G: 8.8188\n",
            "[256/25][61/69] Loss_D: 0.0016 Loss_G: 10.1508\n",
            "[256/25][62/69] Loss_D: 0.0019 Loss_G: 8.5613\n",
            "[256/25][63/69] Loss_D: 0.0040 Loss_G: 8.2952\n",
            "[256/25][64/69] Loss_D: 0.0049 Loss_G: 7.4238\n",
            "[256/25][65/69] Loss_D: 0.0031 Loss_G: 8.0432\n",
            "[256/25][66/69] Loss_D: 0.0038 Loss_G: 7.8248\n",
            "[256/25][67/69] Loss_D: 0.0027 Loss_G: 8.1829\n",
            "[256/25][68/69] Loss_D: 0.0037 Loss_G: 7.6953\n",
            "[257/25][0/69] Loss_D: 0.0006 Loss_G: 9.7976\n",
            "[257/25][1/69] Loss_D: 0.0024 Loss_G: 8.2019\n",
            "[257/25][2/69] Loss_D: 0.0021 Loss_G: 8.6096\n",
            "[257/25][3/69] Loss_D: 0.0252 Loss_G: 7.8014\n",
            "[257/25][4/69] Loss_D: 0.0025 Loss_G: 8.7333\n",
            "[257/25][5/69] Loss_D: 0.0016 Loss_G: 7.7860\n",
            "[257/25][6/69] Loss_D: 0.0036 Loss_G: 6.7823\n",
            "[257/25][7/69] Loss_D: 0.0079 Loss_G: 6.1159\n",
            "[257/25][8/69] Loss_D: 0.0069 Loss_G: 6.3133\n",
            "[257/25][9/69] Loss_D: 0.0067 Loss_G: 6.6174\n",
            "[257/25][10/69] Loss_D: 0.0301 Loss_G: 5.9459\n",
            "[257/25][11/69] Loss_D: 0.0077 Loss_G: 6.6280\n",
            "[257/25][12/69] Loss_D: 0.0121 Loss_G: 6.4006\n",
            "[257/25][13/69] Loss_D: 0.0034 Loss_G: 7.4429\n",
            "[257/25][14/69] Loss_D: 0.0160 Loss_G: 7.0608\n",
            "[257/25][15/69] Loss_D: 0.0024 Loss_G: 7.8372\n",
            "[257/25][16/69] Loss_D: 0.0022 Loss_G: 7.6133\n",
            "[257/25][17/69] Loss_D: 0.0018 Loss_G: 7.8516\n",
            "[257/25][18/69] Loss_D: 0.0010 Loss_G: 9.2142\n",
            "[257/25][19/69] Loss_D: 0.0011 Loss_G: 8.2947\n",
            "[257/25][20/69] Loss_D: 0.0005 Loss_G: 9.1272\n",
            "[257/25][21/69] Loss_D: 0.0049 Loss_G: 8.4452\n",
            "[257/25][22/69] Loss_D: 0.0054 Loss_G: 9.3599\n",
            "[257/25][23/69] Loss_D: 0.0017 Loss_G: 8.2690\n",
            "[257/25][24/69] Loss_D: 0.0013 Loss_G: 8.1087\n",
            "[257/25][25/69] Loss_D: 0.0012 Loss_G: 7.5293\n",
            "[257/25][26/69] Loss_D: 0.0063 Loss_G: 6.4470\n",
            "[257/25][27/69] Loss_D: 0.0063 Loss_G: 6.4860\n",
            "[257/25][28/69] Loss_D: 0.0142 Loss_G: 7.8194\n",
            "[257/25][29/69] Loss_D: 0.0070 Loss_G: 6.6973\n",
            "[257/25][30/69] Loss_D: 0.0022 Loss_G: 7.3330\n",
            "[257/25][31/69] Loss_D: 0.0052 Loss_G: 6.7042\n",
            "[257/25][32/69] Loss_D: 0.0132 Loss_G: 6.0538\n",
            "[257/25][33/69] Loss_D: 0.0104 Loss_G: 6.5834\n",
            "[257/25][34/69] Loss_D: 0.0030 Loss_G: 7.1193\n",
            "[257/25][35/69] Loss_D: 0.0027 Loss_G: 7.3252\n",
            "[257/25][36/69] Loss_D: 0.0005 Loss_G: 8.6105\n",
            "[257/25][37/69] Loss_D: 0.0017 Loss_G: 7.5944\n",
            "[257/25][38/69] Loss_D: 0.0054 Loss_G: 7.4275\n",
            "[257/25][39/69] Loss_D: 0.0022 Loss_G: 8.7690\n",
            "[257/25][40/69] Loss_D: 0.0026 Loss_G: 7.1045\n",
            "[257/25][41/69] Loss_D: 0.0445 Loss_G: 5.7557\n",
            "[257/25][42/69] Loss_D: 0.0048 Loss_G: 5.9711\n",
            "[257/25][43/69] Loss_D: 0.0073 Loss_G: 5.6958\n",
            "[257/25][44/69] Loss_D: 0.0089 Loss_G: 5.4506\n",
            "[257/25][45/69] Loss_D: 0.0076 Loss_G: 5.8704\n",
            "[257/25][46/69] Loss_D: 0.0120 Loss_G: 5.5954\n",
            "[257/25][47/69] Loss_D: 0.0168 Loss_G: 5.9696\n",
            "[257/25][48/69] Loss_D: 0.0037 Loss_G: 7.1085\n",
            "[257/25][49/69] Loss_D: 0.0028 Loss_G: 7.8590\n",
            "[257/25][50/69] Loss_D: 0.0036 Loss_G: 7.1766\n",
            "[257/25][51/69] Loss_D: 0.0016 Loss_G: 9.2597\n",
            "[257/25][52/69] Loss_D: 0.0020 Loss_G: 9.2687\n",
            "[257/25][53/69] Loss_D: 0.0723 Loss_G: 9.4535\n",
            "[257/25][54/69] Loss_D: 0.0033 Loss_G: 6.9785\n",
            "[257/25][55/69] Loss_D: 0.0014 Loss_G: 8.8175\n",
            "[257/25][56/69] Loss_D: 0.0036 Loss_G: 6.9408\n",
            "[257/25][57/69] Loss_D: 0.0043 Loss_G: 7.9086\n",
            "[257/25][58/69] Loss_D: 0.0799 Loss_G: 6.6354\n",
            "[257/25][59/69] Loss_D: 0.0008 Loss_G: 9.1057\n",
            "[257/25][60/69] Loss_D: 0.0038 Loss_G: 7.6302\n",
            "[257/25][61/69] Loss_D: 0.0009 Loss_G: 9.7191\n",
            "[257/25][62/69] Loss_D: 0.0015 Loss_G: 10.4961\n",
            "[257/25][63/69] Loss_D: 0.0013 Loss_G: 10.8643\n",
            "[257/25][64/69] Loss_D: 0.0015 Loss_G: 10.0839\n",
            "[257/25][65/69] Loss_D: 0.0174 Loss_G: 10.0606\n",
            "[257/25][66/69] Loss_D: 0.0037 Loss_G: 9.0695\n",
            "[257/25][67/69] Loss_D: 0.0056 Loss_G: 9.4473\n",
            "[257/25][68/69] Loss_D: 0.0051 Loss_G: 11.4099\n",
            "[258/25][0/69] Loss_D: 0.0064 Loss_G: 9.3285\n",
            "[258/25][1/69] Loss_D: 0.0045 Loss_G: 10.7045\n",
            "[258/25][2/69] Loss_D: 0.0019 Loss_G: 12.0088\n",
            "[258/25][3/69] Loss_D: 0.0018 Loss_G: 11.7430\n",
            "[258/25][4/69] Loss_D: 0.0169 Loss_G: 10.2347\n",
            "[258/25][5/69] Loss_D: 0.0062 Loss_G: 9.0894\n",
            "[258/25][6/69] Loss_D: 0.0077 Loss_G: 8.9930\n",
            "[258/25][7/69] Loss_D: 0.0038 Loss_G: 10.3572\n",
            "[258/25][8/69] Loss_D: 0.0058 Loss_G: 8.9751\n",
            "[258/25][9/69] Loss_D: 0.0028 Loss_G: 9.8589\n",
            "[258/25][10/69] Loss_D: 0.0012 Loss_G: 12.5218\n",
            "[258/25][11/69] Loss_D: 0.0011 Loss_G: 10.6676\n",
            "[258/25][12/69] Loss_D: 0.0012 Loss_G: 8.7807\n",
            "[258/25][13/69] Loss_D: 0.0016 Loss_G: 10.6235\n",
            "[258/25][14/69] Loss_D: 0.0025 Loss_G: 8.1716\n",
            "[258/25][15/69] Loss_D: 0.0117 Loss_G: 9.6233\n",
            "[258/25][16/69] Loss_D: 0.0071 Loss_G: 9.1362\n",
            "[258/25][17/69] Loss_D: 0.0002 Loss_G: 12.1325\n",
            "[258/25][18/69] Loss_D: 0.0033 Loss_G: 8.1107\n",
            "[258/25][19/69] Loss_D: 0.0039 Loss_G: 7.6154\n",
            "[258/25][20/69] Loss_D: 0.0018 Loss_G: 8.3902\n",
            "[258/25][21/69] Loss_D: 0.0012 Loss_G: 9.3758\n",
            "[258/25][22/69] Loss_D: 0.0027 Loss_G: 7.9563\n",
            "[258/25][23/69] Loss_D: 0.0038 Loss_G: 6.7784\n",
            "[258/25][24/69] Loss_D: 0.0026 Loss_G: 7.1797\n",
            "[258/25][25/69] Loss_D: 0.0181 Loss_G: 5.9088\n",
            "[258/25][26/69] Loss_D: 0.0070 Loss_G: 6.4008\n",
            "[258/25][27/69] Loss_D: 0.0073 Loss_G: 6.7719\n",
            "[258/25][28/69] Loss_D: 0.0158 Loss_G: 6.0616\n",
            "[258/25][29/69] Loss_D: 0.0015 Loss_G: 10.0289\n",
            "[258/25][30/69] Loss_D: 0.0166 Loss_G: 9.2570\n",
            "[258/25][31/69] Loss_D: 0.0063 Loss_G: 6.7970\n",
            "[258/25][32/69] Loss_D: 0.0229 Loss_G: 7.1961\n",
            "[258/25][33/69] Loss_D: 0.0107 Loss_G: 7.0283\n",
            "[258/25][34/69] Loss_D: 0.0047 Loss_G: 5.7393\n",
            "[258/25][35/69] Loss_D: 0.0020 Loss_G: 6.7916\n",
            "[258/25][36/69] Loss_D: 0.0053 Loss_G: 6.3236\n",
            "[258/25][37/69] Loss_D: 0.0046 Loss_G: 6.6136\n",
            "[258/25][38/69] Loss_D: 0.0138 Loss_G: 5.7846\n",
            "[258/25][39/69] Loss_D: 0.0057 Loss_G: 7.0165\n",
            "[258/25][40/69] Loss_D: 0.0115 Loss_G: 6.1872\n",
            "[258/25][41/69] Loss_D: 0.0012 Loss_G: 8.3209\n",
            "[258/25][42/69] Loss_D: 0.0070 Loss_G: 6.4360\n",
            "[258/25][43/69] Loss_D: 0.0024 Loss_G: 9.3539\n",
            "[258/25][44/69] Loss_D: 0.0080 Loss_G: 7.8363\n",
            "[258/25][45/69] Loss_D: 0.0027 Loss_G: 8.3636\n",
            "[258/25][46/69] Loss_D: 0.0024 Loss_G: 9.0517\n",
            "[258/25][47/69] Loss_D: 0.0019 Loss_G: 8.8715\n",
            "[258/25][48/69] Loss_D: 0.0020 Loss_G: 7.7386\n",
            "[258/25][49/69] Loss_D: 0.0032 Loss_G: 10.3896\n",
            "[258/25][50/69] Loss_D: 0.0067 Loss_G: 8.2562\n",
            "[258/25][51/69] Loss_D: 0.0007 Loss_G: 8.3119\n",
            "[258/25][52/69] Loss_D: 0.0047 Loss_G: 7.0775\n",
            "[258/25][53/69] Loss_D: 0.0014 Loss_G: 8.8306\n",
            "[258/25][54/69] Loss_D: 0.0024 Loss_G: 7.2281\n",
            "[258/25][55/69] Loss_D: 0.0102 Loss_G: 6.9298\n",
            "[258/25][56/69] Loss_D: 0.0046 Loss_G: 6.4731\n",
            "[258/25][57/69] Loss_D: 0.0010 Loss_G: 7.8485\n",
            "[258/25][58/69] Loss_D: 0.0130 Loss_G: 5.6053\n",
            "[258/25][59/69] Loss_D: 0.0064 Loss_G: 6.2261\n",
            "[258/25][60/69] Loss_D: 0.0024 Loss_G: 7.0175\n",
            "[258/25][61/69] Loss_D: 0.0017 Loss_G: 7.8329\n",
            "[258/25][62/69] Loss_D: 0.0019 Loss_G: 8.2198\n",
            "[258/25][63/69] Loss_D: 0.0024 Loss_G: 7.6012\n",
            "[258/25][64/69] Loss_D: 0.0026 Loss_G: 8.5706\n",
            "[258/25][65/69] Loss_D: 0.0043 Loss_G: 7.2356\n",
            "[258/25][66/69] Loss_D: 0.0306 Loss_G: 6.7915\n",
            "[258/25][67/69] Loss_D: 0.0030 Loss_G: 6.7422\n",
            "[258/25][68/69] Loss_D: 0.0003 Loss_G: 9.4289\n",
            "[259/25][0/69] Loss_D: 0.0194 Loss_G: 4.7476\n",
            "[259/25][1/69] Loss_D: 0.0060 Loss_G: 5.7693\n",
            "[259/25][2/69] Loss_D: 0.0142 Loss_G: 5.2503\n",
            "[259/25][3/69] Loss_D: 0.0184 Loss_G: 5.8507\n",
            "[259/25][4/69] Loss_D: 0.0084 Loss_G: 6.8439\n",
            "[259/25][5/69] Loss_D: 0.0053 Loss_G: 7.7901\n",
            "[259/25][6/69] Loss_D: 0.0016 Loss_G: 8.9201\n",
            "[259/25][7/69] Loss_D: 0.0061 Loss_G: 8.4906\n",
            "[259/25][8/69] Loss_D: 0.0025 Loss_G: 11.1721\n",
            "[259/25][9/69] Loss_D: 0.0019 Loss_G: 8.9285\n",
            "[259/25][10/69] Loss_D: 0.0014 Loss_G: 9.1810\n",
            "[259/25][11/69] Loss_D: 0.0006 Loss_G: 8.9364\n",
            "[259/25][12/69] Loss_D: 0.0014 Loss_G: 9.3793\n",
            "[259/25][13/69] Loss_D: 0.0007 Loss_G: 9.2202\n",
            "[259/25][14/69] Loss_D: 0.0128 Loss_G: 8.7015\n",
            "[259/25][15/69] Loss_D: 0.0011 Loss_G: 8.6533\n",
            "[259/25][16/69] Loss_D: 0.0021 Loss_G: 8.3883\n",
            "[259/25][17/69] Loss_D: 0.0010 Loss_G: 9.0703\n",
            "[259/25][18/69] Loss_D: 0.0061 Loss_G: 7.0753\n",
            "[259/25][19/69] Loss_D: 0.0114 Loss_G: 6.8672\n",
            "[259/25][20/69] Loss_D: 0.0066 Loss_G: 7.4024\n",
            "[259/25][21/69] Loss_D: 0.0007 Loss_G: 10.6807\n",
            "[259/25][22/69] Loss_D: 0.0163 Loss_G: 8.0253\n",
            "[259/25][23/69] Loss_D: 0.0035 Loss_G: 8.3441\n",
            "[259/25][24/69] Loss_D: 0.0021 Loss_G: 7.8968\n",
            "[259/25][25/69] Loss_D: 0.0025 Loss_G: 7.2986\n",
            "[259/25][26/69] Loss_D: 0.0014 Loss_G: 8.0637\n",
            "[259/25][27/69] Loss_D: 0.0026 Loss_G: 6.9295\n",
            "[259/25][28/69] Loss_D: 0.0015 Loss_G: 7.9533\n",
            "[259/25][29/69] Loss_D: 0.0030 Loss_G: 7.1971\n",
            "[259/25][30/69] Loss_D: 0.0025 Loss_G: 6.9296\n",
            "[259/25][31/69] Loss_D: 0.0130 Loss_G: 7.1300\n",
            "[259/25][32/69] Loss_D: 0.0019 Loss_G: 6.7910\n",
            "[259/25][33/69] Loss_D: 0.0027 Loss_G: 6.4283\n",
            "[259/25][34/69] Loss_D: 0.0039 Loss_G: 6.6718\n",
            "[259/25][35/69] Loss_D: 0.0033 Loss_G: 6.6948\n",
            "[259/25][36/69] Loss_D: 0.0068 Loss_G: 6.5080\n",
            "[259/25][37/69] Loss_D: 0.0035 Loss_G: 6.9856\n",
            "[259/25][38/69] Loss_D: 0.0042 Loss_G: 6.6137\n",
            "[259/25][39/69] Loss_D: 0.0097 Loss_G: 7.0868\n",
            "[259/25][40/69] Loss_D: 0.0022 Loss_G: 8.1920\n",
            "[259/25][41/69] Loss_D: 0.0064 Loss_G: 7.2442\n",
            "[259/25][42/69] Loss_D: 0.0009 Loss_G: 8.8062\n",
            "[259/25][43/69] Loss_D: 0.0039 Loss_G: 9.1816\n",
            "[259/25][44/69] Loss_D: 0.0014 Loss_G: 7.8353\n",
            "[259/25][45/69] Loss_D: 0.0217 Loss_G: 6.5506\n",
            "[259/25][46/69] Loss_D: 0.0018 Loss_G: 7.3725\n",
            "[259/25][47/69] Loss_D: 0.0040 Loss_G: 6.9341\n",
            "[259/25][48/69] Loss_D: 0.0053 Loss_G: 6.5201\n",
            "[259/25][49/69] Loss_D: 0.0141 Loss_G: 5.3026\n",
            "[259/25][50/69] Loss_D: 0.0078 Loss_G: 6.0904\n",
            "[259/25][51/69] Loss_D: 0.0062 Loss_G: 6.2843\n",
            "[259/25][52/69] Loss_D: 0.0024 Loss_G: 7.2996\n",
            "[259/25][53/69] Loss_D: 0.0012 Loss_G: 8.0567\n",
            "[259/25][54/69] Loss_D: 0.0005 Loss_G: 10.0372\n",
            "[259/25][55/69] Loss_D: 0.0009 Loss_G: 8.6483\n",
            "[259/25][56/69] Loss_D: 0.0059 Loss_G: 8.2243\n",
            "[259/25][57/69] Loss_D: 0.0120 Loss_G: 9.1745\n",
            "[259/25][58/69] Loss_D: 0.0008 Loss_G: 8.4033\n",
            "[259/25][59/69] Loss_D: 0.0033 Loss_G: 8.1263\n",
            "[259/25][60/69] Loss_D: 0.0002 Loss_G: 9.2172\n",
            "[259/25][61/69] Loss_D: 0.0009 Loss_G: 8.9106\n",
            "[259/25][62/69] Loss_D: 0.0009 Loss_G: 7.7155\n",
            "[259/25][63/69] Loss_D: 0.0056 Loss_G: 7.3576\n",
            "[259/25][64/69] Loss_D: 0.0006 Loss_G: 8.4117\n",
            "[259/25][65/69] Loss_D: 0.0040 Loss_G: 6.6505\n",
            "[259/25][66/69] Loss_D: 0.0016 Loss_G: 7.1289\n",
            "[259/25][67/69] Loss_D: 0.0014 Loss_G: 7.9948\n",
            "[259/25][68/69] Loss_D: 0.0028 Loss_G: 7.0429\n",
            "[260/25][0/69] Loss_D: 0.0250 Loss_G: 6.4423\n",
            "[260/25][1/69] Loss_D: 0.0056 Loss_G: 6.1341\n",
            "[260/25][2/69] Loss_D: 0.0056 Loss_G: 6.7714\n",
            "[260/25][3/69] Loss_D: 0.0175 Loss_G: 5.8592\n",
            "[260/25][4/69] Loss_D: 0.0011 Loss_G: 7.9644\n",
            "[260/25][5/69] Loss_D: 0.0007 Loss_G: 9.0764\n",
            "[260/25][6/69] Loss_D: 0.0008 Loss_G: 8.6260\n",
            "[260/25][7/69] Loss_D: 0.0004 Loss_G: 9.4398\n",
            "[260/25][8/69] Loss_D: 0.0004 Loss_G: 9.5465\n",
            "[260/25][9/69] Loss_D: 0.0007 Loss_G: 10.5996\n",
            "[260/25][10/69] Loss_D: 0.0130 Loss_G: 10.2904\n",
            "[260/25][11/69] Loss_D: 0.0003 Loss_G: 9.4557\n",
            "[260/25][12/69] Loss_D: 0.0012 Loss_G: 10.3505\n",
            "[260/25][13/69] Loss_D: 0.0004 Loss_G: 9.6933\n",
            "[260/25][14/69] Loss_D: 0.0075 Loss_G: 9.1242\n",
            "[260/25][15/69] Loss_D: 0.0009 Loss_G: 8.7110\n",
            "[260/25][16/69] Loss_D: 0.0009 Loss_G: 10.1865\n",
            "[260/25][17/69] Loss_D: 0.0005 Loss_G: 10.0637\n",
            "[260/25][18/69] Loss_D: 0.0014 Loss_G: 7.8163\n",
            "[260/25][19/69] Loss_D: 0.0009 Loss_G: 9.1157\n",
            "[260/25][20/69] Loss_D: 0.0004 Loss_G: 8.9307\n",
            "[260/25][21/69] Loss_D: 0.0030 Loss_G: 6.7273\n",
            "[260/25][22/69] Loss_D: 0.0062 Loss_G: 6.7087\n",
            "[260/25][23/69] Loss_D: 0.0027 Loss_G: 7.0119\n",
            "[260/25][24/69] Loss_D: 0.0042 Loss_G: 6.9204\n",
            "[260/25][25/69] Loss_D: 0.0014 Loss_G: 7.8313\n",
            "[260/25][26/69] Loss_D: 0.0006 Loss_G: 8.2071\n",
            "[260/25][27/69] Loss_D: 0.0002 Loss_G: 9.3339\n",
            "[260/25][28/69] Loss_D: 0.0063 Loss_G: 6.8437\n",
            "[260/25][29/69] Loss_D: 0.0030 Loss_G: 6.5801\n",
            "[260/25][30/69] Loss_D: 0.0206 Loss_G: 7.3947\n",
            "[260/25][31/69] Loss_D: 0.0023 Loss_G: 6.5747\n",
            "[260/25][32/69] Loss_D: 0.0039 Loss_G: 6.3081\n",
            "[260/25][33/69] Loss_D: 0.0018 Loss_G: 6.8942\n",
            "[260/25][34/69] Loss_D: 0.0016 Loss_G: 7.6044\n",
            "[260/25][35/69] Loss_D: 0.0023 Loss_G: 6.6549\n",
            "[260/25][36/69] Loss_D: 0.0026 Loss_G: 6.8434\n",
            "[260/25][37/69] Loss_D: 0.0020 Loss_G: 7.3775\n",
            "[260/25][38/69] Loss_D: 0.0024 Loss_G: 6.8359\n",
            "[260/25][39/69] Loss_D: 0.0016 Loss_G: 7.5184\n",
            "[260/25][40/69] Loss_D: 0.0014 Loss_G: 7.4844\n",
            "[260/25][41/69] Loss_D: 0.0016 Loss_G: 7.2029\n",
            "[260/25][42/69] Loss_D: 0.0011 Loss_G: 7.9398\n",
            "[260/25][43/69] Loss_D: 0.0008 Loss_G: 8.5728\n",
            "[260/25][44/69] Loss_D: 0.0011 Loss_G: 7.7064\n",
            "[260/25][45/69] Loss_D: 0.0004 Loss_G: 9.1169\n",
            "[260/25][46/69] Loss_D: 0.0003 Loss_G: 9.5759\n",
            "[260/25][47/69] Loss_D: 0.0009 Loss_G: 7.8181\n",
            "[260/25][48/69] Loss_D: 0.0002 Loss_G: 9.5792\n",
            "[260/25][49/69] Loss_D: 0.0003 Loss_G: 9.1923\n",
            "[260/25][50/69] Loss_D: 0.0072 Loss_G: 9.0459\n",
            "[260/25][51/69] Loss_D: 0.0008 Loss_G: 8.1862\n",
            "[260/25][52/69] Loss_D: 0.0004 Loss_G: 8.4618\n",
            "[260/25][53/69] Loss_D: 0.0009 Loss_G: 7.5839\n",
            "[260/25][54/69] Loss_D: 0.0073 Loss_G: 9.0453\n",
            "[260/25][55/69] Loss_D: 0.0021 Loss_G: 7.8928\n",
            "[260/25][56/69] Loss_D: 0.0031 Loss_G: 6.6615\n",
            "[260/25][57/69] Loss_D: 0.0011 Loss_G: 8.1147\n",
            "[260/25][58/69] Loss_D: 0.0024 Loss_G: 7.5044\n",
            "[260/25][59/69] Loss_D: 0.0134 Loss_G: 6.5867\n",
            "[260/25][60/69] Loss_D: 0.0073 Loss_G: 6.7879\n",
            "[260/25][61/69] Loss_D: 0.0013 Loss_G: 7.9265\n",
            "[260/25][62/69] Loss_D: 0.0025 Loss_G: 8.1575\n",
            "[260/25][63/69] Loss_D: 0.0039 Loss_G: 6.8444\n",
            "[260/25][64/69] Loss_D: 0.0051 Loss_G: 8.6577\n",
            "[260/25][65/69] Loss_D: 0.0179 Loss_G: 7.7282\n",
            "[260/25][66/69] Loss_D: 0.0028 Loss_G: 6.7013\n",
            "[260/25][67/69] Loss_D: 0.0034 Loss_G: 5.9674\n",
            "[260/25][68/69] Loss_D: 0.0194 Loss_G: 5.0245\n",
            "[261/25][0/69] Loss_D: 0.0067 Loss_G: 6.6879\n",
            "[261/25][1/69] Loss_D: 0.0023 Loss_G: 7.6951\n",
            "[261/25][2/69] Loss_D: 0.0048 Loss_G: 7.0572\n",
            "[261/25][3/69] Loss_D: 0.0041 Loss_G: 7.3099\n",
            "[261/25][4/69] Loss_D: 0.0008 Loss_G: 8.3599\n",
            "[261/25][5/69] Loss_D: 0.0001 Loss_G: 11.4106\n",
            "[261/25][6/69] Loss_D: 0.0025 Loss_G: 8.4138\n",
            "[261/25][7/69] Loss_D: 0.0001 Loss_G: 11.3815\n",
            "[261/25][8/69] Loss_D: 0.0007 Loss_G: 10.9422\n",
            "[261/25][9/69] Loss_D: 0.0028 Loss_G: 11.5094\n",
            "[261/25][10/69] Loss_D: 0.0012 Loss_G: 13.1706\n",
            "[261/25][11/69] Loss_D: 0.0130 Loss_G: 10.7329\n",
            "[261/25][12/69] Loss_D: 0.0030 Loss_G: 12.0962\n",
            "[261/25][13/69] Loss_D: 0.0064 Loss_G: 9.1474\n",
            "[261/25][14/69] Loss_D: 0.0001 Loss_G: 10.9074\n",
            "[261/25][15/69] Loss_D: 0.0003 Loss_G: 9.8801\n",
            "[261/25][16/69] Loss_D: 0.0006 Loss_G: 9.4982\n",
            "[261/25][17/69] Loss_D: 0.0004 Loss_G: 8.7584\n",
            "[261/25][18/69] Loss_D: 0.0033 Loss_G: 8.6027\n",
            "[261/25][19/69] Loss_D: 0.0014 Loss_G: 8.4786\n",
            "[261/25][20/69] Loss_D: 0.0029 Loss_G: 6.8493\n",
            "[261/25][21/69] Loss_D: 0.0154 Loss_G: 6.4304\n",
            "[261/25][22/69] Loss_D: 0.0024 Loss_G: 6.6399\n",
            "[261/25][23/69] Loss_D: 0.0041 Loss_G: 6.0709\n",
            "[261/25][24/69] Loss_D: 0.0031 Loss_G: 6.4816\n",
            "[261/25][25/69] Loss_D: 0.0048 Loss_G: 6.4049\n",
            "[261/25][26/69] Loss_D: 0.0030 Loss_G: 6.9620\n",
            "[261/25][27/69] Loss_D: 0.0101 Loss_G: 5.7893\n",
            "[261/25][28/69] Loss_D: 0.0018 Loss_G: 7.7025\n",
            "[261/25][29/69] Loss_D: 0.0005 Loss_G: 8.6635\n",
            "[261/25][30/69] Loss_D: 0.0027 Loss_G: 7.1734\n",
            "[261/25][31/69] Loss_D: 0.0064 Loss_G: 6.4913\n",
            "[261/25][32/69] Loss_D: 0.0009 Loss_G: 8.3674\n",
            "[261/25][33/69] Loss_D: 0.0005 Loss_G: 9.0048\n",
            "[261/25][34/69] Loss_D: 0.0001 Loss_G: 11.1330\n",
            "[261/25][35/69] Loss_D: 0.0002 Loss_G: 9.9733\n",
            "[261/25][36/69] Loss_D: 0.0003 Loss_G: 9.2236\n",
            "[261/25][37/69] Loss_D: 0.0001 Loss_G: 10.9092\n",
            "[261/25][38/69] Loss_D: 0.0015 Loss_G: 10.9509\n",
            "[261/25][39/69] Loss_D: 0.0001 Loss_G: 10.3275\n",
            "[261/25][40/69] Loss_D: 0.0286 Loss_G: 10.3771\n",
            "[261/25][41/69] Loss_D: 0.1887 Loss_G: 6.1958\n",
            "[261/25][42/69] Loss_D: 0.0062 Loss_G: 3.8421\n",
            "[261/25][43/69] Loss_D: 0.4614 Loss_G: 5.3430\n",
            "[261/25][44/69] Loss_D: 0.0060 Loss_G: 8.9401\n",
            "[261/25][45/69] Loss_D: 0.0020 Loss_G: 12.1879\n",
            "[261/25][46/69] Loss_D: 0.0036 Loss_G: 14.8440\n",
            "[261/25][47/69] Loss_D: 0.6866 Loss_G: 11.2337\n",
            "[261/25][48/69] Loss_D: 0.0041 Loss_G: 9.1262\n",
            "[261/25][49/69] Loss_D: 0.0005 Loss_G: 10.2946\n",
            "[261/25][50/69] Loss_D: 0.0012 Loss_G: 8.9244\n",
            "[261/25][51/69] Loss_D: 0.0042 Loss_G: 9.0989\n",
            "[261/25][52/69] Loss_D: 0.0081 Loss_G: 10.2412\n",
            "[261/25][53/69] Loss_D: 0.0214 Loss_G: 10.8034\n",
            "[261/25][54/69] Loss_D: 0.0241 Loss_G: 10.7925\n",
            "[261/25][55/69] Loss_D: 0.0021 Loss_G: 12.9127\n",
            "[261/25][56/69] Loss_D: 0.0028 Loss_G: 15.2922\n",
            "[261/25][57/69] Loss_D: 0.0131 Loss_G: 14.3507\n",
            "[261/25][58/69] Loss_D: 0.0199 Loss_G: 14.7394\n",
            "[261/25][59/69] Loss_D: 0.0002 Loss_G: 11.9465\n",
            "[261/25][60/69] Loss_D: 0.0008 Loss_G: 13.0124\n",
            "[261/25][61/69] Loss_D: 0.0291 Loss_G: 11.8371\n",
            "[261/25][62/69] Loss_D: 0.0016 Loss_G: 9.2980\n",
            "[261/25][63/69] Loss_D: 0.0078 Loss_G: 7.6809\n",
            "[261/25][64/69] Loss_D: 0.0033 Loss_G: 7.8580\n",
            "[261/25][65/69] Loss_D: 0.0034 Loss_G: 8.7747\n",
            "[261/25][66/69] Loss_D: 0.0369 Loss_G: 7.2414\n",
            "[261/25][67/69] Loss_D: 0.0010 Loss_G: 9.6574\n",
            "[261/25][68/69] Loss_D: 0.0002 Loss_G: 11.9200\n",
            "[262/25][0/69] Loss_D: 0.0007 Loss_G: 9.5517\n",
            "[262/25][1/69] Loss_D: 0.0003 Loss_G: 10.4849\n",
            "[262/25][2/69] Loss_D: 0.0009 Loss_G: 9.7330\n",
            "[262/25][3/69] Loss_D: 0.0015 Loss_G: 9.9581\n",
            "[262/25][4/69] Loss_D: 0.0021 Loss_G: 11.0446\n",
            "[262/25][5/69] Loss_D: 0.0652 Loss_G: 10.3741\n",
            "[262/25][6/69] Loss_D: 0.0059 Loss_G: 7.8026\n",
            "[262/25][7/69] Loss_D: 0.0385 Loss_G: 6.7338\n",
            "[262/25][8/69] Loss_D: 0.0925 Loss_G: 9.1986\n",
            "[262/25][9/69] Loss_D: 0.0002 Loss_G: 14.5164\n",
            "[262/25][10/69] Loss_D: 0.0019 Loss_G: 16.7902\n",
            "[262/25][11/69] Loss_D: 0.0005 Loss_G: 16.7491\n",
            "[262/25][12/69] Loss_D: 0.0159 Loss_G: 17.7165\n",
            "[262/25][13/69] Loss_D: 0.0098 Loss_G: 17.2437\n",
            "[262/25][14/69] Loss_D: 0.0369 Loss_G: 16.6175\n",
            "[262/25][15/69] Loss_D: 0.2234 Loss_G: 13.9133\n",
            "[262/25][16/69] Loss_D: 0.0002 Loss_G: 10.2257\n",
            "[262/25][17/69] Loss_D: 0.0003 Loss_G: 10.0333\n",
            "[262/25][18/69] Loss_D: 0.0047 Loss_G: 8.3917\n",
            "[262/25][19/69] Loss_D: 0.2503 Loss_G: 9.6353\n",
            "[262/25][20/69] Loss_D: 0.0007 Loss_G: 13.5407\n",
            "[262/25][21/69] Loss_D: 0.0001 Loss_G: 15.8819\n",
            "[262/25][22/69] Loss_D: 0.0044 Loss_G: 17.8804\n",
            "[262/25][23/69] Loss_D: 0.0005 Loss_G: 18.5783\n",
            "[262/25][24/69] Loss_D: 0.0101 Loss_G: 20.3180\n",
            "[262/25][25/69] Loss_D: 0.0002 Loss_G: 21.0423\n",
            "[262/25][26/69] Loss_D: 0.1539 Loss_G: 16.3717\n",
            "[262/25][27/69] Loss_D: 0.0000 Loss_G: 15.8557\n",
            "[262/25][28/69] Loss_D: 0.0090 Loss_G: 12.4959\n",
            "[262/25][29/69] Loss_D: 0.0502 Loss_G: 12.1889\n",
            "[262/25][30/69] Loss_D: 0.0009 Loss_G: 13.6124\n",
            "[262/25][31/69] Loss_D: 0.0010 Loss_G: 10.3447\n",
            "[262/25][32/69] Loss_D: 0.0010 Loss_G: 12.4009\n",
            "[262/25][33/69] Loss_D: 0.0007 Loss_G: 14.6291\n",
            "[262/25][34/69] Loss_D: 0.0037 Loss_G: 9.8983\n",
            "[262/25][35/69] Loss_D: 0.0022 Loss_G: 11.2752\n",
            "[262/25][36/69] Loss_D: 0.0070 Loss_G: 10.1754\n",
            "[262/25][37/69] Loss_D: 0.0026 Loss_G: 10.8229\n",
            "[262/25][38/69] Loss_D: 0.0086 Loss_G: 10.1527\n",
            "[262/25][39/69] Loss_D: 0.0018 Loss_G: 12.7388\n",
            "[262/25][40/69] Loss_D: 0.0006 Loss_G: 12.2397\n",
            "[262/25][41/69] Loss_D: 0.0011 Loss_G: 11.2424\n",
            "[262/25][42/69] Loss_D: 0.0068 Loss_G: 11.6496\n",
            "[262/25][43/69] Loss_D: 0.8004 Loss_G: 4.5141\n",
            "[262/25][44/69] Loss_D: 0.3644 Loss_G: 6.7202\n",
            "[262/25][45/69] Loss_D: 0.0575 Loss_G: 9.7578\n",
            "[262/25][46/69] Loss_D: 0.0184 Loss_G: 14.0034\n",
            "[262/25][47/69] Loss_D: 0.0003 Loss_G: 17.6116\n",
            "[262/25][48/69] Loss_D: 0.0002 Loss_G: 20.5812\n",
            "[262/25][49/69] Loss_D: 0.0005 Loss_G: 23.0146\n",
            "[262/25][50/69] Loss_D: 0.7806 Loss_G: 16.1366\n",
            "[262/25][51/69] Loss_D: 0.0194 Loss_G: 12.8699\n",
            "[262/25][52/69] Loss_D: 0.0170 Loss_G: 10.0709\n",
            "[262/25][53/69] Loss_D: 0.1799 Loss_G: 10.4813\n",
            "[262/25][54/69] Loss_D: 0.0046 Loss_G: 11.4995\n",
            "[262/25][55/69] Loss_D: 0.0014 Loss_G: 12.5633\n",
            "[262/25][56/69] Loss_D: 0.0048 Loss_G: 12.9807\n",
            "[262/25][57/69] Loss_D: 0.0041 Loss_G: 13.6166\n",
            "[262/25][58/69] Loss_D: 0.0002 Loss_G: 14.8804\n",
            "[262/25][59/69] Loss_D: 0.0079 Loss_G: 13.2053\n",
            "[262/25][60/69] Loss_D: 0.0240 Loss_G: 14.0118\n",
            "[262/25][61/69] Loss_D: 0.0032 Loss_G: 12.0529\n",
            "[262/25][62/69] Loss_D: 0.0726 Loss_G: 10.3427\n",
            "[262/25][63/69] Loss_D: 0.1147 Loss_G: 12.5824\n",
            "[262/25][64/69] Loss_D: 0.0353 Loss_G: 12.8983\n",
            "[262/25][65/69] Loss_D: 0.1747 Loss_G: 11.1729\n",
            "[262/25][66/69] Loss_D: 0.0035 Loss_G: 9.3341\n",
            "[262/25][67/69] Loss_D: 0.0060 Loss_G: 9.2547\n",
            "[262/25][68/69] Loss_D: 0.0822 Loss_G: 10.0049\n",
            "[263/25][0/69] Loss_D: 0.0074 Loss_G: 10.0000\n",
            "[263/25][1/69] Loss_D: 0.0050 Loss_G: 11.3866\n",
            "[263/25][2/69] Loss_D: 0.0008 Loss_G: 12.5182\n",
            "[263/25][3/69] Loss_D: 0.0579 Loss_G: 12.5523\n",
            "[263/25][4/69] Loss_D: 0.0234 Loss_G: 10.5334\n",
            "[263/25][5/69] Loss_D: 0.0057 Loss_G: 11.3397\n",
            "[263/25][6/69] Loss_D: 0.0120 Loss_G: 9.5308\n",
            "[263/25][7/69] Loss_D: 0.0172 Loss_G: 10.1382\n",
            "[263/25][8/69] Loss_D: 0.0063 Loss_G: 10.2458\n",
            "[263/25][9/69] Loss_D: 0.0049 Loss_G: 10.6679\n",
            "[263/25][10/69] Loss_D: 0.0027 Loss_G: 10.0446\n",
            "[263/25][11/69] Loss_D: 0.0060 Loss_G: 9.8208\n",
            "[263/25][12/69] Loss_D: 0.0057 Loss_G: 9.4676\n",
            "[263/25][13/69] Loss_D: 0.0039 Loss_G: 9.8023\n",
            "[263/25][14/69] Loss_D: 0.0128 Loss_G: 9.1910\n",
            "[263/25][15/69] Loss_D: 0.0178 Loss_G: 8.0300\n",
            "[263/25][16/69] Loss_D: 0.0044 Loss_G: 9.4399\n",
            "[263/25][17/69] Loss_D: 0.0079 Loss_G: 8.5625\n",
            "[263/25][18/69] Loss_D: 0.0164 Loss_G: 8.5535\n",
            "[263/25][19/69] Loss_D: 0.0285 Loss_G: 8.4180\n",
            "[263/25][20/69] Loss_D: 0.0077 Loss_G: 7.3637\n",
            "[263/25][21/69] Loss_D: 0.0149 Loss_G: 6.8080\n",
            "[263/25][22/69] Loss_D: 0.0090 Loss_G: 7.0005\n",
            "[263/25][23/69] Loss_D: 0.0137 Loss_G: 6.5852\n",
            "[263/25][24/69] Loss_D: 0.0120 Loss_G: 6.9291\n",
            "[263/25][25/69] Loss_D: 0.0110 Loss_G: 7.3138\n",
            "[263/25][26/69] Loss_D: 0.0175 Loss_G: 7.8921\n",
            "[263/25][27/69] Loss_D: 0.0042 Loss_G: 9.0680\n",
            "[263/25][28/69] Loss_D: 0.2792 Loss_G: 6.3447\n",
            "[263/25][29/69] Loss_D: 0.0175 Loss_G: 5.2236\n",
            "[263/25][30/69] Loss_D: 0.0283 Loss_G: 5.4668\n",
            "[263/25][31/69] Loss_D: 0.0215 Loss_G: 5.9339\n",
            "[263/25][32/69] Loss_D: 0.0100 Loss_G: 6.9970\n",
            "[263/25][33/69] Loss_D: 0.0090 Loss_G: 7.5364\n",
            "[263/25][34/69] Loss_D: 0.0082 Loss_G: 7.5062\n",
            "[263/25][35/69] Loss_D: 0.0052 Loss_G: 8.0191\n",
            "[263/25][36/69] Loss_D: 0.0019 Loss_G: 8.6988\n",
            "[263/25][37/69] Loss_D: 0.0005 Loss_G: 9.7903\n",
            "[263/25][38/69] Loss_D: 0.0004 Loss_G: 9.7469\n",
            "[263/25][39/69] Loss_D: 0.0003 Loss_G: 10.0462\n",
            "[263/25][40/69] Loss_D: 0.0011 Loss_G: 8.4242\n",
            "[263/25][41/69] Loss_D: 0.0009 Loss_G: 8.7107\n",
            "[263/25][42/69] Loss_D: 0.0005 Loss_G: 9.2888\n",
            "[263/25][43/69] Loss_D: 0.0006 Loss_G: 8.6300\n",
            "[263/25][44/69] Loss_D: 0.0030 Loss_G: 7.1725\n",
            "[263/25][45/69] Loss_D: 0.0030 Loss_G: 7.1352\n",
            "[263/25][46/69] Loss_D: 0.0016 Loss_G: 7.7022\n",
            "[263/25][47/69] Loss_D: 0.0033 Loss_G: 6.9023\n",
            "[263/25][48/69] Loss_D: 0.0129 Loss_G: 6.3169\n",
            "[263/25][49/69] Loss_D: 0.0090 Loss_G: 6.6910\n",
            "[263/25][50/69] Loss_D: 0.0077 Loss_G: 7.1534\n",
            "[263/25][51/69] Loss_D: 0.0059 Loss_G: 7.5841\n",
            "[263/25][52/69] Loss_D: 0.0068 Loss_G: 7.3035\n",
            "[263/25][53/69] Loss_D: 0.0020 Loss_G: 8.8268\n",
            "[263/25][54/69] Loss_D: 0.0516 Loss_G: 7.8910\n",
            "[263/25][55/69] Loss_D: 0.0460 Loss_G: 6.7041\n",
            "[263/25][56/69] Loss_D: 0.0046 Loss_G: 6.1539\n",
            "[263/25][57/69] Loss_D: 0.0111 Loss_G: 5.9691\n",
            "[263/25][58/69] Loss_D: 0.0393 Loss_G: 5.7819\n",
            "[263/25][59/69] Loss_D: 0.0080 Loss_G: 7.0486\n",
            "[263/25][60/69] Loss_D: 0.0024 Loss_G: 8.3624\n",
            "[263/25][61/69] Loss_D: 0.0021 Loss_G: 7.9627\n",
            "[263/25][62/69] Loss_D: 0.0017 Loss_G: 8.7433\n",
            "[263/25][63/69] Loss_D: 0.0005 Loss_G: 9.4795\n",
            "[263/25][64/69] Loss_D: 0.0005 Loss_G: 9.3693\n",
            "[263/25][65/69] Loss_D: 0.0006 Loss_G: 9.8657\n",
            "[263/25][66/69] Loss_D: 0.0007 Loss_G: 9.2366\n",
            "[263/25][67/69] Loss_D: 0.0003 Loss_G: 9.9483\n",
            "[263/25][68/69] Loss_D: 0.0022 Loss_G: 8.9292\n",
            "[264/25][0/69] Loss_D: 0.0005 Loss_G: 9.6437\n",
            "[264/25][1/69] Loss_D: 0.0007 Loss_G: 8.8309\n",
            "[264/25][2/69] Loss_D: 0.0009 Loss_G: 8.8710\n",
            "[264/25][3/69] Loss_D: 0.0044 Loss_G: 8.6762\n",
            "[264/25][4/69] Loss_D: 0.0020 Loss_G: 8.4773\n",
            "[264/25][5/69] Loss_D: 0.0018 Loss_G: 8.0485\n",
            "[264/25][6/69] Loss_D: 0.0046 Loss_G: 7.6820\n",
            "[264/25][7/69] Loss_D: 0.0044 Loss_G: 7.7979\n",
            "[264/25][8/69] Loss_D: 0.0083 Loss_G: 6.8283\n",
            "[264/25][9/69] Loss_D: 0.0075 Loss_G: 7.3342\n",
            "[264/25][10/69] Loss_D: 0.0062 Loss_G: 8.2140\n",
            "[264/25][11/69] Loss_D: 0.0025 Loss_G: 7.7352\n",
            "[264/25][12/69] Loss_D: 0.0053 Loss_G: 8.0192\n",
            "[264/25][13/69] Loss_D: 0.0032 Loss_G: 7.3731\n",
            "[264/25][14/69] Loss_D: 0.0008 Loss_G: 8.6946\n",
            "[264/25][15/69] Loss_D: 0.0026 Loss_G: 8.4036\n",
            "[264/25][16/69] Loss_D: 0.0014 Loss_G: 7.6434\n",
            "[264/25][17/69] Loss_D: 0.0025 Loss_G: 7.8114\n",
            "[264/25][18/69] Loss_D: 0.0011 Loss_G: 7.6639\n",
            "[264/25][19/69] Loss_D: 0.0035 Loss_G: 6.9691\n",
            "[264/25][20/69] Loss_D: 0.0042 Loss_G: 6.5069\n",
            "[264/25][21/69] Loss_D: 0.0033 Loss_G: 6.7625\n",
            "[264/25][22/69] Loss_D: 0.0029 Loss_G: 6.9199\n",
            "[264/25][23/69] Loss_D: 0.0019 Loss_G: 7.9364\n",
            "[264/25][24/69] Loss_D: 0.0035 Loss_G: 7.4018\n",
            "[264/25][25/69] Loss_D: 0.0054 Loss_G: 7.0654\n",
            "[264/25][26/69] Loss_D: 0.0015 Loss_G: 7.7319\n",
            "[264/25][27/69] Loss_D: 0.0029 Loss_G: 7.6600\n",
            "[264/25][28/69] Loss_D: 0.0035 Loss_G: 6.4961\n",
            "[264/25][29/69] Loss_D: 0.0044 Loss_G: 7.0624\n",
            "[264/25][30/69] Loss_D: 0.0075 Loss_G: 7.8508\n",
            "[264/25][31/69] Loss_D: 0.0026 Loss_G: 7.1364\n",
            "[264/25][32/69] Loss_D: 0.2188 Loss_G: 4.7454\n",
            "[264/25][33/69] Loss_D: 0.0428 Loss_G: 4.7908\n",
            "[264/25][34/69] Loss_D: 0.0582 Loss_G: 6.6450\n",
            "[264/25][35/69] Loss_D: 0.0030 Loss_G: 8.8884\n",
            "[264/25][36/69] Loss_D: 0.0011 Loss_G: 9.5761\n",
            "[264/25][37/69] Loss_D: 0.0009 Loss_G: 10.1853\n",
            "[264/25][38/69] Loss_D: 0.0011 Loss_G: 11.9464\n",
            "[264/25][39/69] Loss_D: 0.0003 Loss_G: 10.7618\n",
            "[264/25][40/69] Loss_D: 0.0004 Loss_G: 11.5405\n",
            "[264/25][41/69] Loss_D: 0.0012 Loss_G: 11.8200\n",
            "[264/25][42/69] Loss_D: 0.0000 Loss_G: 16.1609\n",
            "[264/25][43/69] Loss_D: 0.0010 Loss_G: 12.9708\n",
            "[264/25][44/69] Loss_D: 0.0010 Loss_G: 13.5628\n",
            "[264/25][45/69] Loss_D: 0.0019 Loss_G: 11.9193\n",
            "[264/25][46/69] Loss_D: 0.0010 Loss_G: 14.3691\n",
            "[264/25][47/69] Loss_D: 0.0016 Loss_G: 11.6655\n",
            "[264/25][48/69] Loss_D: 0.0022 Loss_G: 11.3522\n",
            "[264/25][49/69] Loss_D: 0.0003 Loss_G: 12.8842\n",
            "[264/25][50/69] Loss_D: 0.0014 Loss_G: 11.8803\n",
            "[264/25][51/69] Loss_D: 0.0011 Loss_G: 12.0832\n",
            "[264/25][52/69] Loss_D: 0.0005 Loss_G: 12.8772\n",
            "[264/25][53/69] Loss_D: 0.0026 Loss_G: 10.2515\n",
            "[264/25][54/69] Loss_D: 0.0021 Loss_G: 10.5863\n",
            "[264/25][55/69] Loss_D: 0.0095 Loss_G: 8.8952\n",
            "[264/25][56/69] Loss_D: 0.0198 Loss_G: 8.6215\n",
            "[264/25][57/69] Loss_D: 0.0031 Loss_G: 10.1048\n",
            "[264/25][58/69] Loss_D: 0.0016 Loss_G: 10.2552\n",
            "[264/25][59/69] Loss_D: 0.0231 Loss_G: 9.5749\n",
            "[264/25][60/69] Loss_D: 0.0009 Loss_G: 10.3947\n",
            "[264/25][61/69] Loss_D: 0.0017 Loss_G: 10.0906\n",
            "[264/25][62/69] Loss_D: 0.0024 Loss_G: 9.5162\n",
            "[264/25][63/69] Loss_D: 0.0324 Loss_G: 8.5952\n",
            "[264/25][64/69] Loss_D: 0.0031 Loss_G: 8.3644\n",
            "[264/25][65/69] Loss_D: 0.0177 Loss_G: 7.6793\n",
            "[264/25][66/69] Loss_D: 0.0080 Loss_G: 8.2350\n",
            "[264/25][67/69] Loss_D: 0.0016 Loss_G: 9.8062\n",
            "[264/25][68/69] Loss_D: 0.0143 Loss_G: 6.8891\n",
            "[265/25][0/69] Loss_D: 0.0006 Loss_G: 9.1568\n",
            "[265/25][1/69] Loss_D: 0.0054 Loss_G: 8.5318\n",
            "[265/25][2/69] Loss_D: 0.0018 Loss_G: 8.2499\n",
            "[265/25][3/69] Loss_D: 0.0027 Loss_G: 9.6401\n",
            "[265/25][4/69] Loss_D: 0.0014 Loss_G: 9.4075\n",
            "[265/25][5/69] Loss_D: 0.0007 Loss_G: 9.0286\n",
            "[265/25][6/69] Loss_D: 0.0013 Loss_G: 10.2427\n",
            "[265/25][7/69] Loss_D: 0.0013 Loss_G: 8.3559\n",
            "[265/25][8/69] Loss_D: 0.0019 Loss_G: 9.0153\n",
            "[265/25][9/69] Loss_D: 0.0003 Loss_G: 11.0745\n",
            "[265/25][10/69] Loss_D: 0.0010 Loss_G: 9.3774\n",
            "[265/25][11/69] Loss_D: 0.0009 Loss_G: 9.8883\n",
            "[265/25][12/69] Loss_D: 0.0029 Loss_G: 9.3189\n",
            "[265/25][13/69] Loss_D: 0.0030 Loss_G: 9.9095\n",
            "[265/25][14/69] Loss_D: 0.0029 Loss_G: 8.9141\n",
            "[265/25][15/69] Loss_D: 0.0026 Loss_G: 8.3196\n",
            "[265/25][16/69] Loss_D: 0.0040 Loss_G: 9.7143\n",
            "[265/25][17/69] Loss_D: 0.0036 Loss_G: 8.0140\n",
            "[265/25][18/69] Loss_D: 0.0172 Loss_G: 7.5032\n",
            "[265/25][19/69] Loss_D: 0.0092 Loss_G: 7.2507\n",
            "[265/25][20/69] Loss_D: 0.0015 Loss_G: 8.0713\n",
            "[265/25][21/69] Loss_D: 0.0054 Loss_G: 7.2824\n",
            "[265/25][22/69] Loss_D: 0.0008 Loss_G: 8.7079\n",
            "[265/25][23/69] Loss_D: 0.0033 Loss_G: 7.5785\n",
            "[265/25][24/69] Loss_D: 0.0011 Loss_G: 9.4082\n",
            "[265/25][25/69] Loss_D: 0.0016 Loss_G: 9.6854\n",
            "[265/25][26/69] Loss_D: 0.0066 Loss_G: 7.0944\n",
            "[265/25][27/69] Loss_D: 0.0118 Loss_G: 8.2068\n",
            "[265/25][28/69] Loss_D: 0.0031 Loss_G: 7.6534\n",
            "[265/25][29/69] Loss_D: 0.0115 Loss_G: 7.2746\n",
            "[265/25][30/69] Loss_D: 0.0363 Loss_G: 8.1357\n",
            "[265/25][31/69] Loss_D: 0.0060 Loss_G: 6.2062\n",
            "[265/25][32/69] Loss_D: 0.0045 Loss_G: 6.4855\n",
            "[265/25][33/69] Loss_D: 0.0325 Loss_G: 5.7361\n",
            "[265/25][34/69] Loss_D: 0.0074 Loss_G: 6.7513\n",
            "[265/25][35/69] Loss_D: 0.0019 Loss_G: 8.2626\n",
            "[265/25][36/69] Loss_D: 0.0012 Loss_G: 8.5342\n",
            "[265/25][37/69] Loss_D: 0.0007 Loss_G: 9.4893\n",
            "[265/25][38/69] Loss_D: 0.0007 Loss_G: 9.3419\n",
            "[265/25][39/69] Loss_D: 0.0015 Loss_G: 8.6306\n",
            "[265/25][40/69] Loss_D: 0.0040 Loss_G: 8.5222\n",
            "[265/25][41/69] Loss_D: 0.0040 Loss_G: 10.3564\n",
            "[265/25][42/69] Loss_D: 0.0043 Loss_G: 11.1476\n",
            "[265/25][43/69] Loss_D: 0.0023 Loss_G: 9.6731\n",
            "[265/25][44/69] Loss_D: 0.0028 Loss_G: 10.6069\n",
            "[265/25][45/69] Loss_D: 0.0008 Loss_G: 10.3823\n",
            "[265/25][46/69] Loss_D: 0.0026 Loss_G: 9.2290\n",
            "[265/25][47/69] Loss_D: 0.0027 Loss_G: 8.4483\n",
            "[265/25][48/69] Loss_D: 0.0017 Loss_G: 9.0820\n",
            "[265/25][49/69] Loss_D: 0.0093 Loss_G: 8.7991\n",
            "[265/25][50/69] Loss_D: 0.0022 Loss_G: 8.7268\n",
            "[265/25][51/69] Loss_D: 0.0006 Loss_G: 9.0693\n",
            "[265/25][52/69] Loss_D: 0.0160 Loss_G: 8.4682\n",
            "[265/25][53/69] Loss_D: 0.0006 Loss_G: 8.8495\n",
            "[265/25][54/69] Loss_D: 0.0027 Loss_G: 7.6031\n",
            "[265/25][55/69] Loss_D: 0.0005 Loss_G: 8.4199\n",
            "[265/25][56/69] Loss_D: 0.0025 Loss_G: 6.9132\n",
            "[265/25][57/69] Loss_D: 0.0013 Loss_G: 7.1840\n",
            "[265/25][58/69] Loss_D: 0.0020 Loss_G: 7.3259\n",
            "[265/25][59/69] Loss_D: 0.0025 Loss_G: 6.8274\n",
            "[265/25][60/69] Loss_D: 0.0095 Loss_G: 5.8516\n",
            "[265/25][61/69] Loss_D: 0.0036 Loss_G: 6.5913\n",
            "[265/25][62/69] Loss_D: 0.0073 Loss_G: 6.0340\n",
            "[265/25][63/69] Loss_D: 0.0032 Loss_G: 7.3655\n",
            "[265/25][64/69] Loss_D: 0.0011 Loss_G: 7.9725\n",
            "[265/25][65/69] Loss_D: 0.1062 Loss_G: 7.3904\n",
            "[265/25][66/69] Loss_D: 0.0044 Loss_G: 5.3628\n",
            "[265/25][67/69] Loss_D: 0.0178 Loss_G: 4.5068\n",
            "[265/25][68/69] Loss_D: 0.0733 Loss_G: 5.1205\n",
            "[266/25][0/69] Loss_D: 0.0081 Loss_G: 7.3091\n",
            "[266/25][1/69] Loss_D: 0.0013 Loss_G: 9.4428\n",
            "[266/25][2/69] Loss_D: 0.0009 Loss_G: 10.1696\n",
            "[266/25][3/69] Loss_D: 0.0016 Loss_G: 10.4783\n",
            "[266/25][4/69] Loss_D: 0.0021 Loss_G: 11.2226\n",
            "[266/25][5/69] Loss_D: 0.0009 Loss_G: 10.3751\n",
            "[266/25][6/69] Loss_D: 0.0163 Loss_G: 11.0207\n",
            "[266/25][7/69] Loss_D: 0.0014 Loss_G: 11.7496\n",
            "[266/25][8/69] Loss_D: 0.0005 Loss_G: 10.7575\n",
            "[266/25][9/69] Loss_D: 0.0004 Loss_G: 11.4218\n",
            "[266/25][10/69] Loss_D: 0.0003 Loss_G: 11.2034\n",
            "[266/25][11/69] Loss_D: 0.0319 Loss_G: 10.4970\n",
            "[266/25][12/69] Loss_D: 0.0490 Loss_G: 8.7393\n",
            "[266/25][13/69] Loss_D: 0.0004 Loss_G: 8.7488\n",
            "[266/25][14/69] Loss_D: 0.0009 Loss_G: 8.0988\n",
            "[266/25][15/69] Loss_D: 0.0040 Loss_G: 7.3467\n",
            "[266/25][16/69] Loss_D: 0.0383 Loss_G: 6.6670\n",
            "[266/25][17/69] Loss_D: 0.0086 Loss_G: 6.7172\n",
            "[266/25][18/69] Loss_D: 0.0059 Loss_G: 7.5747\n",
            "[266/25][19/69] Loss_D: 0.0010 Loss_G: 9.9259\n",
            "[266/25][20/69] Loss_D: 0.0021 Loss_G: 8.5361\n",
            "[266/25][21/69] Loss_D: 0.0028 Loss_G: 9.4275\n",
            "[266/25][22/69] Loss_D: 0.0008 Loss_G: 10.8979\n",
            "[266/25][23/69] Loss_D: 0.0006 Loss_G: 10.9377\n",
            "[266/25][24/69] Loss_D: 0.0046 Loss_G: 8.9043\n",
            "[266/25][25/69] Loss_D: 0.0005 Loss_G: 10.9894\n",
            "[266/25][26/69] Loss_D: 0.0020 Loss_G: 10.2944\n",
            "[266/25][27/69] Loss_D: 0.0019 Loss_G: 10.5745\n",
            "[266/25][28/69] Loss_D: 0.0001 Loss_G: 12.0759\n",
            "[266/25][29/69] Loss_D: 0.0009 Loss_G: 10.7837\n",
            "[266/25][30/69] Loss_D: 0.0018 Loss_G: 9.4267\n",
            "[266/25][31/69] Loss_D: 0.0007 Loss_G: 11.5271\n",
            "[266/25][32/69] Loss_D: 0.0014 Loss_G: 10.3869\n",
            "[266/25][33/69] Loss_D: 0.0003 Loss_G: 11.2145\n",
            "[266/25][34/69] Loss_D: 0.0005 Loss_G: 10.9091\n",
            "[266/25][35/69] Loss_D: 0.0061 Loss_G: 10.3909\n",
            "[266/25][36/69] Loss_D: 0.0048 Loss_G: 9.9342\n",
            "[266/25][37/69] Loss_D: 0.0008 Loss_G: 8.8764\n",
            "[266/25][38/69] Loss_D: 0.0024 Loss_G: 9.1739\n",
            "[266/25][39/69] Loss_D: 0.0011 Loss_G: 9.8225\n",
            "[266/25][40/69] Loss_D: 0.0046 Loss_G: 8.1501\n",
            "[266/25][41/69] Loss_D: 0.0020 Loss_G: 8.2647\n",
            "[266/25][42/69] Loss_D: 0.0012 Loss_G: 8.7888\n",
            "[266/25][43/69] Loss_D: 0.0036 Loss_G: 7.5900\n",
            "[266/25][44/69] Loss_D: 0.0031 Loss_G: 8.2894\n",
            "[266/25][45/69] Loss_D: 0.0031 Loss_G: 7.2966\n",
            "[266/25][46/69] Loss_D: 0.0031 Loss_G: 7.6467\n",
            "[266/25][47/69] Loss_D: 0.0017 Loss_G: 8.4319\n",
            "[266/25][48/69] Loss_D: 0.0072 Loss_G: 6.7142\n",
            "[266/25][49/69] Loss_D: 0.0170 Loss_G: 8.6113\n",
            "[266/25][50/69] Loss_D: 0.0016 Loss_G: 7.8067\n",
            "[266/25][51/69] Loss_D: 0.0084 Loss_G: 6.8214\n",
            "[266/25][52/69] Loss_D: 0.0016 Loss_G: 8.1695\n",
            "[266/25][53/69] Loss_D: 0.0007 Loss_G: 9.6168\n",
            "[266/25][54/69] Loss_D: 0.0013 Loss_G: 7.3165\n",
            "[266/25][55/69] Loss_D: 0.0032 Loss_G: 7.2828\n",
            "[266/25][56/69] Loss_D: 0.0015 Loss_G: 7.7384\n",
            "[266/25][57/69] Loss_D: 0.0007 Loss_G: 8.6676\n",
            "[266/25][58/69] Loss_D: 0.0028 Loss_G: 7.6162\n",
            "[266/25][59/69] Loss_D: 0.0042 Loss_G: 7.0353\n",
            "[266/25][60/69] Loss_D: 0.0045 Loss_G: 7.3164\n",
            "[266/25][61/69] Loss_D: 0.0068 Loss_G: 6.8104\n",
            "[266/25][62/69] Loss_D: 0.0054 Loss_G: 7.2276\n",
            "[266/25][63/69] Loss_D: 0.0056 Loss_G: 7.4931\n",
            "[266/25][64/69] Loss_D: 0.0059 Loss_G: 7.1446\n",
            "[266/25][65/69] Loss_D: 0.0029 Loss_G: 8.9993\n",
            "[266/25][66/69] Loss_D: 0.0025 Loss_G: 7.9317\n",
            "[266/25][67/69] Loss_D: 0.0179 Loss_G: 8.2793\n",
            "[266/25][68/69] Loss_D: 0.1368 Loss_G: 5.7894\n",
            "[267/25][0/69] Loss_D: 0.0023 Loss_G: 5.9519\n",
            "[267/25][1/69] Loss_D: 0.1701 Loss_G: 6.2479\n",
            "[267/25][2/69] Loss_D: 0.0047 Loss_G: 7.6838\n",
            "[267/25][3/69] Loss_D: 0.0049 Loss_G: 8.0811\n",
            "[267/25][4/69] Loss_D: 0.0033 Loss_G: 9.3717\n",
            "[267/25][5/69] Loss_D: 0.0015 Loss_G: 11.3867\n",
            "[267/25][6/69] Loss_D: 0.0012 Loss_G: 12.1965\n",
            "[267/25][7/69] Loss_D: 0.0072 Loss_G: 13.4071\n",
            "[267/25][8/69] Loss_D: 0.0041 Loss_G: 12.2680\n",
            "[267/25][9/69] Loss_D: 0.0048 Loss_G: 13.8876\n",
            "[267/25][10/69] Loss_D: 0.0471 Loss_G: 13.1627\n",
            "[267/25][11/69] Loss_D: 0.0006 Loss_G: 13.5994\n",
            "[267/25][12/69] Loss_D: 0.0010 Loss_G: 11.6717\n",
            "[267/25][13/69] Loss_D: 0.0047 Loss_G: 13.0203\n",
            "[267/25][14/69] Loss_D: 0.0011 Loss_G: 10.8261\n",
            "[267/25][15/69] Loss_D: 0.0013 Loss_G: 10.6795\n",
            "[267/25][16/69] Loss_D: 0.0042 Loss_G: 8.7434\n",
            "[267/25][17/69] Loss_D: 0.0007 Loss_G: 9.6552\n",
            "[267/25][18/69] Loss_D: 0.0024 Loss_G: 9.3593\n",
            "[267/25][19/69] Loss_D: 0.0022 Loss_G: 8.7523\n",
            "[267/25][20/69] Loss_D: 0.0009 Loss_G: 9.5158\n",
            "[267/25][21/69] Loss_D: 0.0067 Loss_G: 7.4188\n",
            "[267/25][22/69] Loss_D: 0.0043 Loss_G: 8.4205\n",
            "[267/25][23/69] Loss_D: 0.0019 Loss_G: 8.3113\n",
            "[267/25][24/69] Loss_D: 0.0056 Loss_G: 6.9615\n",
            "[267/25][25/69] Loss_D: 0.0023 Loss_G: 8.3239\n",
            "[267/25][26/69] Loss_D: 0.0063 Loss_G: 7.2001\n",
            "[267/25][27/69] Loss_D: 0.0036 Loss_G: 7.2187\n",
            "[267/25][28/69] Loss_D: 0.0018 Loss_G: 8.6217\n",
            "[267/25][29/69] Loss_D: 0.0007 Loss_G: 9.5535\n",
            "[267/25][30/69] Loss_D: 0.0026 Loss_G: 9.1039\n",
            "[267/25][31/69] Loss_D: 0.0023 Loss_G: 9.4716\n",
            "[267/25][32/69] Loss_D: 0.0077 Loss_G: 8.9325\n",
            "[267/25][33/69] Loss_D: 0.0020 Loss_G: 9.3953\n",
            "[267/25][34/69] Loss_D: 0.0059 Loss_G: 9.2005\n",
            "[267/25][35/69] Loss_D: 0.0005 Loss_G: 9.5538\n",
            "[267/25][36/69] Loss_D: 0.0013 Loss_G: 8.4753\n",
            "[267/25][37/69] Loss_D: 0.0016 Loss_G: 8.4593\n",
            "[267/25][38/69] Loss_D: 0.0014 Loss_G: 9.8192\n",
            "[267/25][39/69] Loss_D: 0.0017 Loss_G: 8.5460\n",
            "[267/25][40/69] Loss_D: 0.0051 Loss_G: 7.3714\n",
            "[267/25][41/69] Loss_D: 0.0015 Loss_G: 8.4663\n",
            "[267/25][42/69] Loss_D: 0.0008 Loss_G: 9.4873\n",
            "[267/25][43/69] Loss_D: 0.0010 Loss_G: 8.6509\n",
            "[267/25][44/69] Loss_D: 0.0022 Loss_G: 7.6501\n",
            "[267/25][45/69] Loss_D: 0.0024 Loss_G: 9.6427\n",
            "[267/25][46/69] Loss_D: 0.0012 Loss_G: 8.5203\n",
            "[267/25][47/69] Loss_D: 0.0011 Loss_G: 8.7780\n",
            "[267/25][48/69] Loss_D: 0.0062 Loss_G: 8.0010\n",
            "[267/25][49/69] Loss_D: 0.0010 Loss_G: 8.8561\n",
            "[267/25][50/69] Loss_D: 0.0019 Loss_G: 7.9555\n",
            "[267/25][51/69] Loss_D: 0.0006 Loss_G: 9.2751\n",
            "[267/25][52/69] Loss_D: 0.0016 Loss_G: 8.4755\n",
            "[267/25][53/69] Loss_D: 0.0061 Loss_G: 7.7426\n",
            "[267/25][54/69] Loss_D: 0.0053 Loss_G: 6.9481\n",
            "[267/25][55/69] Loss_D: 0.0012 Loss_G: 9.0194\n",
            "[267/25][56/69] Loss_D: 0.0016 Loss_G: 8.2988\n",
            "[267/25][57/69] Loss_D: 0.0039 Loss_G: 8.6482\n",
            "[267/25][58/69] Loss_D: 0.0014 Loss_G: 7.4589\n",
            "[267/25][59/69] Loss_D: 0.0012 Loss_G: 9.3937\n",
            "[267/25][60/69] Loss_D: 0.0052 Loss_G: 7.2162\n",
            "[267/25][61/69] Loss_D: 0.0020 Loss_G: 7.2200\n",
            "[267/25][62/69] Loss_D: 0.0028 Loss_G: 7.4368\n",
            "[267/25][63/69] Loss_D: 0.0080 Loss_G: 7.7575\n",
            "[267/25][64/69] Loss_D: 0.0073 Loss_G: 7.3996\n",
            "[267/25][65/69] Loss_D: 0.0022 Loss_G: 8.9884\n",
            "[267/25][66/69] Loss_D: 0.0022 Loss_G: 7.7319\n",
            "[267/25][67/69] Loss_D: 0.0107 Loss_G: 6.3265\n",
            "[267/25][68/69] Loss_D: 0.0031 Loss_G: 6.9157\n",
            "[268/25][0/69] Loss_D: 0.0015 Loss_G: 7.8844\n",
            "[268/25][1/69] Loss_D: 0.0018 Loss_G: 8.4550\n",
            "[268/25][2/69] Loss_D: 0.0016 Loss_G: 8.6593\n",
            "[268/25][3/69] Loss_D: 0.0194 Loss_G: 9.0654\n",
            "[268/25][4/69] Loss_D: 0.0073 Loss_G: 6.1917\n",
            "[268/25][5/69] Loss_D: 0.0275 Loss_G: 5.8958\n",
            "[268/25][6/69] Loss_D: 0.0063 Loss_G: 7.0553\n",
            "[268/25][7/69] Loss_D: 0.0257 Loss_G: 7.0068\n",
            "[268/25][8/69] Loss_D: 0.0039 Loss_G: 7.3133\n",
            "[268/25][9/69] Loss_D: 0.0009 Loss_G: 9.5394\n",
            "[268/25][10/69] Loss_D: 0.0003 Loss_G: 9.8639\n",
            "[268/25][11/69] Loss_D: 0.0073 Loss_G: 9.3590\n",
            "[268/25][12/69] Loss_D: 0.0010 Loss_G: 8.3445\n",
            "[268/25][13/69] Loss_D: 0.0050 Loss_G: 10.1131\n",
            "[268/25][14/69] Loss_D: 0.0022 Loss_G: 7.8690\n",
            "[268/25][15/69] Loss_D: 0.0002 Loss_G: 9.6538\n",
            "[268/25][16/69] Loss_D: 0.0020 Loss_G: 8.7572\n",
            "[268/25][17/69] Loss_D: 0.0012 Loss_G: 8.0008\n",
            "[268/25][18/69] Loss_D: 0.0018 Loss_G: 7.5943\n",
            "[268/25][19/69] Loss_D: 0.0018 Loss_G: 7.5121\n",
            "[268/25][20/69] Loss_D: 0.0004 Loss_G: 9.2585\n",
            "[268/25][21/69] Loss_D: 0.0020 Loss_G: 10.8693\n",
            "[268/25][22/69] Loss_D: 0.0013 Loss_G: 7.8835\n",
            "[268/25][23/69] Loss_D: 0.0006 Loss_G: 8.2881\n",
            "[268/25][24/69] Loss_D: 0.0017 Loss_G: 8.9363\n",
            "[268/25][25/69] Loss_D: 0.0041 Loss_G: 6.7461\n",
            "[268/25][26/69] Loss_D: 0.0032 Loss_G: 6.6721\n",
            "[268/25][27/69] Loss_D: 0.0003 Loss_G: 9.2573\n",
            "[268/25][28/69] Loss_D: 0.0011 Loss_G: 8.4521\n",
            "[268/25][29/69] Loss_D: 0.0005 Loss_G: 9.4193\n",
            "[268/25][30/69] Loss_D: 0.0021 Loss_G: 7.5416\n",
            "[268/25][31/69] Loss_D: 0.0023 Loss_G: 8.0620\n",
            "[268/25][32/69] Loss_D: 0.0075 Loss_G: 7.3176\n",
            "[268/25][33/69] Loss_D: 0.0047 Loss_G: 6.3759\n",
            "[268/25][34/69] Loss_D: 0.0055 Loss_G: 7.5961\n",
            "[268/25][35/69] Loss_D: 0.0011 Loss_G: 7.9512\n",
            "[268/25][36/69] Loss_D: 0.0008 Loss_G: 8.1821\n",
            "[268/25][37/69] Loss_D: 0.0027 Loss_G: 7.2410\n",
            "[268/25][38/69] Loss_D: 0.0008 Loss_G: 7.9823\n",
            "[268/25][39/69] Loss_D: 0.0004 Loss_G: 8.8728\n",
            "[268/25][40/69] Loss_D: 0.0058 Loss_G: 6.1877\n",
            "[268/25][41/69] Loss_D: 0.0010 Loss_G: 8.2159\n",
            "[268/25][42/69] Loss_D: 0.0023 Loss_G: 7.1254\n",
            "[268/25][43/69] Loss_D: 0.0010 Loss_G: 9.0592\n",
            "[268/25][44/69] Loss_D: 0.0012 Loss_G: 8.8881\n",
            "[268/25][45/69] Loss_D: 0.0049 Loss_G: 7.5451\n",
            "[268/25][46/69] Loss_D: 0.0014 Loss_G: 8.0352\n",
            "[268/25][47/69] Loss_D: 0.0050 Loss_G: 7.8193\n",
            "[268/25][48/69] Loss_D: 0.0039 Loss_G: 6.8419\n",
            "[268/25][49/69] Loss_D: 0.0005 Loss_G: 8.4546\n",
            "[268/25][50/69] Loss_D: 0.0028 Loss_G: 6.6194\n",
            "[268/25][51/69] Loss_D: 0.0059 Loss_G: 8.1324\n",
            "[268/25][52/69] Loss_D: 0.0025 Loss_G: 7.4607\n",
            "[268/25][53/69] Loss_D: 0.0021 Loss_G: 8.0168\n",
            "[268/25][54/69] Loss_D: 0.0017 Loss_G: 7.4262\n",
            "[268/25][55/69] Loss_D: 0.0039 Loss_G: 7.0495\n",
            "[268/25][56/69] Loss_D: 0.0061 Loss_G: 7.1185\n",
            "[268/25][57/69] Loss_D: 0.0029 Loss_G: 7.6390\n",
            "[268/25][58/69] Loss_D: 0.0039 Loss_G: 7.5510\n",
            "[268/25][59/69] Loss_D: 0.0029 Loss_G: 6.7092\n",
            "[268/25][60/69] Loss_D: 0.0392 Loss_G: 7.5973\n",
            "[268/25][61/69] Loss_D: 0.0015 Loss_G: 7.0075\n",
            "[268/25][62/69] Loss_D: 0.0185 Loss_G: 5.4899\n",
            "[268/25][63/69] Loss_D: 0.0078 Loss_G: 6.4968\n",
            "[268/25][64/69] Loss_D: 0.0053 Loss_G: 6.8350\n",
            "[268/25][65/69] Loss_D: 0.0014 Loss_G: 7.9800\n",
            "[268/25][66/69] Loss_D: 0.0046 Loss_G: 6.9000\n",
            "[268/25][67/69] Loss_D: 0.0018 Loss_G: 7.4920\n",
            "[268/25][68/69] Loss_D: 0.0150 Loss_G: 7.0527\n",
            "[269/25][0/69] Loss_D: 0.0007 Loss_G: 8.2866\n",
            "[269/25][1/69] Loss_D: 0.0003 Loss_G: 9.3264\n",
            "[269/25][2/69] Loss_D: 0.0009 Loss_G: 8.3164\n",
            "[269/25][3/69] Loss_D: 0.0006 Loss_G: 8.2801\n",
            "[269/25][4/69] Loss_D: 0.0006 Loss_G: 8.6382\n",
            "[269/25][5/69] Loss_D: 0.0007 Loss_G: 8.0782\n",
            "[269/25][6/69] Loss_D: 0.0004 Loss_G: 8.9845\n",
            "[269/25][7/69] Loss_D: 0.0025 Loss_G: 7.8103\n",
            "[269/25][8/69] Loss_D: 0.0006 Loss_G: 9.3401\n",
            "[269/25][9/69] Loss_D: 0.0011 Loss_G: 7.7825\n",
            "[269/25][10/69] Loss_D: 0.0006 Loss_G: 9.5456\n",
            "[269/25][11/69] Loss_D: 0.0013 Loss_G: 8.3168\n",
            "[269/25][12/69] Loss_D: 0.0014 Loss_G: 7.8868\n",
            "[269/25][13/69] Loss_D: 0.0025 Loss_G: 7.4889\n",
            "[269/25][14/69] Loss_D: 0.0048 Loss_G: 7.8059\n",
            "[269/25][15/69] Loss_D: 0.0022 Loss_G: 7.2270\n",
            "[269/25][16/69] Loss_D: 0.0009 Loss_G: 8.6488\n",
            "[269/25][17/69] Loss_D: 0.0004 Loss_G: 9.0732\n",
            "[269/25][18/69] Loss_D: 0.0019 Loss_G: 7.0608\n",
            "[269/25][19/69] Loss_D: 0.0007 Loss_G: 8.2487\n",
            "[269/25][20/69] Loss_D: 0.0032 Loss_G: 7.3662\n",
            "[269/25][21/69] Loss_D: 0.0012 Loss_G: 8.0180\n",
            "[269/25][22/69] Loss_D: 0.0057 Loss_G: 7.8617\n",
            "[269/25][23/69] Loss_D: 0.0034 Loss_G: 7.4039\n",
            "[269/25][24/69] Loss_D: 0.0004 Loss_G: 8.6486\n",
            "[269/25][25/69] Loss_D: 0.0010 Loss_G: 7.6695\n",
            "[269/25][26/69] Loss_D: 0.0027 Loss_G: 7.6296\n",
            "[269/25][27/69] Loss_D: 0.0012 Loss_G: 8.2853\n",
            "[269/25][28/69] Loss_D: 0.0018 Loss_G: 7.4145\n",
            "[269/25][29/69] Loss_D: 0.0080 Loss_G: 7.9318\n",
            "[269/25][30/69] Loss_D: 0.0021 Loss_G: 7.4779\n",
            "[269/25][31/69] Loss_D: 0.0040 Loss_G: 6.4338\n",
            "[269/25][32/69] Loss_D: 0.0080 Loss_G: 6.0964\n",
            "[269/25][33/69] Loss_D: 0.0032 Loss_G: 7.9220\n",
            "[269/25][34/69] Loss_D: 0.0031 Loss_G: 7.1486\n",
            "[269/25][35/69] Loss_D: 0.0023 Loss_G: 7.1365\n",
            "[269/25][36/69] Loss_D: 0.0004 Loss_G: 8.9004\n",
            "[269/25][37/69] Loss_D: 0.0010 Loss_G: 9.3244\n",
            "[269/25][38/69] Loss_D: 0.0053 Loss_G: 8.5486\n",
            "[269/25][39/69] Loss_D: 0.0086 Loss_G: 6.4104\n",
            "[269/25][40/69] Loss_D: 0.0038 Loss_G: 6.8298\n",
            "[269/25][41/69] Loss_D: 0.0027 Loss_G: 6.8564\n",
            "[269/25][42/69] Loss_D: 0.0029 Loss_G: 6.7729\n",
            "[269/25][43/69] Loss_D: 0.0018 Loss_G: 7.2578\n",
            "[269/25][44/69] Loss_D: 0.0007 Loss_G: 8.7342\n",
            "[269/25][45/69] Loss_D: 0.0006 Loss_G: 8.3577\n",
            "[269/25][46/69] Loss_D: 0.0025 Loss_G: 9.0790\n",
            "[269/25][47/69] Loss_D: 0.0011 Loss_G: 9.0256\n",
            "[269/25][48/69] Loss_D: 0.0038 Loss_G: 8.6239\n",
            "[269/25][49/69] Loss_D: 0.0143 Loss_G: 7.7818\n",
            "[269/25][50/69] Loss_D: 0.0070 Loss_G: 6.9818\n",
            "[269/25][51/69] Loss_D: 0.0013 Loss_G: 7.3929\n",
            "[269/25][52/69] Loss_D: 0.0013 Loss_G: 7.3071\n",
            "[269/25][53/69] Loss_D: 0.0009 Loss_G: 8.0924\n",
            "[269/25][54/69] Loss_D: 0.0184 Loss_G: 5.7810\n",
            "[269/25][55/69] Loss_D: 0.0033 Loss_G: 6.5630\n",
            "[269/25][56/69] Loss_D: 0.0046 Loss_G: 6.6962\n",
            "[269/25][57/69] Loss_D: 0.0142 Loss_G: 5.8914\n",
            "[269/25][58/69] Loss_D: 0.0008 Loss_G: 8.6215\n",
            "[269/25][59/69] Loss_D: 0.0008 Loss_G: 8.7419\n",
            "[269/25][60/69] Loss_D: 0.0033 Loss_G: 6.7016\n",
            "[269/25][61/69] Loss_D: 0.0100 Loss_G: 6.5803\n",
            "[269/25][62/69] Loss_D: 0.0011 Loss_G: 8.3175\n",
            "[269/25][63/69] Loss_D: 0.0036 Loss_G: 7.4196\n",
            "[269/25][64/69] Loss_D: 0.0054 Loss_G: 6.9288\n",
            "[269/25][65/69] Loss_D: 0.0007 Loss_G: 9.1707\n",
            "[269/25][66/69] Loss_D: 0.0012 Loss_G: 7.9325\n",
            "[269/25][67/69] Loss_D: 0.0041 Loss_G: 8.1070\n",
            "[269/25][68/69] Loss_D: 0.0020 Loss_G: 7.1800\n",
            "[270/25][0/69] Loss_D: 0.0012 Loss_G: 8.2719\n",
            "[270/25][1/69] Loss_D: 0.0063 Loss_G: 8.9624\n",
            "[270/25][2/69] Loss_D: 0.0011 Loss_G: 7.4765\n",
            "[270/25][3/69] Loss_D: 0.0003 Loss_G: 9.5655\n",
            "[270/25][4/69] Loss_D: 0.0016 Loss_G: 7.3694\n",
            "[270/25][5/69] Loss_D: 0.0016 Loss_G: 8.2283\n",
            "[270/25][6/69] Loss_D: 0.0009 Loss_G: 8.3630\n",
            "[270/25][7/69] Loss_D: 0.0050 Loss_G: 7.5349\n",
            "[270/25][8/69] Loss_D: 0.0012 Loss_G: 8.3009\n",
            "[270/25][9/69] Loss_D: 0.0004 Loss_G: 8.9603\n",
            "[270/25][10/69] Loss_D: 0.0006 Loss_G: 9.2087\n",
            "[270/25][11/69] Loss_D: 0.0007 Loss_G: 9.8199\n",
            "[270/25][12/69] Loss_D: 0.0019 Loss_G: 7.2831\n",
            "[270/25][13/69] Loss_D: 0.0153 Loss_G: 8.6039\n",
            "[270/25][14/69] Loss_D: 0.0008 Loss_G: 8.3030\n",
            "[270/25][15/69] Loss_D: 0.0002 Loss_G: 9.7397\n",
            "[270/25][16/69] Loss_D: 0.0020 Loss_G: 7.4334\n",
            "[270/25][17/69] Loss_D: 0.0049 Loss_G: 6.4934\n",
            "[270/25][18/69] Loss_D: 0.0007 Loss_G: 8.2106\n",
            "[270/25][19/69] Loss_D: 0.0034 Loss_G: 6.9707\n",
            "[270/25][20/69] Loss_D: 0.0042 Loss_G: 6.8130\n",
            "[270/25][21/69] Loss_D: 0.0046 Loss_G: 6.4688\n",
            "[270/25][22/69] Loss_D: 0.0023 Loss_G: 7.4437\n",
            "[270/25][23/69] Loss_D: 0.0079 Loss_G: 6.2545\n",
            "[270/25][24/69] Loss_D: 0.0031 Loss_G: 7.4777\n",
            "[270/25][25/69] Loss_D: 0.0012 Loss_G: 8.5441\n",
            "[270/25][26/69] Loss_D: 0.0065 Loss_G: 8.4639\n",
            "[270/25][27/69] Loss_D: 0.0010 Loss_G: 9.0322\n",
            "[270/25][28/69] Loss_D: 0.0007 Loss_G: 9.1116\n",
            "[270/25][29/69] Loss_D: 0.0005 Loss_G: 9.0581\n",
            "[270/25][30/69] Loss_D: 0.0073 Loss_G: 8.4712\n",
            "[270/25][31/69] Loss_D: 0.0034 Loss_G: 10.4361\n",
            "[270/25][32/69] Loss_D: 0.0005 Loss_G: 8.7182\n",
            "[270/25][33/69] Loss_D: 0.0008 Loss_G: 9.0716\n",
            "[270/25][34/69] Loss_D: 0.0010 Loss_G: 7.5802\n",
            "[270/25][35/69] Loss_D: 0.0008 Loss_G: 8.5315\n",
            "[270/25][36/69] Loss_D: 0.0009 Loss_G: 8.0256\n",
            "[270/25][37/69] Loss_D: 0.0279 Loss_G: 8.0501\n",
            "[270/25][38/69] Loss_D: 0.0020 Loss_G: 6.4576\n",
            "[270/25][39/69] Loss_D: 0.0029 Loss_G: 6.4051\n",
            "[270/25][40/69] Loss_D: 0.0028 Loss_G: 6.4632\n",
            "[270/25][41/69] Loss_D: 0.0021 Loss_G: 7.4214\n",
            "[270/25][42/69] Loss_D: 0.0124 Loss_G: 5.8468\n",
            "[270/25][43/69] Loss_D: 0.0052 Loss_G: 6.7927\n",
            "[270/25][44/69] Loss_D: 0.0010 Loss_G: 7.9810\n",
            "[270/25][45/69] Loss_D: 0.0023 Loss_G: 7.3158\n",
            "[270/25][46/69] Loss_D: 0.0067 Loss_G: 6.5752\n",
            "[270/25][47/69] Loss_D: 0.0038 Loss_G: 7.9515\n",
            "[270/25][48/69] Loss_D: 0.0020 Loss_G: 7.8557\n",
            "[270/25][49/69] Loss_D: 0.0008 Loss_G: 8.2747\n",
            "[270/25][50/69] Loss_D: 0.0021 Loss_G: 7.4814\n",
            "[270/25][51/69] Loss_D: 0.0004 Loss_G: 9.5407\n",
            "[270/25][52/69] Loss_D: 0.0011 Loss_G: 8.4477\n",
            "[270/25][53/69] Loss_D: 0.0008 Loss_G: 10.0218\n",
            "[270/25][54/69] Loss_D: 0.0008 Loss_G: 9.5699\n",
            "[270/25][55/69] Loss_D: 0.0005 Loss_G: 8.9814\n",
            "[270/25][56/69] Loss_D: 0.0039 Loss_G: 9.5430\n",
            "[270/25][57/69] Loss_D: 0.0026 Loss_G: 8.9717\n",
            "[270/25][58/69] Loss_D: 0.0002 Loss_G: 11.9344\n",
            "[270/25][59/69] Loss_D: 0.0001 Loss_G: 9.9723\n",
            "[270/25][60/69] Loss_D: 0.0021 Loss_G: 9.3499\n",
            "[270/25][61/69] Loss_D: 0.0008 Loss_G: 9.0623\n",
            "[270/25][62/69] Loss_D: 0.0023 Loss_G: 9.6366\n",
            "[270/25][63/69] Loss_D: 0.0141 Loss_G: 7.6265\n",
            "[270/25][64/69] Loss_D: 0.0005 Loss_G: 8.0651\n",
            "[270/25][65/69] Loss_D: 0.0017 Loss_G: 7.3181\n",
            "[270/25][66/69] Loss_D: 0.0017 Loss_G: 8.6721\n",
            "[270/25][67/69] Loss_D: 0.0030 Loss_G: 6.9968\n",
            "[270/25][68/69] Loss_D: 0.0105 Loss_G: 5.9629\n",
            "[271/25][0/69] Loss_D: 0.0056 Loss_G: 6.6795\n",
            "[271/25][1/69] Loss_D: 0.0006 Loss_G: 8.7729\n",
            "[271/25][2/69] Loss_D: 0.0015 Loss_G: 8.1449\n",
            "[271/25][3/69] Loss_D: 0.0005 Loss_G: 9.3863\n",
            "[271/25][4/69] Loss_D: 0.0009 Loss_G: 8.9514\n",
            "[271/25][5/69] Loss_D: 0.0009 Loss_G: 9.0542\n",
            "[271/25][6/69] Loss_D: 0.0004 Loss_G: 10.8461\n",
            "[271/25][7/69] Loss_D: 0.0009 Loss_G: 9.1206\n",
            "[271/25][8/69] Loss_D: 0.0011 Loss_G: 8.7990\n",
            "[271/25][9/69] Loss_D: 0.0029 Loss_G: 7.9240\n",
            "[271/25][10/69] Loss_D: 0.0008 Loss_G: 9.1851\n",
            "[271/25][11/69] Loss_D: 0.0005 Loss_G: 9.0487\n",
            "[271/25][12/69] Loss_D: 0.0043 Loss_G: 9.2841\n",
            "[271/25][13/69] Loss_D: 0.0158 Loss_G: 8.2857\n",
            "[271/25][14/69] Loss_D: 0.0013 Loss_G: 7.9541\n",
            "[271/25][15/69] Loss_D: 0.0018 Loss_G: 8.9728\n",
            "[271/25][16/69] Loss_D: 0.0020 Loss_G: 7.8129\n",
            "[271/25][17/69] Loss_D: 0.0017 Loss_G: 6.9076\n",
            "[271/25][18/69] Loss_D: 0.0020 Loss_G: 7.0778\n",
            "[271/25][19/69] Loss_D: 0.0017 Loss_G: 7.9357\n",
            "[271/25][20/69] Loss_D: 0.0008 Loss_G: 8.4444\n",
            "[271/25][21/69] Loss_D: 0.0056 Loss_G: 6.3844\n",
            "[271/25][22/69] Loss_D: 0.0180 Loss_G: 5.6778\n",
            "[271/25][23/69] Loss_D: 0.0022 Loss_G: 7.5192\n",
            "[271/25][24/69] Loss_D: 0.0016 Loss_G: 8.3493\n",
            "[271/25][25/69] Loss_D: 0.0012 Loss_G: 8.4225\n",
            "[271/25][26/69] Loss_D: 0.0047 Loss_G: 10.8483\n",
            "[271/25][27/69] Loss_D: 0.0907 Loss_G: 8.8311\n",
            "[271/25][28/69] Loss_D: 0.0058 Loss_G: 5.8776\n",
            "[271/25][29/69] Loss_D: 0.0659 Loss_G: 7.3849\n",
            "[271/25][30/69] Loss_D: 0.0091 Loss_G: 7.9850\n",
            "[271/25][31/69] Loss_D: 0.0009 Loss_G: 9.7078\n",
            "[271/25][32/69] Loss_D: 0.0006 Loss_G: 10.8353\n",
            "[271/25][33/69] Loss_D: 0.0022 Loss_G: 9.7335\n",
            "[271/25][34/69] Loss_D: 0.0019 Loss_G: 9.8570\n",
            "[271/25][35/69] Loss_D: 0.0027 Loss_G: 12.9260\n",
            "[271/25][36/69] Loss_D: 0.0003 Loss_G: 13.2442\n",
            "[271/25][37/69] Loss_D: 0.0014 Loss_G: 13.6742\n",
            "[271/25][38/69] Loss_D: 0.0003 Loss_G: 12.7674\n",
            "[271/25][39/69] Loss_D: 0.0003 Loss_G: 12.4284\n",
            "[271/25][40/69] Loss_D: 0.0007 Loss_G: 12.2136\n",
            "[271/25][41/69] Loss_D: 0.0008 Loss_G: 11.9811\n",
            "[271/25][42/69] Loss_D: 0.0011 Loss_G: 12.0131\n",
            "[271/25][43/69] Loss_D: 0.0055 Loss_G: 11.2971\n",
            "[271/25][44/69] Loss_D: 0.0039 Loss_G: 13.0616\n",
            "[271/25][45/69] Loss_D: 0.0003 Loss_G: 12.4485\n",
            "[271/25][46/69] Loss_D: 0.0014 Loss_G: 12.9295\n",
            "[271/25][47/69] Loss_D: 0.0011 Loss_G: 11.5529\n",
            "[271/25][48/69] Loss_D: 0.0019 Loss_G: 12.6246\n",
            "[271/25][49/69] Loss_D: 0.0010 Loss_G: 12.0234\n",
            "[271/25][50/69] Loss_D: 0.0054 Loss_G: 10.5300\n",
            "[271/25][51/69] Loss_D: 0.2227 Loss_G: 8.7129\n",
            "[271/25][52/69] Loss_D: 0.0046 Loss_G: 5.4686\n",
            "[271/25][53/69] Loss_D: 0.0191 Loss_G: 4.1830\n",
            "[271/25][54/69] Loss_D: 0.0815 Loss_G: 5.6524\n",
            "[271/25][55/69] Loss_D: 0.0091 Loss_G: 8.9189\n",
            "[271/25][56/69] Loss_D: 0.0027 Loss_G: 10.0364\n",
            "[271/25][57/69] Loss_D: 0.0015 Loss_G: 10.4181\n",
            "[271/25][58/69] Loss_D: 0.0103 Loss_G: 12.0058\n",
            "[271/25][59/69] Loss_D: 0.0005 Loss_G: 14.5784\n",
            "[271/25][60/69] Loss_D: 0.0017 Loss_G: 13.6702\n",
            "[271/25][61/69] Loss_D: 0.0123 Loss_G: 12.4754\n",
            "[271/25][62/69] Loss_D: 0.2013 Loss_G: 7.1614\n",
            "[271/25][63/69] Loss_D: 0.0016 Loss_G: 5.6191\n",
            "[271/25][64/69] Loss_D: 0.0435 Loss_G: 5.2577\n",
            "[271/25][65/69] Loss_D: 0.0456 Loss_G: 5.9612\n",
            "[271/25][66/69] Loss_D: 0.0438 Loss_G: 8.2082\n",
            "[271/25][67/69] Loss_D: 0.0018 Loss_G: 10.5591\n",
            "[271/25][68/69] Loss_D: 0.0033 Loss_G: 12.3829\n",
            "[272/25][0/69] Loss_D: 0.0001 Loss_G: 17.3771\n",
            "[272/25][1/69] Loss_D: 0.0022 Loss_G: 18.5778\n",
            "[272/25][2/69] Loss_D: 0.0127 Loss_G: 17.2366\n",
            "[272/25][3/69] Loss_D: 0.0496 Loss_G: 15.7607\n",
            "[272/25][4/69] Loss_D: 0.0701 Loss_G: 16.4988\n",
            "[272/25][5/69] Loss_D: 0.0001 Loss_G: 15.4450\n",
            "[272/25][6/69] Loss_D: 0.0453 Loss_G: 9.5657\n",
            "[272/25][7/69] Loss_D: 0.0046 Loss_G: 12.0404\n",
            "[272/25][8/69] Loss_D: 0.0322 Loss_G: 8.6710\n",
            "[272/25][9/69] Loss_D: 0.1235 Loss_G: 7.3067\n",
            "[272/25][10/69] Loss_D: 0.0016 Loss_G: 10.6589\n",
            "[272/25][11/69] Loss_D: 0.0003 Loss_G: 11.9004\n",
            "[272/25][12/69] Loss_D: 0.0079 Loss_G: 10.0186\n",
            "[272/25][13/69] Loss_D: 0.0004 Loss_G: 14.1187\n",
            "[272/25][14/69] Loss_D: 0.0016 Loss_G: 11.7190\n",
            "[272/25][15/69] Loss_D: 0.0020 Loss_G: 12.9014\n",
            "[272/25][16/69] Loss_D: 0.0018 Loss_G: 15.1187\n",
            "[272/25][17/69] Loss_D: 0.0006 Loss_G: 14.6607\n",
            "[272/25][18/69] Loss_D: 0.0009 Loss_G: 18.1988\n",
            "[272/25][19/69] Loss_D: 0.0042 Loss_G: 17.0132\n",
            "[272/25][20/69] Loss_D: 0.0010 Loss_G: 17.1960\n",
            "[272/25][21/69] Loss_D: 0.0011 Loss_G: 14.3674\n",
            "[272/25][22/69] Loss_D: 0.6155 Loss_G: 12.0555\n",
            "[272/25][23/69] Loss_D: 0.0023 Loss_G: 12.1331\n",
            "[272/25][24/69] Loss_D: 0.0542 Loss_G: 14.6473\n",
            "[272/25][25/69] Loss_D: 0.0416 Loss_G: 11.4080\n",
            "[272/25][26/69] Loss_D: 0.0301 Loss_G: 13.1956\n",
            "[272/25][27/69] Loss_D: 0.0004 Loss_G: 13.7061\n",
            "[272/25][28/69] Loss_D: 0.0005 Loss_G: 16.3097\n",
            "[272/25][29/69] Loss_D: 0.0001 Loss_G: 16.7408\n",
            "[272/25][30/69] Loss_D: 0.0002 Loss_G: 16.3305\n",
            "[272/25][31/69] Loss_D: 0.0008 Loss_G: 16.4874\n",
            "[272/25][32/69] Loss_D: 0.0005 Loss_G: 17.8009\n",
            "[272/25][33/69] Loss_D: 0.0051 Loss_G: 18.3744\n",
            "[272/25][34/69] Loss_D: 0.1063 Loss_G: 14.0292\n",
            "[272/25][35/69] Loss_D: 0.0027 Loss_G: 12.2249\n",
            "[272/25][36/69] Loss_D: 0.0041 Loss_G: 12.6706\n",
            "[272/25][37/69] Loss_D: 0.0062 Loss_G: 12.5869\n",
            "[272/25][38/69] Loss_D: 0.0185 Loss_G: 10.4139\n",
            "[272/25][39/69] Loss_D: 0.0062 Loss_G: 10.8811\n",
            "[272/25][40/69] Loss_D: 0.0056 Loss_G: 12.4210\n",
            "[272/25][41/69] Loss_D: 0.0119 Loss_G: 9.7840\n",
            "[272/25][42/69] Loss_D: 0.0150 Loss_G: 12.3616\n",
            "[272/25][43/69] Loss_D: 0.0280 Loss_G: 11.6693\n",
            "[272/25][44/69] Loss_D: 0.0065 Loss_G: 14.3413\n",
            "[272/25][45/69] Loss_D: 0.0009 Loss_G: 14.2340\n",
            "[272/25][46/69] Loss_D: 0.0854 Loss_G: 14.5665\n",
            "[272/25][47/69] Loss_D: 0.0015 Loss_G: 13.3173\n",
            "[272/25][48/69] Loss_D: 0.1170 Loss_G: 13.2704\n",
            "[272/25][49/69] Loss_D: 0.0004 Loss_G: 11.6354\n",
            "[272/25][50/69] Loss_D: 0.0059 Loss_G: 9.8749\n",
            "[272/25][51/69] Loss_D: 0.0529 Loss_G: 10.9566\n",
            "[272/25][52/69] Loss_D: 0.0187 Loss_G: 10.1610\n",
            "[272/25][53/69] Loss_D: 0.0132 Loss_G: 11.4299\n",
            "[272/25][54/69] Loss_D: 0.0003 Loss_G: 12.9973\n",
            "[272/25][55/69] Loss_D: 0.0004 Loss_G: 11.5886\n",
            "[272/25][56/69] Loss_D: 0.0003 Loss_G: 11.9895\n",
            "[272/25][57/69] Loss_D: 0.0004 Loss_G: 12.4920\n",
            "[272/25][58/69] Loss_D: 0.0009 Loss_G: 12.8012\n",
            "[272/25][59/69] Loss_D: 0.0058 Loss_G: 13.0832\n",
            "[272/25][60/69] Loss_D: 0.0003 Loss_G: 13.0231\n",
            "[272/25][61/69] Loss_D: 0.0008 Loss_G: 12.6925\n",
            "[272/25][62/69] Loss_D: 0.0001 Loss_G: 13.8965\n",
            "[272/25][63/69] Loss_D: 0.0020 Loss_G: 13.3357\n",
            "[272/25][64/69] Loss_D: 0.0003 Loss_G: 13.6157\n",
            "[272/25][65/69] Loss_D: 0.0006 Loss_G: 12.9003\n",
            "[272/25][66/69] Loss_D: 0.0005 Loss_G: 13.0403\n",
            "[272/25][67/69] Loss_D: 0.0008 Loss_G: 12.3523\n",
            "[272/25][68/69] Loss_D: 0.0669 Loss_G: 16.2737\n",
            "[273/25][0/69] Loss_D: 0.0016 Loss_G: 14.8177\n",
            "[273/25][1/69] Loss_D: 0.0003 Loss_G: 15.0564\n",
            "[273/25][2/69] Loss_D: 0.0007 Loss_G: 17.3300\n",
            "[273/25][3/69] Loss_D: 0.0050 Loss_G: 16.4119\n",
            "[273/25][4/69] Loss_D: 0.0083 Loss_G: 15.9554\n",
            "[273/25][5/69] Loss_D: 0.0096 Loss_G: 18.1393\n",
            "[273/25][6/69] Loss_D: 0.0061 Loss_G: 15.0340\n",
            "[273/25][7/69] Loss_D: 0.4187 Loss_G: 9.3662\n",
            "[273/25][8/69] Loss_D: 0.0027 Loss_G: 6.9362\n",
            "[273/25][9/69] Loss_D: 0.2169 Loss_G: 7.9295\n",
            "[273/25][10/69] Loss_D: 0.0033 Loss_G: 10.9417\n",
            "[273/25][11/69] Loss_D: 0.0004 Loss_G: 12.8245\n",
            "[273/25][12/69] Loss_D: 0.0001 Loss_G: 14.2057\n",
            "[273/25][13/69] Loss_D: 0.0004 Loss_G: 14.4182\n",
            "[273/25][14/69] Loss_D: 0.0001 Loss_G: 17.6725\n",
            "[273/25][15/69] Loss_D: 0.0001 Loss_G: 17.0821\n",
            "[273/25][16/69] Loss_D: 0.0013 Loss_G: 17.3924\n",
            "[273/25][17/69] Loss_D: 0.0074 Loss_G: 18.0611\n",
            "[273/25][18/69] Loss_D: 0.0010 Loss_G: 17.5442\n",
            "[273/25][19/69] Loss_D: 0.2057 Loss_G: 14.6595\n",
            "[273/25][20/69] Loss_D: 0.0508 Loss_G: 15.1391\n",
            "[273/25][21/69] Loss_D: 0.0815 Loss_G: 16.5962\n",
            "[273/25][22/69] Loss_D: 0.0008 Loss_G: 17.0404\n",
            "[273/25][23/69] Loss_D: 0.0002 Loss_G: 17.7744\n",
            "[273/25][24/69] Loss_D: 0.0036 Loss_G: 20.5730\n",
            "[273/25][25/69] Loss_D: 0.1415 Loss_G: 16.4846\n",
            "[273/25][26/69] Loss_D: 0.0004 Loss_G: 16.9123\n",
            "[273/25][27/69] Loss_D: 0.0019 Loss_G: 15.3098\n",
            "[273/25][28/69] Loss_D: 0.0011 Loss_G: 14.8406\n",
            "[273/25][29/69] Loss_D: 0.0089 Loss_G: 13.7230\n",
            "[273/25][30/69] Loss_D: 0.0114 Loss_G: 13.6819\n",
            "[273/25][31/69] Loss_D: 0.0115 Loss_G: 14.5941\n",
            "[273/25][32/69] Loss_D: 0.0007 Loss_G: 15.0565\n",
            "[273/25][33/69] Loss_D: 0.0057 Loss_G: 12.9277\n",
            "[273/25][34/69] Loss_D: 0.0044 Loss_G: 14.4137\n",
            "[273/25][35/69] Loss_D: 0.0065 Loss_G: 13.0844\n",
            "[273/25][36/69] Loss_D: 0.0005 Loss_G: 14.2366\n",
            "[273/25][37/69] Loss_D: 0.0113 Loss_G: 13.6031\n",
            "[273/25][38/69] Loss_D: 0.0046 Loss_G: 13.3928\n",
            "[273/25][39/69] Loss_D: 0.0021 Loss_G: 12.2361\n",
            "[273/25][40/69] Loss_D: 0.0039 Loss_G: 13.0511\n",
            "[273/25][41/69] Loss_D: 0.0019 Loss_G: 13.1699\n",
            "[273/25][42/69] Loss_D: 0.0012 Loss_G: 12.6573\n",
            "[273/25][43/69] Loss_D: 0.0005 Loss_G: 12.5467\n",
            "[273/25][44/69] Loss_D: 0.0007 Loss_G: 12.2609\n",
            "[273/25][45/69] Loss_D: 0.0001 Loss_G: 12.0646\n",
            "[273/25][46/69] Loss_D: 0.0013 Loss_G: 10.8728\n",
            "[273/25][47/69] Loss_D: 0.0008 Loss_G: 11.1141\n",
            "[273/25][48/69] Loss_D: 0.0019 Loss_G: 10.2076\n",
            "[273/25][49/69] Loss_D: 0.0016 Loss_G: 10.1992\n",
            "[273/25][50/69] Loss_D: 0.0032 Loss_G: 10.0319\n",
            "[273/25][51/69] Loss_D: 0.0020 Loss_G: 10.4981\n",
            "[273/25][52/69] Loss_D: 0.0020 Loss_G: 10.2829\n",
            "[273/25][53/69] Loss_D: 0.1629 Loss_G: 7.7564\n",
            "[273/25][54/69] Loss_D: 0.0028 Loss_G: 7.0429\n",
            "[273/25][55/69] Loss_D: 0.0643 Loss_G: 6.1940\n",
            "[273/25][56/69] Loss_D: 0.0326 Loss_G: 7.2762\n",
            "[273/25][57/69] Loss_D: 0.0048 Loss_G: 8.6989\n",
            "[273/25][58/69] Loss_D: 0.0021 Loss_G: 8.7514\n",
            "[273/25][59/69] Loss_D: 0.0017 Loss_G: 9.1243\n",
            "[273/25][60/69] Loss_D: 0.0009 Loss_G: 9.1241\n",
            "[273/25][61/69] Loss_D: 0.0007 Loss_G: 9.3681\n",
            "[273/25][62/69] Loss_D: 0.0002 Loss_G: 10.4499\n",
            "[273/25][63/69] Loss_D: 0.0002 Loss_G: 10.7068\n",
            "[273/25][64/69] Loss_D: 0.0001 Loss_G: 11.5360\n",
            "[273/25][65/69] Loss_D: 0.0003 Loss_G: 11.0317\n",
            "[273/25][66/69] Loss_D: 0.0031 Loss_G: 10.6692\n",
            "[273/25][67/69] Loss_D: 0.0026 Loss_G: 9.6949\n",
            "[273/25][68/69] Loss_D: 0.0059 Loss_G: 8.8370\n",
            "[274/25][0/69] Loss_D: 0.0013 Loss_G: 9.5731\n",
            "[274/25][1/69] Loss_D: 0.0019 Loss_G: 8.6947\n",
            "[274/25][2/69] Loss_D: 0.0013 Loss_G: 8.9477\n",
            "[274/25][3/69] Loss_D: 0.0012 Loss_G: 8.8997\n",
            "[274/25][4/69] Loss_D: 0.0005 Loss_G: 10.0405\n",
            "[274/25][5/69] Loss_D: 0.0025 Loss_G: 8.1675\n",
            "[274/25][6/69] Loss_D: 0.0013 Loss_G: 8.0502\n",
            "[274/25][7/69] Loss_D: 0.0004 Loss_G: 10.1904\n",
            "[274/25][8/69] Loss_D: 0.0066 Loss_G: 7.6523\n",
            "[274/25][9/69] Loss_D: 0.0013 Loss_G: 9.0696\n",
            "[274/25][10/69] Loss_D: 0.0013 Loss_G: 9.1053\n",
            "[274/25][11/69] Loss_D: 0.0057 Loss_G: 8.1028\n",
            "[274/25][12/69] Loss_D: 0.0042 Loss_G: 7.4671\n",
            "[274/25][13/69] Loss_D: 0.0030 Loss_G: 7.4477\n",
            "[274/25][14/69] Loss_D: 0.0019 Loss_G: 8.3654\n",
            "[274/25][15/69] Loss_D: 0.0012 Loss_G: 8.4112\n",
            "[274/25][16/69] Loss_D: 0.0059 Loss_G: 8.3184\n",
            "[274/25][17/69] Loss_D: 0.0022 Loss_G: 7.0804\n",
            "[274/25][18/69] Loss_D: 0.0036 Loss_G: 6.7913\n",
            "[274/25][19/69] Loss_D: 0.0007 Loss_G: 8.8446\n",
            "[274/25][20/69] Loss_D: 0.0060 Loss_G: 6.4762\n",
            "[274/25][21/69] Loss_D: 0.0063 Loss_G: 6.8413\n",
            "[274/25][22/69] Loss_D: 0.0029 Loss_G: 7.7934\n",
            "[274/25][23/69] Loss_D: 0.0029 Loss_G: 7.2411\n",
            "[274/25][24/69] Loss_D: 0.0046 Loss_G: 8.5351\n",
            "[274/25][25/69] Loss_D: 0.0052 Loss_G: 6.9779\n",
            "[274/25][26/69] Loss_D: 0.0064 Loss_G: 8.1855\n",
            "[274/25][27/69] Loss_D: 0.0321 Loss_G: 7.0452\n",
            "[274/25][28/69] Loss_D: 0.0025 Loss_G: 6.5782\n",
            "[274/25][29/69] Loss_D: 0.0049 Loss_G: 6.0360\n",
            "[274/25][30/69] Loss_D: 0.0056 Loss_G: 6.1864\n",
            "[274/25][31/69] Loss_D: 0.0072 Loss_G: 6.2647\n",
            "[274/25][32/69] Loss_D: 0.0044 Loss_G: 6.4912\n",
            "[274/25][33/69] Loss_D: 0.0021 Loss_G: 7.4349\n",
            "[274/25][34/69] Loss_D: 0.0094 Loss_G: 6.4129\n",
            "[274/25][35/69] Loss_D: 0.0015 Loss_G: 7.8396\n",
            "[274/25][36/69] Loss_D: 0.0018 Loss_G: 7.8124\n",
            "[274/25][37/69] Loss_D: 0.0010 Loss_G: 8.2057\n",
            "[274/25][38/69] Loss_D: 0.0012 Loss_G: 8.1098\n",
            "[274/25][39/69] Loss_D: 0.0011 Loss_G: 9.2258\n",
            "[274/25][40/69] Loss_D: 0.0018 Loss_G: 9.2955\n",
            "[274/25][41/69] Loss_D: 0.0003 Loss_G: 10.7108\n",
            "[274/25][42/69] Loss_D: 0.0014 Loss_G: 10.0329\n",
            "[274/25][43/69] Loss_D: 0.0004 Loss_G: 8.6550\n",
            "[274/25][44/69] Loss_D: 0.0011 Loss_G: 7.9616\n",
            "[274/25][45/69] Loss_D: 0.0003 Loss_G: 9.6236\n",
            "[274/25][46/69] Loss_D: 0.0005 Loss_G: 9.0447\n",
            "[274/25][47/69] Loss_D: 0.0004 Loss_G: 9.3524\n",
            "[274/25][48/69] Loss_D: 0.0010 Loss_G: 8.7650\n",
            "[274/25][49/69] Loss_D: 0.0103 Loss_G: 9.1648\n",
            "[274/25][50/69] Loss_D: 0.0040 Loss_G: 6.5688\n",
            "[274/25][51/69] Loss_D: 0.0006 Loss_G: 8.6070\n",
            "[274/25][52/69] Loss_D: 0.0042 Loss_G: 6.7302\n",
            "[274/25][53/69] Loss_D: 0.0010 Loss_G: 7.8767\n",
            "[274/25][54/69] Loss_D: 0.0018 Loss_G: 7.1965\n",
            "[274/25][55/69] Loss_D: 0.0005 Loss_G: 8.2996\n",
            "[274/25][56/69] Loss_D: 0.0074 Loss_G: 5.9384\n",
            "[274/25][57/69] Loss_D: 0.0067 Loss_G: 7.1669\n",
            "[274/25][58/69] Loss_D: 0.0016 Loss_G: 7.7265\n",
            "[274/25][59/69] Loss_D: 0.0003 Loss_G: 9.0661\n",
            "[274/25][60/69] Loss_D: 0.0017 Loss_G: 7.7190\n",
            "[274/25][61/69] Loss_D: 0.0020 Loss_G: 7.3141\n",
            "[274/25][62/69] Loss_D: 0.0010 Loss_G: 7.9132\n",
            "[274/25][63/69] Loss_D: 0.0017 Loss_G: 7.3545\n",
            "[274/25][64/69] Loss_D: 0.0026 Loss_G: 7.4378\n",
            "[274/25][65/69] Loss_D: 0.0006 Loss_G: 9.4943\n",
            "[274/25][66/69] Loss_D: 0.0288 Loss_G: 6.7784\n",
            "[274/25][67/69] Loss_D: 0.0008 Loss_G: 7.9795\n",
            "[274/25][68/69] Loss_D: 0.0010 Loss_G: 7.4067\n",
            "[275/25][0/69] Loss_D: 0.0031 Loss_G: 6.6045\n",
            "[275/25][1/69] Loss_D: 0.0030 Loss_G: 6.4552\n",
            "[275/25][2/69] Loss_D: 0.0078 Loss_G: 6.0941\n",
            "[275/25][3/69] Loss_D: 0.0065 Loss_G: 6.2755\n",
            "[275/25][4/69] Loss_D: 0.0027 Loss_G: 6.8806\n",
            "[275/25][5/69] Loss_D: 0.0018 Loss_G: 7.5117\n",
            "[275/25][6/69] Loss_D: 0.0114 Loss_G: 6.0879\n",
            "[275/25][7/69] Loss_D: 0.0005 Loss_G: 9.3284\n",
            "[275/25][8/69] Loss_D: 0.0003 Loss_G: 9.8611\n",
            "[275/25][9/69] Loss_D: 0.0008 Loss_G: 8.4227\n",
            "[275/25][10/69] Loss_D: 0.0043 Loss_G: 8.6616\n",
            "[275/25][11/69] Loss_D: 0.0065 Loss_G: 9.2333\n",
            "[275/25][12/69] Loss_D: 0.0115 Loss_G: 9.5501\n",
            "[275/25][13/69] Loss_D: 0.0036 Loss_G: 8.2666\n",
            "[275/25][14/69] Loss_D: 0.0182 Loss_G: 7.5196\n",
            "[275/25][15/69] Loss_D: 0.0048 Loss_G: 8.1964\n",
            "[275/25][16/69] Loss_D: 0.0026 Loss_G: 6.4792\n",
            "[275/25][17/69] Loss_D: 0.0047 Loss_G: 6.2279\n",
            "[275/25][18/69] Loss_D: 0.0049 Loss_G: 6.6923\n",
            "[275/25][19/69] Loss_D: 0.0095 Loss_G: 5.6937\n",
            "[275/25][20/69] Loss_D: 0.0033 Loss_G: 6.6075\n",
            "[275/25][21/69] Loss_D: 0.0219 Loss_G: 5.8678\n",
            "[275/25][22/69] Loss_D: 0.0015 Loss_G: 7.7995\n",
            "[275/25][23/69] Loss_D: 0.0015 Loss_G: 8.0096\n",
            "[275/25][24/69] Loss_D: 0.0003 Loss_G: 9.8240\n",
            "[275/25][25/69] Loss_D: 0.0008 Loss_G: 9.5069\n",
            "[275/25][26/69] Loss_D: 0.0026 Loss_G: 8.9588\n",
            "[275/25][27/69] Loss_D: 0.0003 Loss_G: 9.7841\n",
            "[275/25][28/69] Loss_D: 0.0168 Loss_G: 10.5602\n",
            "[275/25][29/69] Loss_D: 0.0023 Loss_G: 7.9465\n",
            "[275/25][30/69] Loss_D: 0.0005 Loss_G: 8.9125\n",
            "[275/25][31/69] Loss_D: 0.0003 Loss_G: 9.7928\n",
            "[275/25][32/69] Loss_D: 0.0002 Loss_G: 9.5461\n",
            "[275/25][33/69] Loss_D: 0.0009 Loss_G: 7.7587\n",
            "[275/25][34/69] Loss_D: 0.0004 Loss_G: 8.9208\n",
            "[275/25][35/69] Loss_D: 0.0003 Loss_G: 9.7149\n",
            "[275/25][36/69] Loss_D: 0.0007 Loss_G: 8.7260\n",
            "[275/25][37/69] Loss_D: 0.0016 Loss_G: 7.3352\n",
            "[275/25][38/69] Loss_D: 0.0014 Loss_G: 7.8807\n",
            "[275/25][39/69] Loss_D: 0.0007 Loss_G: 9.0710\n",
            "[275/25][40/69] Loss_D: 0.0013 Loss_G: 7.7324\n",
            "[275/25][41/69] Loss_D: 0.0013 Loss_G: 7.9456\n",
            "[275/25][42/69] Loss_D: 0.0015 Loss_G: 9.2335\n",
            "[275/25][43/69] Loss_D: 0.0003 Loss_G: 9.5492\n",
            "[275/25][44/69] Loss_D: 0.0004 Loss_G: 8.9893\n",
            "[275/25][45/69] Loss_D: 0.0083 Loss_G: 7.3935\n",
            "[275/25][46/69] Loss_D: 0.0018 Loss_G: 7.3456\n",
            "[275/25][47/69] Loss_D: 0.0019 Loss_G: 7.0492\n",
            "[275/25][48/69] Loss_D: 0.0029 Loss_G: 6.9353\n",
            "[275/25][49/69] Loss_D: 0.0029 Loss_G: 7.5058\n",
            "[275/25][50/69] Loss_D: 0.0017 Loss_G: 7.8551\n",
            "[275/25][51/69] Loss_D: 0.0031 Loss_G: 6.9383\n",
            "[275/25][52/69] Loss_D: 0.0021 Loss_G: 7.3670\n",
            "[275/25][53/69] Loss_D: 0.0016 Loss_G: 7.5907\n",
            "[275/25][54/69] Loss_D: 0.0008 Loss_G: 8.2078\n",
            "[275/25][55/69] Loss_D: 0.0012 Loss_G: 7.9224\n",
            "[275/25][56/69] Loss_D: 0.0030 Loss_G: 7.6163\n",
            "[275/25][57/69] Loss_D: 0.0004 Loss_G: 9.1859\n",
            "[275/25][58/69] Loss_D: 0.0015 Loss_G: 7.4725\n",
            "[275/25][59/69] Loss_D: 0.0004 Loss_G: 9.5686\n",
            "[275/25][60/69] Loss_D: 0.0006 Loss_G: 8.4710\n",
            "[275/25][61/69] Loss_D: 0.0009 Loss_G: 8.7773\n",
            "[275/25][62/69] Loss_D: 0.0010 Loss_G: 9.0628\n",
            "[275/25][63/69] Loss_D: 0.0009 Loss_G: 8.4759\n",
            "[275/25][64/69] Loss_D: 0.0018 Loss_G: 7.3298\n",
            "[275/25][65/69] Loss_D: 0.0008 Loss_G: 8.3893\n",
            "[275/25][66/69] Loss_D: 0.1491 Loss_G: 4.3009\n",
            "[275/25][67/69] Loss_D: 0.0320 Loss_G: 3.0039\n",
            "[275/25][68/69] Loss_D: 0.2188 Loss_G: 5.4607\n",
            "[276/25][0/69] Loss_D: 0.0134 Loss_G: 6.8935\n",
            "[276/25][1/69] Loss_D: 0.0047 Loss_G: 8.5265\n",
            "[276/25][2/69] Loss_D: 0.0021 Loss_G: 10.1619\n",
            "[276/25][3/69] Loss_D: 0.0001 Loss_G: 12.7262\n",
            "[276/25][4/69] Loss_D: 0.0033 Loss_G: 12.6324\n",
            "[276/25][5/69] Loss_D: 0.0004 Loss_G: 13.7929\n",
            "[276/25][6/69] Loss_D: 0.0001 Loss_G: 15.4588\n",
            "[276/25][7/69] Loss_D: 0.0003 Loss_G: 15.7733\n",
            "[276/25][8/69] Loss_D: 0.0233 Loss_G: 15.6537\n",
            "[276/25][9/69] Loss_D: 0.0007 Loss_G: 15.8133\n",
            "[276/25][10/69] Loss_D: 0.0012 Loss_G: 15.6865\n",
            "[276/25][11/69] Loss_D: 0.0038 Loss_G: 17.6163\n",
            "[276/25][12/69] Loss_D: 0.0079 Loss_G: 15.3251\n",
            "[276/25][13/69] Loss_D: 0.0037 Loss_G: 15.0466\n",
            "[276/25][14/69] Loss_D: 0.1071 Loss_G: 13.0815\n",
            "[276/25][15/69] Loss_D: 0.0201 Loss_G: 11.7705\n",
            "[276/25][16/69] Loss_D: 0.0001 Loss_G: 10.6029\n",
            "[276/25][17/69] Loss_D: 0.0011 Loss_G: 8.2222\n",
            "[276/25][18/69] Loss_D: 0.0013 Loss_G: 7.3623\n",
            "[276/25][19/69] Loss_D: 0.0057 Loss_G: 6.1852\n",
            "[276/25][20/69] Loss_D: 0.0042 Loss_G: 6.3682\n",
            "[276/25][21/69] Loss_D: 0.0268 Loss_G: 5.2521\n",
            "[276/25][22/69] Loss_D: 0.0987 Loss_G: 5.7510\n",
            "[276/25][23/69] Loss_D: 0.0056 Loss_G: 9.0680\n",
            "[276/25][24/69] Loss_D: 0.0014 Loss_G: 10.8163\n",
            "[276/25][25/69] Loss_D: 0.0013 Loss_G: 11.4669\n",
            "[276/25][26/69] Loss_D: 0.0007 Loss_G: 13.8675\n",
            "[276/25][27/69] Loss_D: 0.0129 Loss_G: 13.7289\n",
            "[276/25][28/69] Loss_D: 0.0002 Loss_G: 14.8448\n",
            "[276/25][29/69] Loss_D: 0.0014 Loss_G: 16.3515\n",
            "[276/25][30/69] Loss_D: 0.0232 Loss_G: 13.9940\n",
            "[276/25][31/69] Loss_D: 0.0009 Loss_G: 13.0157\n",
            "[276/25][32/69] Loss_D: 0.0012 Loss_G: 14.3993\n",
            "[276/25][33/69] Loss_D: 0.0075 Loss_G: 14.6775\n",
            "[276/25][34/69] Loss_D: 0.0008 Loss_G: 13.4045\n",
            "[276/25][35/69] Loss_D: 0.0001 Loss_G: 11.9735\n",
            "[276/25][36/69] Loss_D: 0.0011 Loss_G: 13.5998\n",
            "[276/25][37/69] Loss_D: 0.0094 Loss_G: 13.1062\n",
            "[276/25][38/69] Loss_D: 0.0003 Loss_G: 11.6880\n",
            "[276/25][39/69] Loss_D: 0.0009 Loss_G: 11.0071\n",
            "[276/25][40/69] Loss_D: 0.0017 Loss_G: 10.4064\n",
            "[276/25][41/69] Loss_D: 0.0026 Loss_G: 9.4296\n",
            "[276/25][42/69] Loss_D: 0.0022 Loss_G: 9.9522\n",
            "[276/25][43/69] Loss_D: 0.0023 Loss_G: 9.4737\n",
            "[276/25][44/69] Loss_D: 0.0025 Loss_G: 8.2210\n",
            "[276/25][45/69] Loss_D: 0.0029 Loss_G: 8.3416\n",
            "[276/25][46/69] Loss_D: 0.0018 Loss_G: 8.1490\n",
            "[276/25][47/69] Loss_D: 0.0192 Loss_G: 8.1386\n",
            "[276/25][48/69] Loss_D: 0.0003 Loss_G: 9.7603\n",
            "[276/25][49/69] Loss_D: 0.0021 Loss_G: 8.9512\n",
            "[276/25][50/69] Loss_D: 0.0002 Loss_G: 9.9152\n",
            "[276/25][51/69] Loss_D: 0.0013 Loss_G: 8.9146\n",
            "[276/25][52/69] Loss_D: 0.0004 Loss_G: 9.3820\n",
            "[276/25][53/69] Loss_D: 0.0001 Loss_G: 10.1429\n",
            "[276/25][54/69] Loss_D: 0.0007 Loss_G: 8.7489\n",
            "[276/25][55/69] Loss_D: 0.0009 Loss_G: 10.1743\n",
            "[276/25][56/69] Loss_D: 0.0002 Loss_G: 10.1270\n",
            "[276/25][57/69] Loss_D: 0.0002 Loss_G: 9.4835\n",
            "[276/25][58/69] Loss_D: 0.0012 Loss_G: 7.6310\n",
            "[276/25][59/69] Loss_D: 0.0011 Loss_G: 8.4532\n",
            "[276/25][60/69] Loss_D: 0.0009 Loss_G: 9.4866\n",
            "[276/25][61/69] Loss_D: 0.0005 Loss_G: 8.5500\n",
            "[276/25][62/69] Loss_D: 0.0004 Loss_G: 9.3418\n",
            "[276/25][63/69] Loss_D: 0.0008 Loss_G: 8.2693\n",
            "[276/25][64/69] Loss_D: 0.1267 Loss_G: 5.3775\n",
            "[276/25][65/69] Loss_D: 0.0056 Loss_G: 4.9999\n",
            "[276/25][66/69] Loss_D: 0.0061 Loss_G: 5.6567\n",
            "[276/25][67/69] Loss_D: 0.0109 Loss_G: 5.1574\n",
            "[276/25][68/69] Loss_D: 0.0444 Loss_G: 5.4510\n",
            "[277/25][0/69] Loss_D: 0.0128 Loss_G: 6.4421\n",
            "[277/25][1/69] Loss_D: 0.0063 Loss_G: 7.5157\n",
            "[277/25][2/69] Loss_D: 0.0004 Loss_G: 9.6573\n",
            "[277/25][3/69] Loss_D: 0.0009 Loss_G: 10.0710\n",
            "[277/25][4/69] Loss_D: 0.0010 Loss_G: 9.7214\n",
            "[277/25][5/69] Loss_D: 0.0001 Loss_G: 11.4460\n",
            "[277/25][6/69] Loss_D: 0.0005 Loss_G: 10.3626\n",
            "[277/25][7/69] Loss_D: 0.0000 Loss_G: 12.6559\n",
            "[277/25][8/69] Loss_D: 0.0002 Loss_G: 13.2901\n",
            "[277/25][9/69] Loss_D: 0.0001 Loss_G: 12.5614\n",
            "[277/25][10/69] Loss_D: 0.0209 Loss_G: 10.5384\n",
            "[277/25][11/69] Loss_D: 0.0002 Loss_G: 11.4554\n",
            "[277/25][12/69] Loss_D: 0.0000 Loss_G: 11.3727\n",
            "[277/25][13/69] Loss_D: 0.0002 Loss_G: 11.7568\n",
            "[277/25][14/69] Loss_D: 0.0002 Loss_G: 9.7221\n",
            "[277/25][15/69] Loss_D: 0.0003 Loss_G: 12.4674\n",
            "[277/25][16/69] Loss_D: 0.0001 Loss_G: 11.0117\n",
            "[277/25][17/69] Loss_D: 0.0001 Loss_G: 10.9490\n",
            "[277/25][18/69] Loss_D: 0.0005 Loss_G: 9.4334\n",
            "[277/25][19/69] Loss_D: 0.0013 Loss_G: 8.4741\n",
            "[277/25][20/69] Loss_D: 0.1694 Loss_G: 6.3951\n",
            "[277/25][21/69] Loss_D: 0.0109 Loss_G: 4.6072\n",
            "[277/25][22/69] Loss_D: 0.0266 Loss_G: 4.6247\n",
            "[277/25][23/69] Loss_D: 0.1144 Loss_G: 6.6565\n",
            "[277/25][24/69] Loss_D: 0.0220 Loss_G: 8.7350\n",
            "[277/25][25/69] Loss_D: 0.0013 Loss_G: 11.0772\n",
            "[277/25][26/69] Loss_D: 0.0001 Loss_G: 14.1271\n",
            "[277/25][27/69] Loss_D: 0.0085 Loss_G: 14.0953\n",
            "[277/25][28/69] Loss_D: 0.0001 Loss_G: 17.2972\n",
            "[277/25][29/69] Loss_D: 0.0002 Loss_G: 18.6444\n",
            "[277/25][30/69] Loss_D: 0.0490 Loss_G: 19.3958\n",
            "[277/25][31/69] Loss_D: 0.0019 Loss_G: 18.5018\n",
            "[277/25][32/69] Loss_D: 0.0007 Loss_G: 18.5755\n",
            "[277/25][33/69] Loss_D: 0.2189 Loss_G: 15.6824\n",
            "[277/25][34/69] Loss_D: 0.0000 Loss_G: 12.5205\n",
            "[277/25][35/69] Loss_D: 0.0000 Loss_G: 11.2124\n",
            "[277/25][36/69] Loss_D: 0.0003 Loss_G: 9.8621\n",
            "[277/25][37/69] Loss_D: 0.0018 Loss_G: 7.4855\n",
            "[277/25][38/69] Loss_D: 0.0021 Loss_G: 7.7095\n",
            "[277/25][39/69] Loss_D: 0.0089 Loss_G: 6.6523\n",
            "[277/25][40/69] Loss_D: 0.0135 Loss_G: 6.6789\n",
            "[277/25][41/69] Loss_D: 0.1223 Loss_G: 8.7875\n",
            "[277/25][42/69] Loss_D: 0.0014 Loss_G: 11.0494\n",
            "[277/25][43/69] Loss_D: 0.0002 Loss_G: 13.2216\n",
            "[277/25][44/69] Loss_D: 0.0001 Loss_G: 14.0380\n",
            "[277/25][45/69] Loss_D: 0.0002 Loss_G: 15.2916\n",
            "[277/25][46/69] Loss_D: 0.0064 Loss_G: 16.1468\n",
            "[277/25][47/69] Loss_D: 0.0020 Loss_G: 15.2263\n",
            "[277/25][48/69] Loss_D: 0.0227 Loss_G: 16.5350\n",
            "[277/25][49/69] Loss_D: 0.0410 Loss_G: 14.2853\n",
            "[277/25][50/69] Loss_D: 0.1671 Loss_G: 8.3414\n",
            "[277/25][51/69] Loss_D: 0.0356 Loss_G: 7.1789\n",
            "[277/25][52/69] Loss_D: 0.0760 Loss_G: 7.4310\n",
            "[277/25][53/69] Loss_D: 0.0353 Loss_G: 8.4783\n",
            "[277/25][54/69] Loss_D: 0.0029 Loss_G: 10.3467\n",
            "[277/25][55/69] Loss_D: 0.0005 Loss_G: 11.2588\n",
            "[277/25][56/69] Loss_D: 0.0001 Loss_G: 12.8085\n",
            "[277/25][57/69] Loss_D: 0.0006 Loss_G: 11.5222\n",
            "[277/25][58/69] Loss_D: 0.0001 Loss_G: 14.0569\n",
            "[277/25][59/69] Loss_D: 0.0016 Loss_G: 12.2942\n",
            "[277/25][60/69] Loss_D: 0.0002 Loss_G: 13.4047\n",
            "[277/25][61/69] Loss_D: 0.0003 Loss_G: 14.9013\n",
            "[277/25][62/69] Loss_D: 0.0009 Loss_G: 13.0349\n",
            "[277/25][63/69] Loss_D: 0.0032 Loss_G: 13.3018\n",
            "[277/25][64/69] Loss_D: 0.0011 Loss_G: 14.8668\n",
            "[277/25][65/69] Loss_D: 0.0015 Loss_G: 15.2709\n",
            "[277/25][66/69] Loss_D: 0.0029 Loss_G: 11.8059\n",
            "[277/25][67/69] Loss_D: 0.0065 Loss_G: 12.3348\n",
            "[277/25][68/69] Loss_D: 0.3215 Loss_G: 11.0739\n",
            "[278/25][0/69] Loss_D: 0.0039 Loss_G: 10.0612\n",
            "[278/25][1/69] Loss_D: 0.0070 Loss_G: 6.8055\n",
            "[278/25][2/69] Loss_D: 0.0784 Loss_G: 7.6703\n",
            "[278/25][3/69] Loss_D: 0.0406 Loss_G: 9.9321\n",
            "[278/25][4/69] Loss_D: 0.0078 Loss_G: 10.8576\n",
            "[278/25][5/69] Loss_D: 0.0014 Loss_G: 12.9371\n",
            "[278/25][6/69] Loss_D: 0.0002 Loss_G: 12.8759\n",
            "[278/25][7/69] Loss_D: 0.0002 Loss_G: 13.6699\n",
            "[278/25][8/69] Loss_D: 0.0004 Loss_G: 14.8898\n",
            "[278/25][9/69] Loss_D: 0.0016 Loss_G: 15.0841\n",
            "[278/25][10/69] Loss_D: 0.1907 Loss_G: 12.7914\n",
            "[278/25][11/69] Loss_D: 0.0124 Loss_G: 9.5452\n",
            "[278/25][12/69] Loss_D: 0.0054 Loss_G: 9.5398\n",
            "[278/25][13/69] Loss_D: 0.0188 Loss_G: 8.5602\n",
            "[278/25][14/69] Loss_D: 0.0050 Loss_G: 9.3529\n",
            "[278/25][15/69] Loss_D: 0.0244 Loss_G: 8.3929\n",
            "[278/25][16/69] Loss_D: 0.0073 Loss_G: 9.3273\n",
            "[278/25][17/69] Loss_D: 0.0037 Loss_G: 8.8988\n",
            "[278/25][18/69] Loss_D: 0.0041 Loss_G: 9.4161\n",
            "[278/25][19/69] Loss_D: 0.0012 Loss_G: 11.7738\n",
            "[278/25][20/69] Loss_D: 0.0025 Loss_G: 10.8424\n",
            "[278/25][21/69] Loss_D: 0.0025 Loss_G: 10.8704\n",
            "[278/25][22/69] Loss_D: 0.0034 Loss_G: 10.7288\n",
            "[278/25][23/69] Loss_D: 0.0019 Loss_G: 10.9722\n",
            "[278/25][24/69] Loss_D: 0.0048 Loss_G: 10.6746\n",
            "[278/25][25/69] Loss_D: 0.0027 Loss_G: 10.2519\n",
            "[278/25][26/69] Loss_D: 0.0020 Loss_G: 10.9976\n",
            "[278/25][27/69] Loss_D: 0.1016 Loss_G: 10.5647\n",
            "[278/25][28/69] Loss_D: 0.1555 Loss_G: 8.4014\n",
            "[278/25][29/69] Loss_D: 0.0031 Loss_G: 7.1658\n",
            "[278/25][30/69] Loss_D: 0.0098 Loss_G: 6.4673\n",
            "[278/25][31/69] Loss_D: 0.1996 Loss_G: 7.5531\n",
            "[278/25][32/69] Loss_D: 0.0008 Loss_G: 11.4168\n",
            "[278/25][33/69] Loss_D: 0.0012 Loss_G: 10.6008\n",
            "[278/25][34/69] Loss_D: 0.0001 Loss_G: 13.4943\n",
            "[278/25][35/69] Loss_D: 0.0001 Loss_G: 13.7739\n",
            "[278/25][36/69] Loss_D: 0.0002 Loss_G: 14.9200\n",
            "[278/25][37/69] Loss_D: 0.0008 Loss_G: 13.8971\n",
            "[278/25][38/69] Loss_D: 0.0002 Loss_G: 14.2679\n",
            "[278/25][39/69] Loss_D: 0.0002 Loss_G: 15.3129\n",
            "[278/25][40/69] Loss_D: 0.0002 Loss_G: 15.9814\n",
            "[278/25][41/69] Loss_D: 0.0001 Loss_G: 16.5087\n",
            "[278/25][42/69] Loss_D: 0.0001 Loss_G: 16.7685\n",
            "[278/25][43/69] Loss_D: 0.0004 Loss_G: 16.6064\n",
            "[278/25][44/69] Loss_D: 0.0008 Loss_G: 15.7769\n",
            "[278/25][45/69] Loss_D: 0.0118 Loss_G: 14.4068\n",
            "[278/25][46/69] Loss_D: 0.0541 Loss_G: 13.3928\n",
            "[278/25][47/69] Loss_D: 0.0012 Loss_G: 12.0066\n",
            "[278/25][48/69] Loss_D: 0.0013 Loss_G: 12.0150\n",
            "[278/25][49/69] Loss_D: 0.0183 Loss_G: 9.1145\n",
            "[278/25][50/69] Loss_D: 0.0015 Loss_G: 10.9739\n",
            "[278/25][51/69] Loss_D: 0.0027 Loss_G: 9.7916\n",
            "[278/25][52/69] Loss_D: 0.0025 Loss_G: 9.4772\n",
            "[278/25][53/69] Loss_D: 0.0018 Loss_G: 10.0753\n",
            "[278/25][54/69] Loss_D: 0.0057 Loss_G: 10.4284\n",
            "[278/25][55/69] Loss_D: 0.0089 Loss_G: 8.9519\n",
            "[278/25][56/69] Loss_D: 0.0049 Loss_G: 9.5082\n",
            "[278/25][57/69] Loss_D: 0.0016 Loss_G: 9.7978\n",
            "[278/25][58/69] Loss_D: 0.0010 Loss_G: 9.7228\n",
            "[278/25][59/69] Loss_D: 0.0018 Loss_G: 9.0751\n",
            "[278/25][60/69] Loss_D: 0.0017 Loss_G: 9.0314\n",
            "[278/25][61/69] Loss_D: 0.0009 Loss_G: 9.3322\n",
            "[278/25][62/69] Loss_D: 0.0008 Loss_G: 9.4167\n",
            "[278/25][63/69] Loss_D: 0.0013 Loss_G: 8.9535\n",
            "[278/25][64/69] Loss_D: 0.0145 Loss_G: 9.4436\n",
            "[278/25][65/69] Loss_D: 0.0004 Loss_G: 9.2952\n",
            "[278/25][66/69] Loss_D: 0.0013 Loss_G: 8.9075\n",
            "[278/25][67/69] Loss_D: 0.0007 Loss_G: 8.9348\n",
            "[278/25][68/69] Loss_D: 0.0013 Loss_G: 8.4612\n",
            "[279/25][0/69] Loss_D: 0.0012 Loss_G: 8.9140\n",
            "[279/25][1/69] Loss_D: 0.0019 Loss_G: 8.4502\n",
            "[279/25][2/69] Loss_D: 0.0034 Loss_G: 7.4406\n",
            "[279/25][3/69] Loss_D: 0.0008 Loss_G: 9.7538\n",
            "[279/25][4/69] Loss_D: 0.0020 Loss_G: 8.2852\n",
            "[279/25][5/69] Loss_D: 0.0046 Loss_G: 7.1667\n",
            "[279/25][6/69] Loss_D: 0.0059 Loss_G: 7.9613\n",
            "[279/25][7/69] Loss_D: 0.0017 Loss_G: 8.3845\n",
            "[279/25][8/69] Loss_D: 0.0228 Loss_G: 7.3551\n",
            "[279/25][9/69] Loss_D: 0.0029 Loss_G: 6.5936\n",
            "[279/25][10/69] Loss_D: 0.0033 Loss_G: 6.9755\n",
            "[279/25][11/69] Loss_D: 0.0039 Loss_G: 6.5639\n",
            "[279/25][12/69] Loss_D: 0.0054 Loss_G: 6.2366\n",
            "[279/25][13/69] Loss_D: 0.0018 Loss_G: 7.2502\n",
            "[279/25][14/69] Loss_D: 0.0029 Loss_G: 8.1491\n",
            "[279/25][15/69] Loss_D: 0.0029 Loss_G: 7.8927\n",
            "[279/25][16/69] Loss_D: 0.0009 Loss_G: 8.3807\n",
            "[279/25][17/69] Loss_D: 0.0058 Loss_G: 7.2066\n",
            "[279/25][18/69] Loss_D: 0.0007 Loss_G: 8.5730\n",
            "[279/25][19/69] Loss_D: 0.0019 Loss_G: 8.0671\n",
            "[279/25][20/69] Loss_D: 0.0008 Loss_G: 9.0076\n",
            "[279/25][21/69] Loss_D: 0.0004 Loss_G: 9.3476\n",
            "[279/25][22/69] Loss_D: 0.0005 Loss_G: 9.7554\n",
            "[279/25][23/69] Loss_D: 0.0003 Loss_G: 9.2805\n",
            "[279/25][24/69] Loss_D: 0.0003 Loss_G: 9.7440\n",
            "[279/25][25/69] Loss_D: 0.0002 Loss_G: 10.0981\n",
            "[279/25][26/69] Loss_D: 0.0003 Loss_G: 9.4409\n",
            "[279/25][27/69] Loss_D: 0.0003 Loss_G: 9.6629\n",
            "[279/25][28/69] Loss_D: 0.0002 Loss_G: 10.0347\n",
            "[279/25][29/69] Loss_D: 0.0007 Loss_G: 9.5906\n",
            "[279/25][30/69] Loss_D: 0.0122 Loss_G: 9.3472\n",
            "[279/25][31/69] Loss_D: 0.0011 Loss_G: 8.6400\n",
            "[279/25][32/69] Loss_D: 0.0011 Loss_G: 8.9013\n",
            "[279/25][33/69] Loss_D: 0.0007 Loss_G: 8.5759\n",
            "[279/25][34/69] Loss_D: 0.0011 Loss_G: 8.6507\n",
            "[279/25][35/69] Loss_D: 0.0023 Loss_G: 7.8482\n",
            "[279/25][36/69] Loss_D: 0.0055 Loss_G: 8.3519\n",
            "[279/25][37/69] Loss_D: 0.0032 Loss_G: 8.0264\n",
            "[279/25][38/69] Loss_D: 0.0054 Loss_G: 7.1049\n",
            "[279/25][39/69] Loss_D: 0.0016 Loss_G: 8.3478\n",
            "[279/25][40/69] Loss_D: 0.0013 Loss_G: 8.3568\n",
            "[279/25][41/69] Loss_D: 0.0004 Loss_G: 9.7662\n",
            "[279/25][42/69] Loss_D: 0.0015 Loss_G: 7.6621\n",
            "[279/25][43/69] Loss_D: 0.0012 Loss_G: 8.1003\n",
            "[279/25][44/69] Loss_D: 0.0043 Loss_G: 7.1847\n",
            "[279/25][45/69] Loss_D: 0.0018 Loss_G: 7.3512\n",
            "[279/25][46/69] Loss_D: 0.0009 Loss_G: 8.3954\n",
            "[279/25][47/69] Loss_D: 0.0011 Loss_G: 8.2729\n",
            "[279/25][48/69] Loss_D: 0.0018 Loss_G: 7.7852\n",
            "[279/25][49/69] Loss_D: 0.0170 Loss_G: 8.2285\n",
            "[279/25][50/69] Loss_D: 0.0015 Loss_G: 7.6237\n",
            "[279/25][51/69] Loss_D: 0.0019 Loss_G: 7.1462\n",
            "[279/25][52/69] Loss_D: 0.0059 Loss_G: 6.7444\n",
            "[279/25][53/69] Loss_D: 0.0027 Loss_G: 7.8533\n",
            "[279/25][54/69] Loss_D: 0.0032 Loss_G: 6.7198\n",
            "[279/25][55/69] Loss_D: 0.0025 Loss_G: 7.1785\n",
            "[279/25][56/69] Loss_D: 0.0019 Loss_G: 7.6784\n",
            "[279/25][57/69] Loss_D: 0.0032 Loss_G: 6.7721\n",
            "[279/25][58/69] Loss_D: 0.0039 Loss_G: 6.8337\n",
            "[279/25][59/69] Loss_D: 0.0023 Loss_G: 8.4007\n",
            "[279/25][60/69] Loss_D: 0.0021 Loss_G: 7.7260\n",
            "[279/25][61/69] Loss_D: 0.0012 Loss_G: 7.9038\n",
            "[279/25][62/69] Loss_D: 0.0007 Loss_G: 8.4078\n",
            "[279/25][63/69] Loss_D: 0.0005 Loss_G: 8.8511\n",
            "[279/25][64/69] Loss_D: 0.0019 Loss_G: 7.5328\n",
            "[279/25][65/69] Loss_D: 0.0003 Loss_G: 9.1224\n",
            "[279/25][66/69] Loss_D: 0.0018 Loss_G: 7.5052\n",
            "[279/25][67/69] Loss_D: 0.0009 Loss_G: 7.8195\n",
            "[279/25][68/69] Loss_D: 0.2455 Loss_G: 3.4828\n",
            "[280/25][0/69] Loss_D: 0.0232 Loss_G: 3.5541\n",
            "[280/25][1/69] Loss_D: 0.1300 Loss_G: 5.0311\n",
            "[280/25][2/69] Loss_D: 0.0157 Loss_G: 7.7945\n",
            "[280/25][3/69] Loss_D: 0.0041 Loss_G: 8.8200\n",
            "[280/25][4/69] Loss_D: 0.0002 Loss_G: 11.9170\n",
            "[280/25][5/69] Loss_D: 0.0002 Loss_G: 12.3126\n",
            "[280/25][6/69] Loss_D: 0.0001 Loss_G: 13.5251\n",
            "[280/25][7/69] Loss_D: 0.0001 Loss_G: 13.4017\n",
            "[280/25][8/69] Loss_D: 0.0001 Loss_G: 14.9608\n",
            "[280/25][9/69] Loss_D: 0.0002 Loss_G: 14.8948\n",
            "[280/25][10/69] Loss_D: 0.0002 Loss_G: 15.1225\n",
            "[280/25][11/69] Loss_D: 0.0136 Loss_G: 16.9852\n",
            "[280/25][12/69] Loss_D: 0.0001 Loss_G: 14.7824\n",
            "[280/25][13/69] Loss_D: 0.0003 Loss_G: 14.2986\n",
            "[280/25][14/69] Loss_D: 0.0001 Loss_G: 15.0357\n",
            "[280/25][15/69] Loss_D: 0.0008 Loss_G: 14.4620\n",
            "[280/25][16/69] Loss_D: 0.0001 Loss_G: 13.0254\n",
            "[280/25][17/69] Loss_D: 0.0007 Loss_G: 13.2691\n",
            "[280/25][18/69] Loss_D: 0.0004 Loss_G: 13.3281\n",
            "[280/25][19/69] Loss_D: 0.0004 Loss_G: 11.7118\n",
            "[280/25][20/69] Loss_D: 0.0039 Loss_G: 11.3615\n",
            "[280/25][21/69] Loss_D: 0.0005 Loss_G: 10.6676\n",
            "[280/25][22/69] Loss_D: 0.0048 Loss_G: 10.2863\n",
            "[280/25][23/69] Loss_D: 0.0020 Loss_G: 9.8025\n",
            "[280/25][24/69] Loss_D: 0.0090 Loss_G: 8.8466\n",
            "[280/25][25/69] Loss_D: 0.0069 Loss_G: 8.7197\n",
            "[280/25][26/69] Loss_D: 0.0128 Loss_G: 8.3810\n",
            "[280/25][27/69] Loss_D: 0.0040 Loss_G: 8.6849\n",
            "[280/25][28/69] Loss_D: 0.0597 Loss_G: 7.9392\n",
            "[280/25][29/69] Loss_D: 0.0043 Loss_G: 7.3193\n",
            "[280/25][30/69] Loss_D: 0.0090 Loss_G: 6.2580\n",
            "[280/25][31/69] Loss_D: 0.0186 Loss_G: 5.7902\n",
            "[280/25][32/69] Loss_D: 0.0038 Loss_G: 7.1666\n",
            "[280/25][33/69] Loss_D: 0.0025 Loss_G: 7.8250\n",
            "[280/25][34/69] Loss_D: 0.0040 Loss_G: 7.6581\n",
            "[280/25][35/69] Loss_D: 0.0014 Loss_G: 8.6573\n",
            "[280/25][36/69] Loss_D: 0.0015 Loss_G: 8.4974\n",
            "[280/25][37/69] Loss_D: 0.0004 Loss_G: 10.6630\n",
            "[280/25][38/69] Loss_D: 0.0010 Loss_G: 9.0753\n",
            "[280/25][39/69] Loss_D: 0.0007 Loss_G: 9.8804\n",
            "[280/25][40/69] Loss_D: 0.0006 Loss_G: 10.5142\n",
            "[280/25][41/69] Loss_D: 0.0009 Loss_G: 9.4947\n",
            "[280/25][42/69] Loss_D: 0.0032 Loss_G: 9.5313\n",
            "[280/25][43/69] Loss_D: 0.0013 Loss_G: 10.1144\n",
            "[280/25][44/69] Loss_D: 0.0020 Loss_G: 8.9150\n",
            "[280/25][45/69] Loss_D: 0.0012 Loss_G: 9.0049\n",
            "[280/25][46/69] Loss_D: 0.0022 Loss_G: 9.4899\n",
            "[280/25][47/69] Loss_D: 0.0014 Loss_G: 8.9509\n",
            "[280/25][48/69] Loss_D: 0.0005 Loss_G: 9.6589\n",
            "[280/25][49/69] Loss_D: 0.0013 Loss_G: 10.2091\n",
            "[280/25][50/69] Loss_D: 0.0025 Loss_G: 8.2704\n",
            "[280/25][51/69] Loss_D: 0.0036 Loss_G: 8.6608\n",
            "[280/25][52/69] Loss_D: 0.0034 Loss_G: 7.7596\n",
            "[280/25][53/69] Loss_D: 0.0054 Loss_G: 8.4528\n",
            "[280/25][54/69] Loss_D: 0.0022 Loss_G: 8.3031\n",
            "[280/25][55/69] Loss_D: 0.0006 Loss_G: 9.2573\n",
            "[280/25][56/69] Loss_D: 0.0019 Loss_G: 7.8005\n",
            "[280/25][57/69] Loss_D: 0.0084 Loss_G: 8.9944\n",
            "[280/25][58/69] Loss_D: 0.0063 Loss_G: 9.2703\n",
            "[280/25][59/69] Loss_D: 0.0009 Loss_G: 8.3378\n",
            "[280/25][60/69] Loss_D: 0.0284 Loss_G: 7.3297\n",
            "[280/25][61/69] Loss_D: 0.0015 Loss_G: 6.7419\n",
            "[280/25][62/69] Loss_D: 0.0059 Loss_G: 5.7760\n",
            "[280/25][63/69] Loss_D: 0.0155 Loss_G: 5.4503\n",
            "[280/25][64/69] Loss_D: 0.0059 Loss_G: 6.5565\n",
            "[280/25][65/69] Loss_D: 0.0017 Loss_G: 7.4766\n",
            "[280/25][66/69] Loss_D: 0.0064 Loss_G: 6.6210\n",
            "[280/25][67/69] Loss_D: 0.0015 Loss_G: 7.9427\n",
            "[280/25][68/69] Loss_D: 0.0078 Loss_G: 8.8267\n",
            "[281/25][0/69] Loss_D: 0.0008 Loss_G: 8.5348\n",
            "[281/25][1/69] Loss_D: 0.0008 Loss_G: 8.4012\n",
            "[281/25][2/69] Loss_D: 0.0009 Loss_G: 8.4487\n",
            "[281/25][3/69] Loss_D: 0.0002 Loss_G: 9.5708\n",
            "[281/25][4/69] Loss_D: 0.0012 Loss_G: 9.2984\n",
            "[281/25][5/69] Loss_D: 0.0004 Loss_G: 9.2126\n",
            "[281/25][6/69] Loss_D: 0.0007 Loss_G: 8.9412\n",
            "[281/25][7/69] Loss_D: 0.0006 Loss_G: 9.3061\n",
            "[281/25][8/69] Loss_D: 0.0164 Loss_G: 8.4149\n",
            "[281/25][9/69] Loss_D: 0.0008 Loss_G: 8.7059\n",
            "[281/25][10/69] Loss_D: 0.0009 Loss_G: 8.3337\n",
            "[281/25][11/69] Loss_D: 0.0005 Loss_G: 8.6213\n",
            "[281/25][12/69] Loss_D: 0.0019 Loss_G: 8.1852\n",
            "[281/25][13/69] Loss_D: 0.0006 Loss_G: 9.4259\n",
            "[281/25][14/69] Loss_D: 0.0122 Loss_G: 8.7536\n",
            "[281/25][15/69] Loss_D: 0.0026 Loss_G: 7.4442\n",
            "[281/25][16/69] Loss_D: 0.0021 Loss_G: 7.1719\n",
            "[281/25][17/69] Loss_D: 0.0019 Loss_G: 7.5087\n",
            "[281/25][18/69] Loss_D: 0.0038 Loss_G: 6.7945\n",
            "[281/25][19/69] Loss_D: 0.0012 Loss_G: 7.9340\n",
            "[281/25][20/69] Loss_D: 0.0060 Loss_G: 6.2403\n",
            "[281/25][21/69] Loss_D: 0.0008 Loss_G: 8.5965\n",
            "[281/25][22/69] Loss_D: 0.0011 Loss_G: 7.7601\n",
            "[281/25][23/69] Loss_D: 0.0015 Loss_G: 7.5175\n",
            "[281/25][24/69] Loss_D: 0.0006 Loss_G: 8.5683\n",
            "[281/25][25/69] Loss_D: 0.0045 Loss_G: 6.8806\n",
            "[281/25][26/69] Loss_D: 0.0005 Loss_G: 8.4846\n",
            "[281/25][27/69] Loss_D: 0.0003 Loss_G: 9.0505\n",
            "[281/25][28/69] Loss_D: 0.0004 Loss_G: 8.7892\n",
            "[281/25][29/69] Loss_D: 0.0004 Loss_G: 8.7280\n",
            "[281/25][30/69] Loss_D: 0.0004 Loss_G: 8.7692\n",
            "[281/25][31/69] Loss_D: 0.0002 Loss_G: 9.2344\n",
            "[281/25][32/69] Loss_D: 0.0005 Loss_G: 8.8000\n",
            "[281/25][33/69] Loss_D: 0.0007 Loss_G: 8.1647\n",
            "[281/25][34/69] Loss_D: 0.0003 Loss_G: 9.3065\n",
            "[281/25][35/69] Loss_D: 0.0033 Loss_G: 10.7435\n",
            "[281/25][36/69] Loss_D: 0.0004 Loss_G: 8.4868\n",
            "[281/25][37/69] Loss_D: 0.0012 Loss_G: 8.8743\n",
            "[281/25][38/69] Loss_D: 0.0004 Loss_G: 8.3537\n",
            "[281/25][39/69] Loss_D: 0.0001 Loss_G: 10.4150\n",
            "[281/25][40/69] Loss_D: 0.0109 Loss_G: 7.2030\n",
            "[281/25][41/69] Loss_D: 0.0012 Loss_G: 7.0406\n",
            "[281/25][42/69] Loss_D: 0.0013 Loss_G: 7.1473\n",
            "[281/25][43/69] Loss_D: 0.0019 Loss_G: 7.0156\n",
            "[281/25][44/69] Loss_D: 0.0048 Loss_G: 6.5224\n",
            "[281/25][45/69] Loss_D: 0.0014 Loss_G: 7.6137\n",
            "[281/25][46/69] Loss_D: 0.0035 Loss_G: 6.6273\n",
            "[281/25][47/69] Loss_D: 0.0057 Loss_G: 7.1388\n",
            "[281/25][48/69] Loss_D: 0.0007 Loss_G: 8.2517\n",
            "[281/25][49/69] Loss_D: 0.0023 Loss_G: 7.1866\n",
            "[281/25][50/69] Loss_D: 0.0004 Loss_G: 8.6495\n",
            "[281/25][51/69] Loss_D: 0.0008 Loss_G: 8.7137\n",
            "[281/25][52/69] Loss_D: 0.0013 Loss_G: 7.5604\n",
            "[281/25][53/69] Loss_D: 0.0002 Loss_G: 10.3035\n",
            "[281/25][54/69] Loss_D: 0.0013 Loss_G: 8.5222\n",
            "[281/25][55/69] Loss_D: 0.0013 Loss_G: 7.7646\n",
            "[281/25][56/69] Loss_D: 0.0006 Loss_G: 8.5524\n",
            "[281/25][57/69] Loss_D: 0.0079 Loss_G: 8.0198\n",
            "[281/25][58/69] Loss_D: 0.0011 Loss_G: 7.9455\n",
            "[281/25][59/69] Loss_D: 0.0007 Loss_G: 8.1837\n",
            "[281/25][60/69] Loss_D: 0.0008 Loss_G: 8.8298\n",
            "[281/25][61/69] Loss_D: 0.0011 Loss_G: 8.4356\n",
            "[281/25][62/69] Loss_D: 0.0007 Loss_G: 8.1633\n",
            "[281/25][63/69] Loss_D: 0.0025 Loss_G: 6.9323\n",
            "[281/25][64/69] Loss_D: 0.0018 Loss_G: 7.2799\n",
            "[281/25][65/69] Loss_D: 0.0012 Loss_G: 7.6557\n",
            "[281/25][66/69] Loss_D: 0.0015 Loss_G: 7.8951\n",
            "[281/25][67/69] Loss_D: 0.0022 Loss_G: 7.1031\n",
            "[281/25][68/69] Loss_D: 0.0015 Loss_G: 7.6822\n",
            "[282/25][0/69] Loss_D: 0.0012 Loss_G: 7.9513\n",
            "[282/25][1/69] Loss_D: 0.0006 Loss_G: 9.1314\n",
            "[282/25][2/69] Loss_D: 0.0017 Loss_G: 8.9751\n",
            "[282/25][3/69] Loss_D: 0.1248 Loss_G: 5.6895\n",
            "[282/25][4/69] Loss_D: 0.0192 Loss_G: 3.9358\n",
            "[282/25][5/69] Loss_D: 0.0200 Loss_G: 4.8311\n",
            "[282/25][6/69] Loss_D: 0.0774 Loss_G: 5.6764\n",
            "[282/25][7/69] Loss_D: 0.0109 Loss_G: 7.5488\n",
            "[282/25][8/69] Loss_D: 0.0016 Loss_G: 9.1465\n",
            "[282/25][9/69] Loss_D: 0.0002 Loss_G: 11.1243\n",
            "[282/25][10/69] Loss_D: 0.0000 Loss_G: 12.7221\n",
            "[282/25][11/69] Loss_D: 0.0001 Loss_G: 14.2926\n",
            "[282/25][12/69] Loss_D: 0.0000 Loss_G: 14.6573\n",
            "[282/25][13/69] Loss_D: 0.0000 Loss_G: 17.2569\n",
            "[282/25][14/69] Loss_D: 0.0060 Loss_G: 17.0594\n",
            "[282/25][15/69] Loss_D: 0.0000 Loss_G: 17.3879\n",
            "[282/25][16/69] Loss_D: 0.0000 Loss_G: 16.5962\n",
            "[282/25][17/69] Loss_D: 0.0000 Loss_G: 19.6882\n",
            "[282/25][18/69] Loss_D: 0.0001 Loss_G: 17.8517\n",
            "[282/25][19/69] Loss_D: 0.0003 Loss_G: 20.2083\n",
            "[282/25][20/69] Loss_D: 0.1093 Loss_G: 20.6105\n",
            "[282/25][21/69] Loss_D: 0.0000 Loss_G: 19.1216\n",
            "[282/25][22/69] Loss_D: 0.0006 Loss_G: 16.6709\n",
            "[282/25][23/69] Loss_D: 0.0000 Loss_G: 15.4274\n",
            "[282/25][24/69] Loss_D: 0.0000 Loss_G: 15.2148\n",
            "[282/25][25/69] Loss_D: 0.0000 Loss_G: 15.1608\n",
            "[282/25][26/69] Loss_D: 0.0000 Loss_G: 13.0745\n",
            "[282/25][27/69] Loss_D: 0.0000 Loss_G: 12.7124\n",
            "[282/25][28/69] Loss_D: 0.0031 Loss_G: 12.1665\n",
            "[282/25][29/69] Loss_D: 0.0000 Loss_G: 13.7434\n",
            "[282/25][30/69] Loss_D: 0.0000 Loss_G: 10.9819\n",
            "[282/25][31/69] Loss_D: 0.0001 Loss_G: 10.6029\n",
            "[282/25][32/69] Loss_D: 0.0002 Loss_G: 9.4838\n",
            "[282/25][33/69] Loss_D: 0.0001 Loss_G: 10.2313\n",
            "[282/25][34/69] Loss_D: 0.0001 Loss_G: 9.8375\n",
            "[282/25][35/69] Loss_D: 0.0003 Loss_G: 9.2112\n",
            "[282/25][36/69] Loss_D: 0.0005 Loss_G: 8.8383\n",
            "[282/25][37/69] Loss_D: 0.0004 Loss_G: 8.8894\n",
            "[282/25][38/69] Loss_D: 0.0005 Loss_G: 8.3841\n",
            "[282/25][39/69] Loss_D: 0.0005 Loss_G: 8.6879\n",
            "[282/25][40/69] Loss_D: 0.0029 Loss_G: 7.1673\n",
            "[282/25][41/69] Loss_D: 0.0077 Loss_G: 6.2795\n",
            "[282/25][42/69] Loss_D: 0.0012 Loss_G: 8.1585\n",
            "[282/25][43/69] Loss_D: 0.0008 Loss_G: 8.5678\n",
            "[282/25][44/69] Loss_D: 0.0010 Loss_G: 7.9465\n",
            "[282/25][45/69] Loss_D: 0.0008 Loss_G: 8.3787\n",
            "[282/25][46/69] Loss_D: 0.0126 Loss_G: 6.0989\n",
            "[282/25][47/69] Loss_D: 0.0001 Loss_G: 10.3354\n",
            "[282/25][48/69] Loss_D: 0.0007 Loss_G: 8.6329\n",
            "[282/25][49/69] Loss_D: 0.0021 Loss_G: 7.6823\n",
            "[282/25][50/69] Loss_D: 0.0005 Loss_G: 9.1627\n",
            "[282/25][51/69] Loss_D: 0.0003 Loss_G: 9.8072\n",
            "[282/25][52/69] Loss_D: 0.0005 Loss_G: 8.8000\n",
            "[282/25][53/69] Loss_D: 0.0072 Loss_G: 10.9714\n",
            "[282/25][54/69] Loss_D: 0.0003 Loss_G: 8.9448\n",
            "[282/25][55/69] Loss_D: 0.0387 Loss_G: 7.9528\n",
            "[282/25][56/69] Loss_D: 0.0019 Loss_G: 6.5924\n",
            "[282/25][57/69] Loss_D: 0.0007 Loss_G: 7.5939\n",
            "[282/25][58/69] Loss_D: 0.0088 Loss_G: 5.1611\n",
            "[282/25][59/69] Loss_D: 0.0009 Loss_G: 7.8522\n",
            "[282/25][60/69] Loss_D: 0.0008 Loss_G: 8.3724\n",
            "[282/25][61/69] Loss_D: 0.0035 Loss_G: 6.5678\n",
            "[282/25][62/69] Loss_D: 0.0014 Loss_G: 7.3909\n",
            "[282/25][63/69] Loss_D: 0.0040 Loss_G: 6.7404\n",
            "[282/25][64/69] Loss_D: 0.0056 Loss_G: 6.2183\n",
            "[282/25][65/69] Loss_D: 0.0015 Loss_G: 8.2182\n",
            "[282/25][66/69] Loss_D: 0.0003 Loss_G: 9.6978\n",
            "[282/25][67/69] Loss_D: 0.0013 Loss_G: 8.8811\n",
            "[282/25][68/69] Loss_D: 0.0002 Loss_G: 12.7989\n",
            "[283/25][0/69] Loss_D: 0.0019 Loss_G: 7.4783\n",
            "[283/25][1/69] Loss_D: 0.0015 Loss_G: 7.8165\n",
            "[283/25][2/69] Loss_D: 0.0009 Loss_G: 8.2573\n",
            "[283/25][3/69] Loss_D: 0.0013 Loss_G: 7.8745\n",
            "[283/25][4/69] Loss_D: 0.0002 Loss_G: 9.8141\n",
            "[283/25][5/69] Loss_D: 0.0002 Loss_G: 10.1800\n",
            "[283/25][6/69] Loss_D: 0.0004 Loss_G: 9.0201\n",
            "[283/25][7/69] Loss_D: 0.0005 Loss_G: 8.8750\n",
            "[283/25][8/69] Loss_D: 0.0002 Loss_G: 9.5087\n",
            "[283/25][9/69] Loss_D: 0.0006 Loss_G: 8.2266\n",
            "[283/25][10/69] Loss_D: 0.0003 Loss_G: 8.8821\n",
            "[283/25][11/69] Loss_D: 0.0001 Loss_G: 10.4271\n",
            "[283/25][12/69] Loss_D: 0.0008 Loss_G: 8.2034\n",
            "[283/25][13/69] Loss_D: 0.0007 Loss_G: 7.7524\n",
            "[283/25][14/69] Loss_D: 0.0195 Loss_G: 8.2338\n",
            "[283/25][15/69] Loss_D: 0.0010 Loss_G: 8.6383\n",
            "[283/25][16/69] Loss_D: 0.0008 Loss_G: 7.7136\n",
            "[283/25][17/69] Loss_D: 0.0020 Loss_G: 6.9542\n",
            "[283/25][18/69] Loss_D: 0.0088 Loss_G: 5.7536\n",
            "[283/25][19/69] Loss_D: 0.0008 Loss_G: 8.3610\n",
            "[283/25][20/69] Loss_D: 0.0009 Loss_G: 8.2731\n",
            "[283/25][21/69] Loss_D: 0.0029 Loss_G: 7.2149\n",
            "[283/25][22/69] Loss_D: 0.0155 Loss_G: 6.8416\n",
            "[283/25][23/69] Loss_D: 0.0024 Loss_G: 6.9704\n",
            "[283/25][24/69] Loss_D: 0.0055 Loss_G: 6.3671\n",
            "[283/25][25/69] Loss_D: 0.0008 Loss_G: 8.5371\n",
            "[283/25][26/69] Loss_D: 0.0024 Loss_G: 7.1065\n",
            "[283/25][27/69] Loss_D: 0.0007 Loss_G: 8.5736\n",
            "[283/25][28/69] Loss_D: 0.0008 Loss_G: 8.2070\n",
            "[283/25][29/69] Loss_D: 0.0007 Loss_G: 8.7819\n",
            "[283/25][30/69] Loss_D: 0.0010 Loss_G: 8.4350\n",
            "[283/25][31/69] Loss_D: 0.0017 Loss_G: 7.8926\n",
            "[283/25][32/69] Loss_D: 0.0007 Loss_G: 8.3532\n",
            "[283/25][33/69] Loss_D: 0.0005 Loss_G: 9.4480\n",
            "[283/25][34/69] Loss_D: 0.0002 Loss_G: 9.4363\n",
            "[283/25][35/69] Loss_D: 0.0002 Loss_G: 10.5031\n",
            "[283/25][36/69] Loss_D: 0.0005 Loss_G: 9.8476\n",
            "[283/25][37/69] Loss_D: 0.0002 Loss_G: 9.6426\n",
            "[283/25][38/69] Loss_D: 0.0002 Loss_G: 9.7224\n",
            "[283/25][39/69] Loss_D: 0.0003 Loss_G: 9.1717\n",
            "[283/25][40/69] Loss_D: 0.0006 Loss_G: 9.0926\n",
            "[283/25][41/69] Loss_D: 0.0012 Loss_G: 9.5624\n",
            "[283/25][42/69] Loss_D: 0.0001 Loss_G: 10.4165\n",
            "[283/25][43/69] Loss_D: 0.0002 Loss_G: 9.6340\n",
            "[283/25][44/69] Loss_D: 0.0018 Loss_G: 9.4989\n",
            "[283/25][45/69] Loss_D: 0.0001 Loss_G: 9.6609\n",
            "[283/25][46/69] Loss_D: 0.0008 Loss_G: 8.2422\n",
            "[283/25][47/69] Loss_D: 0.0015 Loss_G: 7.5749\n",
            "[283/25][48/69] Loss_D: 0.0005 Loss_G: 8.3472\n",
            "[283/25][49/69] Loss_D: 0.0004 Loss_G: 8.8614\n",
            "[283/25][50/69] Loss_D: 0.0027 Loss_G: 9.9700\n",
            "[283/25][51/69] Loss_D: 0.0008 Loss_G: 8.1166\n",
            "[283/25][52/69] Loss_D: 0.0005 Loss_G: 8.4371\n",
            "[283/25][53/69] Loss_D: 0.0006 Loss_G: 7.9928\n",
            "[283/25][54/69] Loss_D: 0.0424 Loss_G: 6.0869\n",
            "[283/25][55/69] Loss_D: 0.0066 Loss_G: 5.4600\n",
            "[283/25][56/69] Loss_D: 0.0107 Loss_G: 5.9791\n",
            "[283/25][57/69] Loss_D: 0.0089 Loss_G: 6.5339\n",
            "[283/25][58/69] Loss_D: 0.0030 Loss_G: 7.3987\n",
            "[283/25][59/69] Loss_D: 0.0285 Loss_G: 6.6781\n",
            "[283/25][60/69] Loss_D: 0.0009 Loss_G: 8.9509\n",
            "[283/25][61/69] Loss_D: 0.0004 Loss_G: 10.6109\n",
            "[283/25][62/69] Loss_D: 0.0038 Loss_G: 11.1427\n",
            "[283/25][63/69] Loss_D: 0.0010 Loss_G: 10.9913\n",
            "[283/25][64/69] Loss_D: 0.0001 Loss_G: 11.8124\n",
            "[283/25][65/69] Loss_D: 0.0001 Loss_G: 12.5835\n",
            "[283/25][66/69] Loss_D: 0.0001 Loss_G: 12.3966\n",
            "[283/25][67/69] Loss_D: 0.0049 Loss_G: 13.7021\n",
            "[283/25][68/69] Loss_D: 0.0245 Loss_G: 13.5453\n",
            "[284/25][0/69] Loss_D: 0.0097 Loss_G: 12.4516\n",
            "[284/25][1/69] Loss_D: 0.0375 Loss_G: 10.5566\n",
            "[284/25][2/69] Loss_D: 0.0153 Loss_G: 8.7648\n",
            "[284/25][3/69] Loss_D: 0.0002 Loss_G: 8.6931\n",
            "[284/25][4/69] Loss_D: 0.0010 Loss_G: 6.7014\n",
            "[284/25][5/69] Loss_D: 0.0055 Loss_G: 5.2740\n",
            "[284/25][6/69] Loss_D: 0.0096 Loss_G: 5.0308\n",
            "[284/25][7/69] Loss_D: 0.0426 Loss_G: 5.3759\n",
            "[284/25][8/69] Loss_D: 0.0133 Loss_G: 6.5491\n",
            "[284/25][9/69] Loss_D: 0.0033 Loss_G: 7.5399\n",
            "[284/25][10/69] Loss_D: 0.0006 Loss_G: 9.1763\n",
            "[284/25][11/69] Loss_D: 0.0014 Loss_G: 8.6301\n",
            "[284/25][12/69] Loss_D: 0.0000 Loss_G: 12.2198\n",
            "[284/25][13/69] Loss_D: 0.0001 Loss_G: 11.6999\n",
            "[284/25][14/69] Loss_D: 0.0001 Loss_G: 11.3202\n",
            "[284/25][15/69] Loss_D: 0.0001 Loss_G: 12.1507\n",
            "[284/25][16/69] Loss_D: 0.0003 Loss_G: 11.6751\n",
            "[284/25][17/69] Loss_D: 0.0091 Loss_G: 12.1852\n",
            "[284/25][18/69] Loss_D: 0.0020 Loss_G: 13.1217\n",
            "[284/25][19/69] Loss_D: 0.0002 Loss_G: 11.7029\n",
            "[284/25][20/69] Loss_D: 0.0859 Loss_G: 10.7836\n",
            "[284/25][21/69] Loss_D: 0.0005 Loss_G: 9.7352\n",
            "[284/25][22/69] Loss_D: 0.0012 Loss_G: 8.4433\n",
            "[284/25][23/69] Loss_D: 0.0049 Loss_G: 6.9802\n",
            "[284/25][24/69] Loss_D: 0.0076 Loss_G: 6.6430\n",
            "[284/25][25/69] Loss_D: 0.0090 Loss_G: 6.4558\n",
            "[284/25][26/69] Loss_D: 0.0037 Loss_G: 6.8568\n",
            "[284/25][27/69] Loss_D: 0.0097 Loss_G: 5.6929\n",
            "[284/25][28/69] Loss_D: 0.0075 Loss_G: 6.6419\n",
            "[284/25][29/69] Loss_D: 0.0010 Loss_G: 8.5587\n",
            "[284/25][30/69] Loss_D: 0.0031 Loss_G: 7.6748\n",
            "[284/25][31/69] Loss_D: 0.0018 Loss_G: 8.9577\n",
            "[284/25][32/69] Loss_D: 0.0115 Loss_G: 7.7750\n",
            "[284/25][33/69] Loss_D: 0.0020 Loss_G: 9.0373\n",
            "[284/25][34/69] Loss_D: 0.0074 Loss_G: 8.2540\n",
            "[284/25][35/69] Loss_D: 0.0005 Loss_G: 10.0846\n",
            "[284/25][36/69] Loss_D: 0.0001 Loss_G: 11.6700\n",
            "[284/25][37/69] Loss_D: 0.0001 Loss_G: 12.1960\n",
            "[284/25][38/69] Loss_D: 0.0009 Loss_G: 11.0668\n",
            "[284/25][39/69] Loss_D: 0.0001 Loss_G: 12.0453\n",
            "[284/25][40/69] Loss_D: 0.0925 Loss_G: 10.8073\n",
            "[284/25][41/69] Loss_D: 0.0002 Loss_G: 8.6402\n",
            "[284/25][42/69] Loss_D: 0.0007 Loss_G: 7.1653\n",
            "[284/25][43/69] Loss_D: 0.0016 Loss_G: 6.5342\n",
            "[284/25][44/69] Loss_D: 0.0146 Loss_G: 5.8359\n",
            "[284/25][45/69] Loss_D: 0.0083 Loss_G: 6.2145\n",
            "[284/25][46/69] Loss_D: 0.0033 Loss_G: 7.7220\n",
            "[284/25][47/69] Loss_D: 0.0009 Loss_G: 8.9880\n",
            "[284/25][48/69] Loss_D: 0.0039 Loss_G: 7.7591\n",
            "[284/25][49/69] Loss_D: 0.0104 Loss_G: 6.8272\n",
            "[284/25][50/69] Loss_D: 0.0044 Loss_G: 7.9340\n",
            "[284/25][51/69] Loss_D: 0.0026 Loss_G: 8.2585\n",
            "[284/25][52/69] Loss_D: 0.0003 Loss_G: 9.9593\n",
            "[284/25][53/69] Loss_D: 0.0000 Loss_G: 11.8427\n",
            "[284/25][54/69] Loss_D: 0.0004 Loss_G: 9.4735\n",
            "[284/25][55/69] Loss_D: 0.0001 Loss_G: 11.7461\n",
            "[284/25][56/69] Loss_D: 0.0002 Loss_G: 11.1042\n",
            "[284/25][57/69] Loss_D: 0.0001 Loss_G: 10.5642\n",
            "[284/25][58/69] Loss_D: 0.0002 Loss_G: 9.9769\n",
            "[284/25][59/69] Loss_D: 0.0001 Loss_G: 10.3930\n",
            "[284/25][60/69] Loss_D: 0.0043 Loss_G: 10.6907\n",
            "[284/25][61/69] Loss_D: 0.1218 Loss_G: 7.3804\n",
            "[284/25][62/69] Loss_D: 0.0038 Loss_G: 4.8048\n",
            "[284/25][63/69] Loss_D: 0.0095 Loss_G: 5.4303\n",
            "[284/25][64/69] Loss_D: 0.0100 Loss_G: 5.8371\n",
            "[284/25][65/69] Loss_D: 0.0377 Loss_G: 5.3326\n",
            "[284/25][66/69] Loss_D: 0.0065 Loss_G: 7.0655\n",
            "[284/25][67/69] Loss_D: 0.0038 Loss_G: 7.7656\n",
            "[284/25][68/69] Loss_D: 0.0096 Loss_G: 7.9422\n",
            "[285/25][0/69] Loss_D: 0.0034 Loss_G: 9.9830\n",
            "[285/25][1/69] Loss_D: 0.0001 Loss_G: 13.5962\n",
            "[285/25][2/69] Loss_D: 0.0003 Loss_G: 12.4844\n",
            "[285/25][3/69] Loss_D: 0.0003 Loss_G: 12.0110\n",
            "[285/25][4/69] Loss_D: 0.0002 Loss_G: 12.8053\n",
            "[285/25][5/69] Loss_D: 0.0001 Loss_G: 13.5725\n",
            "[285/25][6/69] Loss_D: 0.0401 Loss_G: 12.0714\n",
            "[285/25][7/69] Loss_D: 0.0001 Loss_G: 12.2664\n",
            "[285/25][8/69] Loss_D: 0.0002 Loss_G: 11.8127\n",
            "[285/25][9/69] Loss_D: 0.0002 Loss_G: 10.8007\n",
            "[285/25][10/69] Loss_D: 0.0002 Loss_G: 10.1916\n",
            "[285/25][11/69] Loss_D: 0.0001 Loss_G: 10.5837\n",
            "[285/25][12/69] Loss_D: 0.0002 Loss_G: 9.2699\n",
            "[285/25][13/69] Loss_D: 0.0001 Loss_G: 9.6159\n",
            "[285/25][14/69] Loss_D: 0.0010 Loss_G: 7.7367\n",
            "[285/25][15/69] Loss_D: 0.0008 Loss_G: 8.9029\n",
            "[285/25][16/69] Loss_D: 0.0022 Loss_G: 8.3669\n",
            "[285/25][17/69] Loss_D: 0.0073 Loss_G: 7.7929\n",
            "[285/25][18/69] Loss_D: 0.0021 Loss_G: 10.0222\n",
            "[285/25][19/69] Loss_D: 0.0003 Loss_G: 10.5799\n",
            "[285/25][20/69] Loss_D: 0.0043 Loss_G: 7.8371\n",
            "[285/25][21/69] Loss_D: 0.0003 Loss_G: 10.1403\n",
            "[285/25][22/69] Loss_D: 0.0007 Loss_G: 9.4406\n",
            "[285/25][23/69] Loss_D: 0.0003 Loss_G: 10.3507\n",
            "[285/25][24/69] Loss_D: 0.0003 Loss_G: 10.6399\n",
            "[285/25][25/69] Loss_D: 0.0004 Loss_G: 10.1407\n",
            "[285/25][26/69] Loss_D: 0.0005 Loss_G: 9.9020\n",
            "[285/25][27/69] Loss_D: 0.0004 Loss_G: 10.3799\n",
            "[285/25][28/69] Loss_D: 0.0015 Loss_G: 10.4176\n",
            "[285/25][29/69] Loss_D: 0.0011 Loss_G: 9.2210\n",
            "[285/25][30/69] Loss_D: 0.0012 Loss_G: 8.8136\n",
            "[285/25][31/69] Loss_D: 0.0013 Loss_G: 9.7730\n",
            "[285/25][32/69] Loss_D: 0.0029 Loss_G: 8.2469\n",
            "[285/25][33/69] Loss_D: 0.0017 Loss_G: 8.5763\n",
            "[285/25][34/69] Loss_D: 0.0001 Loss_G: 12.2634\n",
            "[285/25][35/69] Loss_D: 0.0003 Loss_G: 9.9650\n",
            "[285/25][36/69] Loss_D: 0.0006 Loss_G: 8.8034\n",
            "[285/25][37/69] Loss_D: 0.0009 Loss_G: 8.6543\n",
            "[285/25][38/69] Loss_D: 0.0002 Loss_G: 10.2424\n",
            "[285/25][39/69] Loss_D: 0.0003 Loss_G: 9.9700\n",
            "[285/25][40/69] Loss_D: 0.0007 Loss_G: 12.0346\n",
            "[285/25][41/69] Loss_D: 0.0004 Loss_G: 9.7374\n",
            "[285/25][42/69] Loss_D: 0.0001 Loss_G: 10.5458\n",
            "[285/25][43/69] Loss_D: 0.0005 Loss_G: 9.2770\n",
            "[285/25][44/69] Loss_D: 0.0002 Loss_G: 9.6814\n",
            "[285/25][45/69] Loss_D: 0.0011 Loss_G: 8.6822\n",
            "[285/25][46/69] Loss_D: 0.0003 Loss_G: 9.6113\n",
            "[285/25][47/69] Loss_D: 0.0003 Loss_G: 9.6855\n",
            "[285/25][48/69] Loss_D: 0.0002 Loss_G: 9.8933\n",
            "[285/25][49/69] Loss_D: 0.0013 Loss_G: 8.1387\n",
            "[285/25][50/69] Loss_D: 0.0011 Loss_G: 10.7449\n",
            "[285/25][51/69] Loss_D: 0.0003 Loss_G: 9.1667\n",
            "[285/25][52/69] Loss_D: 0.0006 Loss_G: 9.0805\n",
            "[285/25][53/69] Loss_D: 0.0019 Loss_G: 9.8598\n",
            "[285/25][54/69] Loss_D: 0.0002 Loss_G: 10.0817\n",
            "[285/25][55/69] Loss_D: 0.0008 Loss_G: 8.6565\n",
            "[285/25][56/69] Loss_D: 0.0011 Loss_G: 8.0682\n",
            "[285/25][57/69] Loss_D: 0.0010 Loss_G: 8.4388\n",
            "[285/25][58/69] Loss_D: 0.0004 Loss_G: 9.1101\n",
            "[285/25][59/69] Loss_D: 0.0010 Loss_G: 8.0564\n",
            "[285/25][60/69] Loss_D: 0.0204 Loss_G: 9.8444\n",
            "[285/25][61/69] Loss_D: 0.0005 Loss_G: 8.6818\n",
            "[285/25][62/69] Loss_D: 0.0026 Loss_G: 6.6165\n",
            "[285/25][63/69] Loss_D: 0.0017 Loss_G: 7.7754\n",
            "[285/25][64/69] Loss_D: 0.0020 Loss_G: 7.5271\n",
            "[285/25][65/69] Loss_D: 0.0011 Loss_G: 8.1896\n",
            "[285/25][66/69] Loss_D: 0.0045 Loss_G: 6.9626\n",
            "[285/25][67/69] Loss_D: 0.0022 Loss_G: 7.6033\n",
            "[285/25][68/69] Loss_D: 0.0015 Loss_G: 8.2587\n",
            "[286/25][0/69] Loss_D: 0.0020 Loss_G: 7.6353\n",
            "[286/25][1/69] Loss_D: 0.0009 Loss_G: 8.8818\n",
            "[286/25][2/69] Loss_D: 0.0021 Loss_G: 7.8784\n",
            "[286/25][3/69] Loss_D: 0.0025 Loss_G: 7.8383\n",
            "[286/25][4/69] Loss_D: 0.0004 Loss_G: 9.8321\n",
            "[286/25][5/69] Loss_D: 0.0007 Loss_G: 9.9989\n",
            "[286/25][6/69] Loss_D: 0.0018 Loss_G: 8.0986\n",
            "[286/25][7/69] Loss_D: 0.0002 Loss_G: 10.0267\n",
            "[286/25][8/69] Loss_D: 0.0006 Loss_G: 8.9128\n",
            "[286/25][9/69] Loss_D: 0.0004 Loss_G: 9.7234\n",
            "[286/25][10/69] Loss_D: 0.0003 Loss_G: 9.7552\n",
            "[286/25][11/69] Loss_D: 0.0003 Loss_G: 9.6756\n",
            "[286/25][12/69] Loss_D: 0.0012 Loss_G: 8.2064\n",
            "[286/25][13/69] Loss_D: 0.0002 Loss_G: 10.2921\n",
            "[286/25][14/69] Loss_D: 0.0003 Loss_G: 11.2566\n",
            "[286/25][15/69] Loss_D: 0.0052 Loss_G: 8.8743\n",
            "[286/25][16/69] Loss_D: 0.0009 Loss_G: 9.1132\n",
            "[286/25][17/69] Loss_D: 0.0005 Loss_G: 8.8849\n",
            "[286/25][18/69] Loss_D: 0.0053 Loss_G: 8.8508\n",
            "[286/25][19/69] Loss_D: 0.2170 Loss_G: 5.0178\n",
            "[286/25][20/69] Loss_D: 0.0368 Loss_G: 4.1717\n",
            "[286/25][21/69] Loss_D: 0.0045 Loss_G: 6.8939\n",
            "[286/25][22/69] Loss_D: 0.0733 Loss_G: 6.0226\n",
            "[286/25][23/69] Loss_D: 0.0044 Loss_G: 8.8487\n",
            "[286/25][24/69] Loss_D: 0.0012 Loss_G: 10.6830\n",
            "[286/25][25/69] Loss_D: 0.0005 Loss_G: 13.1467\n",
            "[286/25][26/69] Loss_D: 0.0001 Loss_G: 14.6039\n",
            "[286/25][27/69] Loss_D: 0.0001 Loss_G: 15.4786\n",
            "[286/25][28/69] Loss_D: 0.0000 Loss_G: 17.3510\n",
            "[286/25][29/69] Loss_D: 0.0008 Loss_G: 17.1843\n",
            "[286/25][30/69] Loss_D: 0.0562 Loss_G: 16.0545\n",
            "[286/25][31/69] Loss_D: 0.0001 Loss_G: 15.3388\n",
            "[286/25][32/69] Loss_D: 0.0250 Loss_G: 12.9534\n",
            "[286/25][33/69] Loss_D: 0.0112 Loss_G: 11.1266\n",
            "[286/25][34/69] Loss_D: 0.0027 Loss_G: 10.2834\n",
            "[286/25][35/69] Loss_D: 0.0020 Loss_G: 9.1485\n",
            "[286/25][36/69] Loss_D: 0.0036 Loss_G: 9.1349\n",
            "[286/25][37/69] Loss_D: 0.0023 Loss_G: 9.0649\n",
            "[286/25][38/69] Loss_D: 0.0103 Loss_G: 6.1824\n",
            "[286/25][39/69] Loss_D: 0.0034 Loss_G: 7.7944\n",
            "[286/25][40/69] Loss_D: 0.0026 Loss_G: 8.1237\n",
            "[286/25][41/69] Loss_D: 0.0054 Loss_G: 6.7018\n",
            "[286/25][42/69] Loss_D: 0.0106 Loss_G: 6.8852\n",
            "[286/25][43/69] Loss_D: 0.0015 Loss_G: 8.3329\n",
            "[286/25][44/69] Loss_D: 0.0011 Loss_G: 8.2350\n",
            "[286/25][45/69] Loss_D: 0.0007 Loss_G: 9.1315\n",
            "[286/25][46/69] Loss_D: 0.0002 Loss_G: 9.7444\n",
            "[286/25][47/69] Loss_D: 0.0002 Loss_G: 10.4326\n",
            "[286/25][48/69] Loss_D: 0.0002 Loss_G: 9.7689\n",
            "[286/25][49/69] Loss_D: 0.0007 Loss_G: 9.2624\n",
            "[286/25][50/69] Loss_D: 0.0009 Loss_G: 9.1392\n",
            "[286/25][51/69] Loss_D: 0.0002 Loss_G: 10.6182\n",
            "[286/25][52/69] Loss_D: 0.0137 Loss_G: 10.2965\n",
            "[286/25][53/69] Loss_D: 0.0007 Loss_G: 9.3103\n",
            "[286/25][54/69] Loss_D: 0.0034 Loss_G: 8.3324\n",
            "[286/25][55/69] Loss_D: 0.0016 Loss_G: 9.3581\n",
            "[286/25][56/69] Loss_D: 0.0041 Loss_G: 8.5664\n",
            "[286/25][57/69] Loss_D: 0.0011 Loss_G: 9.1757\n",
            "[286/25][58/69] Loss_D: 0.0022 Loss_G: 8.2431\n",
            "[286/25][59/69] Loss_D: 0.0008 Loss_G: 9.3107\n",
            "[286/25][60/69] Loss_D: 0.0033 Loss_G: 8.2617\n",
            "[286/25][61/69] Loss_D: 0.0009 Loss_G: 9.7953\n",
            "[286/25][62/69] Loss_D: 0.0012 Loss_G: 9.0818\n",
            "[286/25][63/69] Loss_D: 0.0014 Loss_G: 8.7862\n",
            "[286/25][64/69] Loss_D: 0.0008 Loss_G: 9.1699\n",
            "[286/25][65/69] Loss_D: 0.0006 Loss_G: 9.2545\n",
            "[286/25][66/69] Loss_D: 0.0003 Loss_G: 9.9116\n",
            "[286/25][67/69] Loss_D: 0.0003 Loss_G: 9.7029\n",
            "[286/25][68/69] Loss_D: 0.0001 Loss_G: 10.2876\n",
            "[287/25][0/69] Loss_D: 0.0006 Loss_G: 8.8343\n",
            "[287/25][1/69] Loss_D: 0.0004 Loss_G: 9.9305\n",
            "[287/25][2/69] Loss_D: 0.0007 Loss_G: 9.1989\n",
            "[287/25][3/69] Loss_D: 0.0009 Loss_G: 8.6238\n",
            "[287/25][4/69] Loss_D: 0.0010 Loss_G: 8.7169\n",
            "[287/25][5/69] Loss_D: 0.0020 Loss_G: 8.2631\n",
            "[287/25][6/69] Loss_D: 0.0005 Loss_G: 8.8715\n",
            "[287/25][7/69] Loss_D: 0.0008 Loss_G: 9.7117\n",
            "[287/25][8/69] Loss_D: 0.0005 Loss_G: 9.8527\n",
            "[287/25][9/69] Loss_D: 0.0014 Loss_G: 8.7519\n",
            "[287/25][10/69] Loss_D: 0.0003 Loss_G: 10.3361\n",
            "[287/25][11/69] Loss_D: 0.0007 Loss_G: 9.2871\n",
            "[287/25][12/69] Loss_D: 0.0004 Loss_G: 9.7850\n",
            "[287/25][13/69] Loss_D: 0.0006 Loss_G: 9.1036\n",
            "[287/25][14/69] Loss_D: 0.0527 Loss_G: 8.0140\n",
            "[287/25][15/69] Loss_D: 0.0044 Loss_G: 7.3106\n",
            "[287/25][16/69] Loss_D: 0.0088 Loss_G: 7.6172\n",
            "[287/25][17/69] Loss_D: 0.0076 Loss_G: 7.8453\n",
            "[287/25][18/69] Loss_D: 0.0193 Loss_G: 7.2209\n",
            "[287/25][19/69] Loss_D: 0.0017 Loss_G: 8.6228\n",
            "[287/25][20/69] Loss_D: 0.0015 Loss_G: 9.4278\n",
            "[287/25][21/69] Loss_D: 0.0004 Loss_G: 9.8683\n",
            "[287/25][22/69] Loss_D: 0.0004 Loss_G: 10.3393\n",
            "[287/25][23/69] Loss_D: 0.0001 Loss_G: 11.4999\n",
            "[287/25][24/69] Loss_D: 0.0001 Loss_G: 11.9241\n",
            "[287/25][25/69] Loss_D: 0.0001 Loss_G: 10.7811\n",
            "[287/25][26/69] Loss_D: 0.0218 Loss_G: 11.4040\n",
            "[287/25][27/69] Loss_D: 0.0001 Loss_G: 11.6401\n",
            "[287/25][28/69] Loss_D: 0.0003 Loss_G: 10.0313\n",
            "[287/25][29/69] Loss_D: 0.0005 Loss_G: 9.8006\n",
            "[287/25][30/69] Loss_D: 0.0006 Loss_G: 9.4808\n",
            "[287/25][31/69] Loss_D: 0.0034 Loss_G: 8.4966\n",
            "[287/25][32/69] Loss_D: 0.0015 Loss_G: 9.3098\n",
            "[287/25][33/69] Loss_D: 0.0016 Loss_G: 8.8150\n",
            "[287/25][34/69] Loss_D: 0.0014 Loss_G: 8.6533\n",
            "[287/25][35/69] Loss_D: 0.0011 Loss_G: 8.3242\n",
            "[287/25][36/69] Loss_D: 0.0007 Loss_G: 9.6051\n",
            "[287/25][37/69] Loss_D: 0.0015 Loss_G: 9.3395\n",
            "[287/25][38/69] Loss_D: 0.0026 Loss_G: 8.2912\n",
            "[287/25][39/69] Loss_D: 0.0027 Loss_G: 9.0829\n",
            "[287/25][40/69] Loss_D: 0.0012 Loss_G: 9.2753\n",
            "[287/25][41/69] Loss_D: 0.0005 Loss_G: 9.2552\n",
            "[287/25][42/69] Loss_D: 0.0006 Loss_G: 9.4006\n",
            "[287/25][43/69] Loss_D: 0.0014 Loss_G: 8.3215\n",
            "[287/25][44/69] Loss_D: 0.0008 Loss_G: 9.9418\n",
            "[287/25][45/69] Loss_D: 0.0005 Loss_G: 9.3018\n",
            "[287/25][46/69] Loss_D: 0.0005 Loss_G: 8.7130\n",
            "[287/25][47/69] Loss_D: 0.0003 Loss_G: 9.5024\n",
            "[287/25][48/69] Loss_D: 0.0006 Loss_G: 8.9824\n",
            "[287/25][49/69] Loss_D: 0.0008 Loss_G: 8.6750\n",
            "[287/25][50/69] Loss_D: 0.0002 Loss_G: 9.5624\n",
            "[287/25][51/69] Loss_D: 0.0010 Loss_G: 8.5261\n",
            "[287/25][52/69] Loss_D: 0.0006 Loss_G: 9.4709\n",
            "[287/25][53/69] Loss_D: 0.0007 Loss_G: 8.9820\n",
            "[287/25][54/69] Loss_D: 0.0023 Loss_G: 9.1780\n",
            "[287/25][55/69] Loss_D: 0.0004 Loss_G: 9.0497\n",
            "[287/25][56/69] Loss_D: 0.0004 Loss_G: 9.2617\n",
            "[287/25][57/69] Loss_D: 0.0005 Loss_G: 8.8145\n",
            "[287/25][58/69] Loss_D: 0.0002 Loss_G: 11.2480\n",
            "[287/25][59/69] Loss_D: 0.0003 Loss_G: 9.6804\n",
            "[287/25][60/69] Loss_D: 0.0009 Loss_G: 8.5857\n",
            "[287/25][61/69] Loss_D: 0.0007 Loss_G: 8.7323\n",
            "[287/25][62/69] Loss_D: 0.0003 Loss_G: 9.5615\n",
            "[287/25][63/69] Loss_D: 0.0024 Loss_G: 7.4721\n",
            "[287/25][64/69] Loss_D: 0.0004 Loss_G: 9.6104\n",
            "[287/25][65/69] Loss_D: 0.0006 Loss_G: 8.5888\n",
            "[287/25][66/69] Loss_D: 0.0005 Loss_G: 9.0003\n",
            "[287/25][67/69] Loss_D: 0.0014 Loss_G: 8.9762\n",
            "[287/25][68/69] Loss_D: 0.1032 Loss_G: 6.6822\n",
            "[288/25][0/69] Loss_D: 0.0101 Loss_G: 6.3034\n",
            "[288/25][1/69] Loss_D: 0.0933 Loss_G: 6.2252\n",
            "[288/25][2/69] Loss_D: 0.0109 Loss_G: 7.8930\n",
            "[288/25][3/69] Loss_D: 0.0003 Loss_G: 11.3343\n",
            "[288/25][4/69] Loss_D: 0.0003 Loss_G: 11.0644\n",
            "[288/25][5/69] Loss_D: 0.0003 Loss_G: 10.9772\n",
            "[288/25][6/69] Loss_D: 0.0001 Loss_G: 11.7723\n",
            "[288/25][7/69] Loss_D: 0.0001 Loss_G: 12.9015\n",
            "[288/25][8/69] Loss_D: 0.0001 Loss_G: 13.8093\n",
            "[288/25][9/69] Loss_D: 0.0003 Loss_G: 13.6957\n",
            "[288/25][10/69] Loss_D: 0.0003 Loss_G: 15.2319\n",
            "[288/25][11/69] Loss_D: 0.0000 Loss_G: 14.4649\n",
            "[288/25][12/69] Loss_D: 0.0002 Loss_G: 15.2034\n",
            "[288/25][13/69] Loss_D: 0.0001 Loss_G: 14.1819\n",
            "[288/25][14/69] Loss_D: 0.0539 Loss_G: 13.3245\n",
            "[288/25][15/69] Loss_D: 0.0000 Loss_G: 13.3127\n",
            "[288/25][16/69] Loss_D: 0.0008 Loss_G: 13.7851\n",
            "[288/25][17/69] Loss_D: 0.0002 Loss_G: 11.7933\n",
            "[288/25][18/69] Loss_D: 0.0001 Loss_G: 12.4517\n",
            "[288/25][19/69] Loss_D: 0.0001 Loss_G: 11.1472\n",
            "[288/25][20/69] Loss_D: 0.0002 Loss_G: 10.3152\n",
            "[288/25][21/69] Loss_D: 0.0008 Loss_G: 10.1030\n",
            "[288/25][22/69] Loss_D: 0.0006 Loss_G: 9.1560\n",
            "[288/25][23/69] Loss_D: 0.0002 Loss_G: 10.1121\n",
            "[288/25][24/69] Loss_D: 0.0009 Loss_G: 8.9624\n",
            "[288/25][25/69] Loss_D: 0.0774 Loss_G: 9.7468\n",
            "[288/25][26/69] Loss_D: 0.0021 Loss_G: 6.7938\n",
            "[288/25][27/69] Loss_D: 0.0225 Loss_G: 5.7807\n",
            "[288/25][28/69] Loss_D: 0.0270 Loss_G: 6.9755\n",
            "[288/25][29/69] Loss_D: 0.0263 Loss_G: 7.6810\n",
            "[288/25][30/69] Loss_D: 0.0099 Loss_G: 7.7230\n",
            "[288/25][31/69] Loss_D: 0.0011 Loss_G: 9.3828\n",
            "[288/25][32/69] Loss_D: 0.0008 Loss_G: 9.5859\n",
            "[288/25][33/69] Loss_D: 0.0007 Loss_G: 10.4692\n",
            "[288/25][34/69] Loss_D: 0.0002 Loss_G: 11.0348\n",
            "[288/25][35/69] Loss_D: 0.0006 Loss_G: 11.0948\n",
            "[288/25][36/69] Loss_D: 0.0042 Loss_G: 12.5485\n",
            "[288/25][37/69] Loss_D: 0.0010 Loss_G: 14.1900\n",
            "[288/25][38/69] Loss_D: 0.0002 Loss_G: 12.5614\n",
            "[288/25][39/69] Loss_D: 0.0007 Loss_G: 12.0784\n",
            "[288/25][40/69] Loss_D: 0.0002 Loss_G: 13.2177\n",
            "[288/25][41/69] Loss_D: 0.0217 Loss_G: 13.2581\n",
            "[288/25][42/69] Loss_D: 0.0020 Loss_G: 10.9453\n",
            "[288/25][43/69] Loss_D: 0.0007 Loss_G: 11.0958\n",
            "[288/25][44/69] Loss_D: 0.0006 Loss_G: 11.3742\n",
            "[288/25][45/69] Loss_D: 0.0032 Loss_G: 10.5171\n",
            "[288/25][46/69] Loss_D: 0.0012 Loss_G: 11.5799\n",
            "[288/25][47/69] Loss_D: 0.0180 Loss_G: 10.0270\n",
            "[288/25][48/69] Loss_D: 0.0072 Loss_G: 8.7768\n",
            "[288/25][49/69] Loss_D: 0.0037 Loss_G: 9.5380\n",
            "[288/25][50/69] Loss_D: 0.0015 Loss_G: 9.3183\n",
            "[288/25][51/69] Loss_D: 0.0001 Loss_G: 12.2257\n",
            "[288/25][52/69] Loss_D: 0.0024 Loss_G: 8.5476\n",
            "[288/25][53/69] Loss_D: 0.0033 Loss_G: 8.5309\n",
            "[288/25][54/69] Loss_D: 0.0001 Loss_G: 10.0853\n",
            "[288/25][55/69] Loss_D: 0.0009 Loss_G: 8.3223\n",
            "[288/25][56/69] Loss_D: 0.0007 Loss_G: 9.0316\n",
            "[288/25][57/69] Loss_D: 0.0006 Loss_G: 8.8953\n",
            "[288/25][58/69] Loss_D: 0.0013 Loss_G: 7.7326\n",
            "[288/25][59/69] Loss_D: 0.0004 Loss_G: 8.9947\n",
            "[288/25][60/69] Loss_D: 0.0002 Loss_G: 9.7133\n",
            "[288/25][61/69] Loss_D: 0.0020 Loss_G: 7.2159\n",
            "[288/25][62/69] Loss_D: 0.0011 Loss_G: 8.0631\n",
            "[288/25][63/69] Loss_D: 0.0015 Loss_G: 9.7622\n",
            "[288/25][64/69] Loss_D: 0.0005 Loss_G: 9.9582\n",
            "[288/25][65/69] Loss_D: 0.0005 Loss_G: 9.4717\n",
            "[288/25][66/69] Loss_D: 0.0136 Loss_G: 7.7710\n",
            "[288/25][67/69] Loss_D: 0.0032 Loss_G: 6.9007\n",
            "[288/25][68/69] Loss_D: 0.0009 Loss_G: 7.8454\n",
            "[289/25][0/69] Loss_D: 0.0045 Loss_G: 6.0858\n",
            "[289/25][1/69] Loss_D: 0.0070 Loss_G: 6.1185\n",
            "[289/25][2/69] Loss_D: 0.0017 Loss_G: 7.9206\n",
            "[289/25][3/69] Loss_D: 0.0025 Loss_G: 7.1753\n",
            "[289/25][4/69] Loss_D: 0.0018 Loss_G: 7.5636\n",
            "[289/25][5/69] Loss_D: 0.0058 Loss_G: 6.9215\n",
            "[289/25][6/69] Loss_D: 0.0019 Loss_G: 7.6732\n",
            "[289/25][7/69] Loss_D: 0.0079 Loss_G: 6.5836\n",
            "[289/25][8/69] Loss_D: 0.0008 Loss_G: 9.1431\n",
            "[289/25][9/69] Loss_D: 0.0005 Loss_G: 9.0563\n",
            "[289/25][10/69] Loss_D: 0.0006 Loss_G: 8.6455\n",
            "[289/25][11/69] Loss_D: 0.0029 Loss_G: 9.0068\n",
            "[289/25][12/69] Loss_D: 0.0018 Loss_G: 7.4712\n",
            "[289/25][13/69] Loss_D: 0.0003 Loss_G: 10.0055\n",
            "[289/25][14/69] Loss_D: 0.0011 Loss_G: 7.9979\n",
            "[289/25][15/69] Loss_D: 0.0007 Loss_G: 9.1438\n",
            "[289/25][16/69] Loss_D: 0.0001 Loss_G: 10.9900\n",
            "[289/25][17/69] Loss_D: 0.0002 Loss_G: 10.8697\n",
            "[289/25][18/69] Loss_D: 0.0160 Loss_G: 8.8832\n",
            "[289/25][19/69] Loss_D: 0.0006 Loss_G: 8.9889\n",
            "[289/25][20/69] Loss_D: 0.0012 Loss_G: 11.7412\n",
            "[289/25][21/69] Loss_D: 0.0031 Loss_G: 7.0053\n",
            "[289/25][22/69] Loss_D: 0.0029 Loss_G: 6.5659\n",
            "[289/25][23/69] Loss_D: 0.0007 Loss_G: 8.0453\n",
            "[289/25][24/69] Loss_D: 0.0007 Loss_G: 8.2000\n",
            "[289/25][25/69] Loss_D: 0.0005 Loss_G: 8.2226\n",
            "[289/25][26/69] Loss_D: 0.0007 Loss_G: 8.5790\n",
            "[289/25][27/69] Loss_D: 0.0014 Loss_G: 7.3514\n",
            "[289/25][28/69] Loss_D: 0.0005 Loss_G: 8.6312\n",
            "[289/25][29/69] Loss_D: 0.0025 Loss_G: 6.6434\n",
            "[289/25][30/69] Loss_D: 0.0011 Loss_G: 7.4827\n",
            "[289/25][31/69] Loss_D: 0.0042 Loss_G: 6.1949\n",
            "[289/25][32/69] Loss_D: 0.0018 Loss_G: 9.1696\n",
            "[289/25][33/69] Loss_D: 0.0241 Loss_G: 8.3790\n",
            "[289/25][34/69] Loss_D: 0.0038 Loss_G: 6.4666\n",
            "[289/25][35/69] Loss_D: 0.0072 Loss_G: 5.5666\n",
            "[289/25][36/69] Loss_D: 0.0062 Loss_G: 6.3072\n",
            "[289/25][37/69] Loss_D: 0.0062 Loss_G: 6.3907\n",
            "[289/25][38/69] Loss_D: 0.0032 Loss_G: 8.1414\n",
            "[289/25][39/69] Loss_D: 0.0050 Loss_G: 6.8531\n",
            "[289/25][40/69] Loss_D: 0.0004 Loss_G: 9.3298\n",
            "[289/25][41/69] Loss_D: 0.0017 Loss_G: 8.2802\n",
            "[289/25][42/69] Loss_D: 0.0011 Loss_G: 9.8033\n",
            "[289/25][43/69] Loss_D: 0.0008 Loss_G: 8.3587\n",
            "[289/25][44/69] Loss_D: 0.0109 Loss_G: 7.2736\n",
            "[289/25][45/69] Loss_D: 0.0012 Loss_G: 9.3658\n",
            "[289/25][46/69] Loss_D: 0.0019 Loss_G: 7.3966\n",
            "[289/25][47/69] Loss_D: 0.0010 Loss_G: 8.3131\n",
            "[289/25][48/69] Loss_D: 0.0031 Loss_G: 7.7793\n",
            "[289/25][49/69] Loss_D: 0.0022 Loss_G: 7.2675\n",
            "[289/25][50/69] Loss_D: 0.0037 Loss_G: 7.3810\n",
            "[289/25][51/69] Loss_D: 0.0011 Loss_G: 8.5359\n",
            "[289/25][52/69] Loss_D: 0.0017 Loss_G: 8.1857\n",
            "[289/25][53/69] Loss_D: 0.0010 Loss_G: 8.6421\n",
            "[289/25][54/69] Loss_D: 0.0012 Loss_G: 7.9124\n",
            "[289/25][55/69] Loss_D: 0.0003 Loss_G: 11.2742\n",
            "[289/25][56/69] Loss_D: 0.0024 Loss_G: 8.1584\n",
            "[289/25][57/69] Loss_D: 0.0018 Loss_G: 8.4319\n",
            "[289/25][58/69] Loss_D: 0.0010 Loss_G: 7.8161\n",
            "[289/25][59/69] Loss_D: 0.0003 Loss_G: 10.0121\n",
            "[289/25][60/69] Loss_D: 0.0032 Loss_G: 9.3474\n",
            "[289/25][61/69] Loss_D: 0.0005 Loss_G: 8.9429\n",
            "[289/25][62/69] Loss_D: 0.0022 Loss_G: 9.6602\n",
            "[289/25][63/69] Loss_D: 0.0010 Loss_G: 8.0065\n",
            "[289/25][64/69] Loss_D: 0.0004 Loss_G: 8.5292\n",
            "[289/25][65/69] Loss_D: 0.0005 Loss_G: 8.4205\n",
            "[289/25][66/69] Loss_D: 0.0001 Loss_G: 10.6272\n",
            "[289/25][67/69] Loss_D: 0.0019 Loss_G: 6.8847\n",
            "[289/25][68/69] Loss_D: 0.0067 Loss_G: 9.4339\n",
            "[290/25][0/69] Loss_D: 0.0008 Loss_G: 7.9116\n",
            "[290/25][1/69] Loss_D: 0.0035 Loss_G: 6.5748\n",
            "[290/25][2/69] Loss_D: 0.0020 Loss_G: 7.9016\n",
            "[290/25][3/69] Loss_D: 0.0003 Loss_G: 9.3050\n",
            "[290/25][4/69] Loss_D: 0.0009 Loss_G: 9.3000\n",
            "[290/25][5/69] Loss_D: 0.0070 Loss_G: 6.4577\n",
            "[290/25][6/69] Loss_D: 0.0013 Loss_G: 7.4235\n",
            "[290/25][7/69] Loss_D: 0.0018 Loss_G: 7.5537\n",
            "[290/25][8/69] Loss_D: 0.0041 Loss_G: 6.4225\n",
            "[290/25][9/69] Loss_D: 0.0066 Loss_G: 6.2123\n",
            "[290/25][10/69] Loss_D: 0.0173 Loss_G: 8.0599\n",
            "[290/25][11/69] Loss_D: 0.0007 Loss_G: 9.5569\n",
            "[290/25][12/69] Loss_D: 0.0011 Loss_G: 7.6596\n",
            "[290/25][13/69] Loss_D: 0.0014 Loss_G: 7.9201\n",
            "[290/25][14/69] Loss_D: 0.0054 Loss_G: 7.1624\n",
            "[290/25][15/69] Loss_D: 0.0016 Loss_G: 7.9060\n",
            "[290/25][16/69] Loss_D: 0.0033 Loss_G: 6.7712\n",
            "[290/25][17/69] Loss_D: 0.0007 Loss_G: 8.6796\n",
            "[290/25][18/69] Loss_D: 0.0002 Loss_G: 9.6960\n",
            "[290/25][19/69] Loss_D: 0.0048 Loss_G: 6.5319\n",
            "[290/25][20/69] Loss_D: 0.0009 Loss_G: 10.2067\n",
            "[290/25][21/69] Loss_D: 0.0011 Loss_G: 8.1174\n",
            "[290/25][22/69] Loss_D: 0.0006 Loss_G: 8.6179\n",
            "[290/25][23/69] Loss_D: 0.0003 Loss_G: 9.1523\n",
            "[290/25][24/69] Loss_D: 0.0007 Loss_G: 8.7635\n",
            "[290/25][25/69] Loss_D: 0.0013 Loss_G: 9.6054\n",
            "[290/25][26/69] Loss_D: 0.0005 Loss_G: 8.5144\n",
            "[290/25][27/69] Loss_D: 0.0403 Loss_G: 8.7220\n",
            "[290/25][28/69] Loss_D: 0.0141 Loss_G: 7.9860\n",
            "[290/25][29/69] Loss_D: 0.0097 Loss_G: 6.3631\n",
            "[290/25][30/69] Loss_D: 0.1150 Loss_G: 8.1138\n",
            "[290/25][31/69] Loss_D: 0.0003 Loss_G: 10.9714\n",
            "[290/25][32/69] Loss_D: 0.0005 Loss_G: 12.9641\n",
            "[290/25][33/69] Loss_D: 0.0007 Loss_G: 11.9681\n",
            "[290/25][34/69] Loss_D: 0.0022 Loss_G: 12.3348\n",
            "[290/25][35/69] Loss_D: 0.0891 Loss_G: 16.5197\n",
            "[290/25][36/69] Loss_D: 0.0869 Loss_G: 12.9093\n",
            "[290/25][37/69] Loss_D: 0.0190 Loss_G: 11.8942\n",
            "[290/25][38/69] Loss_D: 0.3918 Loss_G: 9.3898\n",
            "[290/25][39/69] Loss_D: 0.0254 Loss_G: 6.8635\n",
            "[290/25][40/69] Loss_D: 0.0329 Loss_G: 7.8477\n",
            "[290/25][41/69] Loss_D: 0.0010 Loss_G: 9.8612\n",
            "[290/25][42/69] Loss_D: 0.0009 Loss_G: 10.2697\n",
            "[290/25][43/69] Loss_D: 0.0009 Loss_G: 11.0641\n",
            "[290/25][44/69] Loss_D: 0.0014 Loss_G: 12.0801\n",
            "[290/25][45/69] Loss_D: 0.0048 Loss_G: 10.3036\n",
            "[290/25][46/69] Loss_D: 0.3942 Loss_G: 6.4682\n",
            "[290/25][47/69] Loss_D: 0.1920 Loss_G: 5.0455\n",
            "[290/25][48/69] Loss_D: 0.6354 Loss_G: 10.1898\n",
            "[290/25][49/69] Loss_D: 0.0016 Loss_G: 15.2646\n",
            "[290/25][50/69] Loss_D: 0.0980 Loss_G: 19.7630\n",
            "[290/25][51/69] Loss_D: 0.0022 Loss_G: 22.6673\n",
            "[290/25][52/69] Loss_D: 0.0631 Loss_G: 22.0335\n",
            "[290/25][53/69] Loss_D: 0.0041 Loss_G: 24.2181\n",
            "[290/25][54/69] Loss_D: 0.0833 Loss_G: 23.9503\n",
            "[290/25][55/69] Loss_D: 0.0025 Loss_G: 20.9791\n",
            "[290/25][56/69] Loss_D: 0.0180 Loss_G: 20.5855\n",
            "[290/25][57/69] Loss_D: 0.0004 Loss_G: 21.4500\n",
            "[290/25][58/69] Loss_D: 0.0325 Loss_G: 22.1694\n",
            "[290/25][59/69] Loss_D: 0.0021 Loss_G: 21.9029\n",
            "[290/25][60/69] Loss_D: 0.0014 Loss_G: 24.2751\n",
            "[290/25][61/69] Loss_D: 0.0002 Loss_G: 22.3135\n",
            "[290/25][62/69] Loss_D: 0.0003 Loss_G: 24.3057\n",
            "[290/25][63/69] Loss_D: 0.0002 Loss_G: 22.2889\n",
            "[290/25][64/69] Loss_D: 0.0000 Loss_G: 21.5816\n",
            "[290/25][65/69] Loss_D: 0.0035 Loss_G: 20.4776\n",
            "[290/25][66/69] Loss_D: 0.0000 Loss_G: 21.3443\n",
            "[290/25][67/69] Loss_D: 0.0001 Loss_G: 20.6520\n",
            "[290/25][68/69] Loss_D: 0.0470 Loss_G: 18.8036\n",
            "[291/25][0/69] Loss_D: 0.0036 Loss_G: 18.4189\n",
            "[291/25][1/69] Loss_D: 0.0082 Loss_G: 20.7419\n",
            "[291/25][2/69] Loss_D: 0.0037 Loss_G: 18.7834\n",
            "[291/25][3/69] Loss_D: 0.0066 Loss_G: 18.9030\n",
            "[291/25][4/69] Loss_D: 0.0389 Loss_G: 20.4418\n",
            "[291/25][5/69] Loss_D: 0.0102 Loss_G: 15.4647\n",
            "[291/25][6/69] Loss_D: 0.0031 Loss_G: 17.8677\n",
            "[291/25][7/69] Loss_D: 0.0001 Loss_G: 17.4331\n",
            "[291/25][8/69] Loss_D: 0.0001 Loss_G: 19.6245\n",
            "[291/25][9/69] Loss_D: 0.0009 Loss_G: 18.8834\n",
            "[291/25][10/69] Loss_D: 0.0048 Loss_G: 16.3686\n",
            "[291/25][11/69] Loss_D: 0.0005 Loss_G: 19.2526\n",
            "[291/25][12/69] Loss_D: 0.0022 Loss_G: 15.5301\n",
            "[291/25][13/69] Loss_D: 0.0131 Loss_G: 21.7179\n",
            "[291/25][14/69] Loss_D: 0.0006 Loss_G: 18.2892\n",
            "[291/25][15/69] Loss_D: 0.0003 Loss_G: 18.7335\n",
            "[291/25][16/69] Loss_D: 0.0090 Loss_G: 16.6425\n",
            "[291/25][17/69] Loss_D: 0.0059 Loss_G: 17.2319\n",
            "[291/25][18/69] Loss_D: 0.0039 Loss_G: 14.2380\n",
            "[291/25][19/69] Loss_D: 0.0032 Loss_G: 13.7183\n",
            "[291/25][20/69] Loss_D: 0.0012 Loss_G: 17.8163\n",
            "[291/25][21/69] Loss_D: 0.0074 Loss_G: 15.8738\n",
            "[291/25][22/69] Loss_D: 0.0010 Loss_G: 19.0399\n",
            "[291/25][23/69] Loss_D: 0.0056 Loss_G: 18.2684\n",
            "[291/25][24/69] Loss_D: 0.0120 Loss_G: 14.2576\n",
            "[291/25][25/69] Loss_D: 0.0007 Loss_G: 16.9362\n",
            "[291/25][26/69] Loss_D: 0.0427 Loss_G: 12.2693\n",
            "[291/25][27/69] Loss_D: 0.0053 Loss_G: 11.9398\n",
            "[291/25][28/69] Loss_D: 0.0072 Loss_G: 13.3653\n",
            "[291/25][29/69] Loss_D: 0.0024 Loss_G: 12.9230\n",
            "[291/25][30/69] Loss_D: 0.0030 Loss_G: 12.6003\n",
            "[291/25][31/69] Loss_D: 0.0044 Loss_G: 11.5148\n",
            "[291/25][32/69] Loss_D: 0.0023 Loss_G: 14.4415\n",
            "[291/25][33/69] Loss_D: 0.0085 Loss_G: 11.2093\n",
            "[291/25][34/69] Loss_D: 0.0033 Loss_G: 12.1609\n",
            "[291/25][35/69] Loss_D: 0.0037 Loss_G: 10.7482\n",
            "[291/25][36/69] Loss_D: 0.0013 Loss_G: 14.1448\n",
            "[291/25][37/69] Loss_D: 0.0013 Loss_G: 11.6299\n",
            "[291/25][38/69] Loss_D: 0.0055 Loss_G: 13.1336\n",
            "[291/25][39/69] Loss_D: 0.0038 Loss_G: 12.9797\n",
            "[291/25][40/69] Loss_D: 0.0073 Loss_G: 12.3893\n",
            "[291/25][41/69] Loss_D: 0.0003 Loss_G: 12.7346\n",
            "[291/25][42/69] Loss_D: 0.0526 Loss_G: 15.3364\n",
            "[291/25][43/69] Loss_D: 0.0015 Loss_G: 12.0318\n",
            "[291/25][44/69] Loss_D: 0.0022 Loss_G: 10.0060\n",
            "[291/25][45/69] Loss_D: 0.0024 Loss_G: 11.1488\n",
            "[291/25][46/69] Loss_D: 0.0025 Loss_G: 9.9911\n",
            "[291/25][47/69] Loss_D: 0.0056 Loss_G: 8.8218\n",
            "[291/25][48/69] Loss_D: 0.0129 Loss_G: 9.6826\n",
            "[291/25][49/69] Loss_D: 0.0219 Loss_G: 8.7352\n",
            "[291/25][50/69] Loss_D: 0.0039 Loss_G: 9.5552\n",
            "[291/25][51/69] Loss_D: 0.0020 Loss_G: 10.7619\n",
            "[291/25][52/69] Loss_D: 0.0008 Loss_G: 11.0256\n",
            "[291/25][53/69] Loss_D: 0.0004 Loss_G: 12.0004\n",
            "[291/25][54/69] Loss_D: 0.0003 Loss_G: 12.0401\n",
            "[291/25][55/69] Loss_D: 0.0002 Loss_G: 12.7511\n",
            "[291/25][56/69] Loss_D: 0.0007 Loss_G: 12.9730\n",
            "[291/25][57/69] Loss_D: 0.0001 Loss_G: 12.8095\n",
            "[291/25][58/69] Loss_D: 0.0009 Loss_G: 11.6261\n",
            "[291/25][59/69] Loss_D: 0.0002 Loss_G: 11.9696\n",
            "[291/25][60/69] Loss_D: 0.0076 Loss_G: 11.2390\n",
            "[291/25][61/69] Loss_D: 0.0004 Loss_G: 10.6192\n",
            "[291/25][62/69] Loss_D: 0.0014 Loss_G: 9.9702\n",
            "[291/25][63/69] Loss_D: 0.0058 Loss_G: 9.9028\n",
            "[291/25][64/69] Loss_D: 0.0022 Loss_G: 8.7779\n",
            "[291/25][65/69] Loss_D: 0.0026 Loss_G: 8.5988\n",
            "[291/25][66/69] Loss_D: 0.0026 Loss_G: 7.9140\n",
            "[291/25][67/69] Loss_D: 0.0113 Loss_G: 7.2858\n",
            "[291/25][68/69] Loss_D: 0.0186 Loss_G: 7.8019\n",
            "[292/25][0/69] Loss_D: 0.0100 Loss_G: 7.2824\n",
            "[292/25][1/69] Loss_D: 0.0022 Loss_G: 9.1910\n",
            "[292/25][2/69] Loss_D: 0.0334 Loss_G: 8.0079\n",
            "[292/25][3/69] Loss_D: 0.2320 Loss_G: 4.8211\n",
            "[292/25][4/69] Loss_D: 0.0084 Loss_G: 4.3048\n",
            "[292/25][5/69] Loss_D: 0.4065 Loss_G: 8.4383\n",
            "[292/25][6/69] Loss_D: 0.0012 Loss_G: 13.8239\n",
            "[292/25][7/69] Loss_D: 0.0001 Loss_G: 16.7453\n",
            "[292/25][8/69] Loss_D: 0.0004 Loss_G: 21.4754\n",
            "[292/25][9/69] Loss_D: 0.0306 Loss_G: 23.1133\n",
            "[292/25][10/69] Loss_D: 0.0034 Loss_G: 25.7695\n",
            "[292/25][11/69] Loss_D: 0.0598 Loss_G: 26.1779\n",
            "[292/25][12/69] Loss_D: 0.0181 Loss_G: 23.4717\n",
            "[292/25][13/69] Loss_D: 0.1256 Loss_G: 23.5348\n",
            "[292/25][14/69] Loss_D: 0.0021 Loss_G: 20.5842\n",
            "[292/25][15/69] Loss_D: 0.0000 Loss_G: 19.0328\n",
            "[292/25][16/69] Loss_D: 0.0000 Loss_G: 16.7569\n",
            "[292/25][17/69] Loss_D: 0.0000 Loss_G: 16.3374\n",
            "[292/25][18/69] Loss_D: 0.0000 Loss_G: 14.4563\n",
            "[292/25][19/69] Loss_D: 0.0000 Loss_G: 12.8910\n",
            "[292/25][20/69] Loss_D: 0.0002 Loss_G: 12.5430\n",
            "[292/25][21/69] Loss_D: 0.0001 Loss_G: 13.4234\n",
            "[292/25][22/69] Loss_D: 0.0059 Loss_G: 9.4240\n",
            "[292/25][23/69] Loss_D: 0.0022 Loss_G: 10.2236\n",
            "[292/25][24/69] Loss_D: 0.0039 Loss_G: 9.6847\n",
            "[292/25][25/69] Loss_D: 0.0023 Loss_G: 10.1051\n",
            "[292/25][26/69] Loss_D: 0.0120 Loss_G: 10.5350\n",
            "[292/25][27/69] Loss_D: 0.0198 Loss_G: 8.4660\n",
            "[292/25][28/69] Loss_D: 0.0083 Loss_G: 10.5112\n",
            "[292/25][29/69] Loss_D: 0.0038 Loss_G: 10.7947\n",
            "[292/25][30/69] Loss_D: 0.0006 Loss_G: 13.3853\n",
            "[292/25][31/69] Loss_D: 0.0003 Loss_G: 12.6114\n",
            "[292/25][32/69] Loss_D: 0.0003 Loss_G: 13.0159\n",
            "[292/25][33/69] Loss_D: 0.0002 Loss_G: 11.9597\n",
            "[292/25][34/69] Loss_D: 0.0002 Loss_G: 13.2016\n",
            "[292/25][35/69] Loss_D: 0.0001 Loss_G: 13.9907\n",
            "[292/25][36/69] Loss_D: 0.0002 Loss_G: 16.6619\n",
            "[292/25][37/69] Loss_D: 0.0008 Loss_G: 14.3921\n",
            "[292/25][38/69] Loss_D: 0.0316 Loss_G: 12.1018\n",
            "[292/25][39/69] Loss_D: 0.0006 Loss_G: 10.7303\n",
            "[292/25][40/69] Loss_D: 0.0016 Loss_G: 10.1486\n",
            "[292/25][41/69] Loss_D: 0.0017 Loss_G: 9.0115\n",
            "[292/25][42/69] Loss_D: 0.0028 Loss_G: 7.9262\n",
            "[292/25][43/69] Loss_D: 0.0044 Loss_G: 8.2503\n",
            "[292/25][44/69] Loss_D: 0.0024 Loss_G: 9.9827\n",
            "[292/25][45/69] Loss_D: 0.0526 Loss_G: 8.3307\n",
            "[292/25][46/69] Loss_D: 0.0072 Loss_G: 9.4604\n",
            "[292/25][47/69] Loss_D: 0.0022 Loss_G: 10.4460\n",
            "[292/25][48/69] Loss_D: 0.0033 Loss_G: 11.3197\n",
            "[292/25][49/69] Loss_D: 0.0006 Loss_G: 11.2058\n",
            "[292/25][50/69] Loss_D: 0.0074 Loss_G: 14.6987\n",
            "[292/25][51/69] Loss_D: 0.0146 Loss_G: 13.9743\n",
            "[292/25][52/69] Loss_D: 0.3906 Loss_G: 8.8369\n",
            "[292/25][53/69] Loss_D: 0.0004 Loss_G: 6.2680\n",
            "[292/25][54/69] Loss_D: 0.3682 Loss_G: 9.4493\n",
            "[292/25][55/69] Loss_D: 0.0056 Loss_G: 14.2852\n",
            "[292/25][56/69] Loss_D: 0.0000 Loss_G: 20.8178\n",
            "[292/25][57/69] Loss_D: 0.0000 Loss_G: 24.2358\n",
            "[292/25][58/69] Loss_D: 0.0000 Loss_G: 26.0913\n",
            "[292/25][59/69] Loss_D: 0.0008 Loss_G: 30.3149\n",
            "[292/25][60/69] Loss_D: 0.9457 Loss_G: 25.8262\n",
            "[292/25][61/69] Loss_D: 0.0019 Loss_G: 19.9641\n",
            "[292/25][62/69] Loss_D: 0.0000 Loss_G: 18.0721\n",
            "[292/25][63/69] Loss_D: 0.0000 Loss_G: 15.1365\n",
            "[292/25][64/69] Loss_D: 0.0010 Loss_G: 14.2854\n",
            "[292/25][65/69] Loss_D: 0.0040 Loss_G: 13.0284\n",
            "[292/25][66/69] Loss_D: 0.0457 Loss_G: 11.0115\n",
            "[292/25][67/69] Loss_D: 0.0081 Loss_G: 10.8264\n",
            "[292/25][68/69] Loss_D: 0.0016 Loss_G: 11.0502\n",
            "[293/25][0/69] Loss_D: 0.0010 Loss_G: 11.5766\n",
            "[293/25][1/69] Loss_D: 0.0009 Loss_G: 12.0324\n",
            "[293/25][2/69] Loss_D: 0.0014 Loss_G: 9.8411\n",
            "[293/25][3/69] Loss_D: 0.0156 Loss_G: 9.6831\n",
            "[293/25][4/69] Loss_D: 0.0106 Loss_G: 9.5051\n",
            "[293/25][5/69] Loss_D: 0.0056 Loss_G: 9.6867\n",
            "[293/25][6/69] Loss_D: 0.0039 Loss_G: 9.7068\n",
            "[293/25][7/69] Loss_D: 0.0045 Loss_G: 9.2004\n",
            "[293/25][8/69] Loss_D: 0.0181 Loss_G: 8.7739\n",
            "[293/25][9/69] Loss_D: 0.0282 Loss_G: 8.6072\n",
            "[293/25][10/69] Loss_D: 0.0026 Loss_G: 8.6938\n",
            "[293/25][11/69] Loss_D: 0.0182 Loss_G: 7.1497\n",
            "[293/25][12/69] Loss_D: 0.0073 Loss_G: 7.5052\n",
            "[293/25][13/69] Loss_D: 0.0069 Loss_G: 7.3729\n",
            "[293/25][14/69] Loss_D: 0.0067 Loss_G: 7.2111\n",
            "[293/25][15/69] Loss_D: 0.0101 Loss_G: 7.0551\n",
            "[293/25][16/69] Loss_D: 0.0027 Loss_G: 7.8110\n",
            "[293/25][17/69] Loss_D: 0.0033 Loss_G: 7.8654\n",
            "[293/25][18/69] Loss_D: 0.0044 Loss_G: 7.5652\n",
            "[293/25][19/69] Loss_D: 0.0055 Loss_G: 7.9303\n",
            "[293/25][20/69] Loss_D: 0.0050 Loss_G: 8.5859\n",
            "[293/25][21/69] Loss_D: 0.0055 Loss_G: 7.9956\n",
            "[293/25][22/69] Loss_D: 0.0026 Loss_G: 8.6611\n",
            "[293/25][23/69] Loss_D: 0.0039 Loss_G: 8.6306\n",
            "[293/25][24/69] Loss_D: 0.0066 Loss_G: 8.3324\n",
            "[293/25][25/69] Loss_D: 0.0023 Loss_G: 8.9488\n",
            "[293/25][26/69] Loss_D: 0.0026 Loss_G: 8.5160\n",
            "[293/25][27/69] Loss_D: 0.0057 Loss_G: 8.1558\n",
            "[293/25][28/69] Loss_D: 0.0024 Loss_G: 8.4483\n",
            "[293/25][29/69] Loss_D: 0.0117 Loss_G: 7.4479\n",
            "[293/25][30/69] Loss_D: 0.0053 Loss_G: 7.2386\n",
            "[293/25][31/69] Loss_D: 0.0159 Loss_G: 7.4804\n",
            "[293/25][32/69] Loss_D: 0.0687 Loss_G: 5.5601\n",
            "[293/25][33/69] Loss_D: 0.0099 Loss_G: 5.3040\n",
            "[293/25][34/69] Loss_D: 0.0242 Loss_G: 4.9537\n",
            "[293/25][35/69] Loss_D: 0.0294 Loss_G: 5.3567\n",
            "[293/25][36/69] Loss_D: 0.0084 Loss_G: 6.6840\n",
            "[293/25][37/69] Loss_D: 0.0121 Loss_G: 6.7053\n",
            "[293/25][38/69] Loss_D: 0.0033 Loss_G: 7.9859\n",
            "[293/25][39/69] Loss_D: 0.0020 Loss_G: 8.7379\n",
            "[293/25][40/69] Loss_D: 0.0029 Loss_G: 8.7146\n",
            "[293/25][41/69] Loss_D: 0.0007 Loss_G: 10.1702\n",
            "[293/25][42/69] Loss_D: 0.0001 Loss_G: 11.0848\n",
            "[293/25][43/69] Loss_D: 0.1065 Loss_G: 9.5102\n",
            "[293/25][44/69] Loss_D: 0.0002 Loss_G: 9.9355\n",
            "[293/25][45/69] Loss_D: 0.0007 Loss_G: 8.3976\n",
            "[293/25][46/69] Loss_D: 0.0014 Loss_G: 8.1557\n",
            "[293/25][47/69] Loss_D: 0.0023 Loss_G: 7.9780\n",
            "[293/25][48/69] Loss_D: 0.0017 Loss_G: 7.7771\n",
            "[293/25][49/69] Loss_D: 0.0180 Loss_G: 6.3797\n",
            "[293/25][50/69] Loss_D: 0.0012 Loss_G: 8.0579\n",
            "[293/25][51/69] Loss_D: 0.0039 Loss_G: 7.4877\n",
            "[293/25][52/69] Loss_D: 0.0076 Loss_G: 6.4509\n",
            "[293/25][53/69] Loss_D: 0.0054 Loss_G: 7.1525\n",
            "[293/25][54/69] Loss_D: 0.0023 Loss_G: 7.5661\n",
            "[293/25][55/69] Loss_D: 0.0020 Loss_G: 7.7693\n",
            "[293/25][56/69] Loss_D: 0.0031 Loss_G: 7.5929\n",
            "[293/25][57/69] Loss_D: 0.0013 Loss_G: 8.4695\n",
            "[293/25][58/69] Loss_D: 0.0006 Loss_G: 8.7155\n",
            "[293/25][59/69] Loss_D: 0.0018 Loss_G: 7.6020\n",
            "[293/25][60/69] Loss_D: 0.0009 Loss_G: 8.1954\n",
            "[293/25][61/69] Loss_D: 0.0031 Loss_G: 7.0980\n",
            "[293/25][62/69] Loss_D: 0.0052 Loss_G: 6.4920\n",
            "[293/25][63/69] Loss_D: 0.0032 Loss_G: 7.1514\n",
            "[293/25][64/69] Loss_D: 0.0009 Loss_G: 8.4545\n",
            "[293/25][65/69] Loss_D: 0.0018 Loss_G: 7.7592\n",
            "[293/25][66/69] Loss_D: 0.0023 Loss_G: 7.8332\n",
            "[293/25][67/69] Loss_D: 0.0072 Loss_G: 6.8087\n",
            "[293/25][68/69] Loss_D: 0.0056 Loss_G: 7.0737\n",
            "[294/25][0/69] Loss_D: 0.0041 Loss_G: 8.1444\n",
            "[294/25][1/69] Loss_D: 0.0029 Loss_G: 8.0897\n",
            "[294/25][2/69] Loss_D: 0.0022 Loss_G: 9.8692\n",
            "[294/25][3/69] Loss_D: 0.0005 Loss_G: 8.7986\n",
            "[294/25][4/69] Loss_D: 0.0011 Loss_G: 8.0535\n",
            "[294/25][5/69] Loss_D: 0.0027 Loss_G: 7.4682\n",
            "[294/25][6/69] Loss_D: 0.0006 Loss_G: 8.6189\n",
            "[294/25][7/69] Loss_D: 0.0014 Loss_G: 7.5173\n",
            "[294/25][8/69] Loss_D: 0.0043 Loss_G: 6.8307\n",
            "[294/25][9/69] Loss_D: 0.0022 Loss_G: 7.3193\n",
            "[294/25][10/69] Loss_D: 0.0026 Loss_G: 8.4232\n",
            "[294/25][11/69] Loss_D: 0.0061 Loss_G: 6.0919\n",
            "[294/25][12/69] Loss_D: 0.0029 Loss_G: 7.7780\n",
            "[294/25][13/69] Loss_D: 0.0241 Loss_G: 8.3817\n",
            "[294/25][14/69] Loss_D: 0.0084 Loss_G: 6.0388\n",
            "[294/25][15/69] Loss_D: 0.0287 Loss_G: 5.4088\n",
            "[294/25][16/69] Loss_D: 0.0035 Loss_G: 6.6096\n",
            "[294/25][17/69] Loss_D: 0.0077 Loss_G: 6.2120\n",
            "[294/25][18/69] Loss_D: 0.0044 Loss_G: 6.9786\n",
            "[294/25][19/69] Loss_D: 0.0084 Loss_G: 7.2544\n",
            "[294/25][20/69] Loss_D: 0.0059 Loss_G: 6.5223\n",
            "[294/25][21/69] Loss_D: 0.0065 Loss_G: 6.9648\n",
            "[294/25][22/69] Loss_D: 0.0040 Loss_G: 6.9665\n",
            "[294/25][23/69] Loss_D: 0.0028 Loss_G: 7.2368\n",
            "[294/25][24/69] Loss_D: 0.0017 Loss_G: 7.5496\n",
            "[294/25][25/69] Loss_D: 0.0047 Loss_G: 6.8068\n",
            "[294/25][26/69] Loss_D: 0.0015 Loss_G: 8.2192\n",
            "[294/25][27/69] Loss_D: 0.0035 Loss_G: 7.8027\n",
            "[294/25][28/69] Loss_D: 0.0012 Loss_G: 8.3354\n",
            "[294/25][29/69] Loss_D: 0.0005 Loss_G: 8.8047\n",
            "[294/25][30/69] Loss_D: 0.0007 Loss_G: 8.4437\n",
            "[294/25][31/69] Loss_D: 0.0026 Loss_G: 8.8751\n",
            "[294/25][32/69] Loss_D: 0.0015 Loss_G: 7.7193\n",
            "[294/25][33/69] Loss_D: 0.0015 Loss_G: 7.3619\n",
            "[294/25][34/69] Loss_D: 0.0043 Loss_G: 7.6443\n",
            "[294/25][35/69] Loss_D: 0.0027 Loss_G: 7.2761\n",
            "[294/25][36/69] Loss_D: 0.0036 Loss_G: 6.5782\n",
            "[294/25][37/69] Loss_D: 0.0022 Loss_G: 7.3962\n",
            "[294/25][38/69] Loss_D: 0.0023 Loss_G: 7.1994\n",
            "[294/25][39/69] Loss_D: 0.0133 Loss_G: 7.2124\n",
            "[294/25][40/69] Loss_D: 0.0012 Loss_G: 7.5709\n",
            "[294/25][41/69] Loss_D: 0.0032 Loss_G: 6.5867\n",
            "[294/25][42/69] Loss_D: 0.0016 Loss_G: 7.5054\n",
            "[294/25][43/69] Loss_D: 0.0018 Loss_G: 7.8397\n",
            "[294/25][44/69] Loss_D: 0.0049 Loss_G: 6.1734\n",
            "[294/25][45/69] Loss_D: 0.0087 Loss_G: 6.3182\n",
            "[294/25][46/69] Loss_D: 0.0127 Loss_G: 6.1028\n",
            "[294/25][47/69] Loss_D: 0.0024 Loss_G: 7.5324\n",
            "[294/25][48/69] Loss_D: 0.0003 Loss_G: 9.4159\n",
            "[294/25][49/69] Loss_D: 0.0012 Loss_G: 8.1575\n",
            "[294/25][50/69] Loss_D: 0.0009 Loss_G: 9.1996\n",
            "[294/25][51/69] Loss_D: 0.0010 Loss_G: 7.9731\n",
            "[294/25][52/69] Loss_D: 0.0006 Loss_G: 9.8905\n",
            "[294/25][53/69] Loss_D: 0.0008 Loss_G: 8.5065\n",
            "[294/25][54/69] Loss_D: 0.0007 Loss_G: 9.1168\n",
            "[294/25][55/69] Loss_D: 0.0021 Loss_G: 8.2436\n",
            "[294/25][56/69] Loss_D: 0.0016 Loss_G: 7.3549\n",
            "[294/25][57/69] Loss_D: 0.0038 Loss_G: 8.6571\n",
            "[294/25][58/69] Loss_D: 0.0584 Loss_G: 7.5987\n",
            "[294/25][59/69] Loss_D: 0.0020 Loss_G: 6.2104\n",
            "[294/25][60/69] Loss_D: 0.0069 Loss_G: 5.2591\n",
            "[294/25][61/69] Loss_D: 0.0047 Loss_G: 5.9124\n",
            "[294/25][62/69] Loss_D: 0.0603 Loss_G: 5.1981\n",
            "[294/25][63/69] Loss_D: 0.0051 Loss_G: 7.6327\n",
            "[294/25][64/69] Loss_D: 0.0046 Loss_G: 8.1175\n",
            "[294/25][65/69] Loss_D: 0.0018 Loss_G: 9.0609\n",
            "[294/25][66/69] Loss_D: 0.0006 Loss_G: 10.7347\n",
            "[294/25][67/69] Loss_D: 0.0011 Loss_G: 10.3543\n",
            "[294/25][68/69] Loss_D: 0.0004 Loss_G: 11.5633\n",
            "[295/25][0/69] Loss_D: 0.0004 Loss_G: 11.7551\n",
            "[295/25][1/69] Loss_D: 0.0004 Loss_G: 11.9931\n",
            "[295/25][2/69] Loss_D: 0.3875 Loss_G: 9.9272\n",
            "[295/25][3/69] Loss_D: 0.0035 Loss_G: 8.0563\n",
            "[295/25][4/69] Loss_D: 0.0007 Loss_G: 7.0627\n",
            "[295/25][5/69] Loss_D: 0.0084 Loss_G: 4.7358\n",
            "[295/25][6/69] Loss_D: 0.0523 Loss_G: 5.6853\n",
            "[295/25][7/69] Loss_D: 0.0234 Loss_G: 5.9175\n",
            "[295/25][8/69] Loss_D: 0.0049 Loss_G: 7.0002\n",
            "[295/25][9/69] Loss_D: 0.0106 Loss_G: 6.3975\n",
            "[295/25][10/69] Loss_D: 0.0027 Loss_G: 7.8283\n",
            "[295/25][11/69] Loss_D: 0.0039 Loss_G: 7.5081\n",
            "[295/25][12/69] Loss_D: 0.0008 Loss_G: 9.2318\n",
            "[295/25][13/69] Loss_D: 0.0003 Loss_G: 10.3231\n",
            "[295/25][14/69] Loss_D: 0.0011 Loss_G: 8.9174\n",
            "[295/25][15/69] Loss_D: 0.0002 Loss_G: 10.3499\n",
            "[295/25][16/69] Loss_D: 0.0002 Loss_G: 10.7513\n",
            "[295/25][17/69] Loss_D: 0.0004 Loss_G: 10.1808\n",
            "[295/25][18/69] Loss_D: 0.0001 Loss_G: 11.1070\n",
            "[295/25][19/69] Loss_D: 0.0013 Loss_G: 10.1873\n",
            "[295/25][20/69] Loss_D: 0.0001 Loss_G: 11.0012\n",
            "[295/25][21/69] Loss_D: 0.0004 Loss_G: 9.4291\n",
            "[295/25][22/69] Loss_D: 0.0002 Loss_G: 10.9872\n",
            "[295/25][23/69] Loss_D: 0.0004 Loss_G: 9.5361\n",
            "[295/25][24/69] Loss_D: 0.0009 Loss_G: 8.8396\n",
            "[295/25][25/69] Loss_D: 0.0006 Loss_G: 9.3102\n",
            "[295/25][26/69] Loss_D: 0.0012 Loss_G: 8.3907\n",
            "[295/25][27/69] Loss_D: 0.0019 Loss_G: 8.3546\n",
            "[295/25][28/69] Loss_D: 0.0028 Loss_G: 8.1615\n",
            "[295/25][29/69] Loss_D: 0.0010 Loss_G: 8.0956\n",
            "[295/25][30/69] Loss_D: 0.0015 Loss_G: 8.8569\n",
            "[295/25][31/69] Loss_D: 0.0181 Loss_G: 7.8938\n",
            "[295/25][32/69] Loss_D: 0.0064 Loss_G: 7.4889\n",
            "[295/25][33/69] Loss_D: 0.0013 Loss_G: 9.4976\n",
            "[295/25][34/69] Loss_D: 0.0025 Loss_G: 7.9964\n",
            "[295/25][35/69] Loss_D: 0.0009 Loss_G: 9.3739\n",
            "[295/25][36/69] Loss_D: 0.0008 Loss_G: 8.7727\n",
            "[295/25][37/69] Loss_D: 0.0015 Loss_G: 9.8693\n",
            "[295/25][38/69] Loss_D: 0.0014 Loss_G: 9.5373\n",
            "[295/25][39/69] Loss_D: 0.0024 Loss_G: 7.9858\n",
            "[295/25][40/69] Loss_D: 0.0632 Loss_G: 9.3005\n",
            "[295/25][41/69] Loss_D: 0.0165 Loss_G: 6.2586\n",
            "[295/25][42/69] Loss_D: 0.0241 Loss_G: 6.7984\n",
            "[295/25][43/69] Loss_D: 0.0618 Loss_G: 7.1833\n",
            "[295/25][44/69] Loss_D: 0.0037 Loss_G: 8.1452\n",
            "[295/25][45/69] Loss_D: 0.0006 Loss_G: 10.9241\n",
            "[295/25][46/69] Loss_D: 0.0097 Loss_G: 9.5528\n",
            "[295/25][47/69] Loss_D: 0.0035 Loss_G: 11.0681\n",
            "[295/25][48/69] Loss_D: 0.0017 Loss_G: 11.7045\n",
            "[295/25][49/69] Loss_D: 0.0058 Loss_G: 12.2752\n",
            "[295/25][50/69] Loss_D: 0.0127 Loss_G: 13.2739\n",
            "[295/25][51/69] Loss_D: 0.0298 Loss_G: 12.3383\n",
            "[295/25][52/69] Loss_D: 0.0050 Loss_G: 11.9440\n",
            "[295/25][53/69] Loss_D: 0.0003 Loss_G: 12.2997\n",
            "[295/25][54/69] Loss_D: 0.0006 Loss_G: 13.8001\n",
            "[295/25][55/69] Loss_D: 0.0009 Loss_G: 12.2981\n",
            "[295/25][56/69] Loss_D: 0.0031 Loss_G: 11.8128\n",
            "[295/25][57/69] Loss_D: 0.0029 Loss_G: 12.3496\n",
            "[295/25][58/69] Loss_D: 0.0016 Loss_G: 11.4538\n",
            "[295/25][59/69] Loss_D: 0.0034 Loss_G: 11.9882\n",
            "[295/25][60/69] Loss_D: 0.0042 Loss_G: 10.0685\n",
            "[295/25][61/69] Loss_D: 0.0004 Loss_G: 11.2587\n",
            "[295/25][62/69] Loss_D: 0.0009 Loss_G: 10.4789\n",
            "[295/25][63/69] Loss_D: 0.0009 Loss_G: 8.9553\n",
            "[295/25][64/69] Loss_D: 0.0004 Loss_G: 10.3529\n",
            "[295/25][65/69] Loss_D: 0.0025 Loss_G: 9.0570\n",
            "[295/25][66/69] Loss_D: 0.0025 Loss_G: 9.2479\n",
            "[295/25][67/69] Loss_D: 0.0003 Loss_G: 10.2892\n",
            "[295/25][68/69] Loss_D: 0.0014 Loss_G: 12.9022\n",
            "[296/25][0/69] Loss_D: 0.0003 Loss_G: 9.7042\n",
            "[296/25][1/69] Loss_D: 0.0024 Loss_G: 7.0749\n",
            "[296/25][2/69] Loss_D: 0.0020 Loss_G: 7.7239\n",
            "[296/25][3/69] Loss_D: 0.0055 Loss_G: 7.5225\n",
            "[296/25][4/69] Loss_D: 0.0044 Loss_G: 7.5355\n",
            "[296/25][5/69] Loss_D: 0.0102 Loss_G: 8.2865\n",
            "[296/25][6/69] Loss_D: 0.0052 Loss_G: 7.3477\n",
            "[296/25][7/69] Loss_D: 0.0044 Loss_G: 8.7640\n",
            "[296/25][8/69] Loss_D: 0.0008 Loss_G: 8.8362\n",
            "[296/25][9/69] Loss_D: 0.0004 Loss_G: 9.1015\n",
            "[296/25][10/69] Loss_D: 0.0009 Loss_G: 9.3871\n",
            "[296/25][11/69] Loss_D: 0.0036 Loss_G: 9.3019\n",
            "[296/25][12/69] Loss_D: 0.0011 Loss_G: 8.7051\n",
            "[296/25][13/69] Loss_D: 0.0043 Loss_G: 9.3147\n",
            "[296/25][14/69] Loss_D: 0.0106 Loss_G: 9.7181\n",
            "[296/25][15/69] Loss_D: 0.0028 Loss_G: 9.4899\n",
            "[296/25][16/69] Loss_D: 0.0006 Loss_G: 9.4900\n",
            "[296/25][17/69] Loss_D: 0.0010 Loss_G: 8.5665\n",
            "[296/25][18/69] Loss_D: 0.0003 Loss_G: 9.9873\n",
            "[296/25][19/69] Loss_D: 0.0025 Loss_G: 7.7289\n",
            "[296/25][20/69] Loss_D: 0.1071 Loss_G: 6.5508\n",
            "[296/25][21/69] Loss_D: 0.0557 Loss_G: 5.3799\n",
            "[296/25][22/69] Loss_D: 0.0413 Loss_G: 6.4517\n",
            "[296/25][23/69] Loss_D: 0.0037 Loss_G: 7.6779\n",
            "[296/25][24/69] Loss_D: 0.0067 Loss_G: 6.8483\n",
            "[296/25][25/69] Loss_D: 0.0015 Loss_G: 8.9934\n",
            "[296/25][26/69] Loss_D: 0.0010 Loss_G: 9.2896\n",
            "[296/25][27/69] Loss_D: 0.0006 Loss_G: 10.4265\n",
            "[296/25][28/69] Loss_D: 0.0004 Loss_G: 10.8760\n",
            "[296/25][29/69] Loss_D: 0.0127 Loss_G: 9.2707\n",
            "[296/25][30/69] Loss_D: 0.0005 Loss_G: 10.8841\n",
            "[296/25][31/69] Loss_D: 0.0005 Loss_G: 11.5452\n",
            "[296/25][32/69] Loss_D: 0.0008 Loss_G: 11.0586\n",
            "[296/25][33/69] Loss_D: 0.0015 Loss_G: 10.5596\n",
            "[296/25][34/69] Loss_D: 0.0006 Loss_G: 10.4845\n",
            "[296/25][35/69] Loss_D: 0.0010 Loss_G: 10.9995\n",
            "[296/25][36/69] Loss_D: 0.0020 Loss_G: 10.0084\n",
            "[296/25][37/69] Loss_D: 0.0008 Loss_G: 11.4597\n",
            "[296/25][38/69] Loss_D: 0.0004 Loss_G: 10.8301\n",
            "[296/25][39/69] Loss_D: 0.0005 Loss_G: 10.6927\n",
            "[296/25][40/69] Loss_D: 0.0006 Loss_G: 10.9042\n",
            "[296/25][41/69] Loss_D: 0.0009 Loss_G: 10.3996\n",
            "[296/25][42/69] Loss_D: 0.0008 Loss_G: 9.5146\n",
            "[296/25][43/69] Loss_D: 0.0005 Loss_G: 10.8826\n",
            "[296/25][44/69] Loss_D: 0.0049 Loss_G: 9.5019\n",
            "[296/25][45/69] Loss_D: 0.0011 Loss_G: 8.8170\n",
            "[296/25][46/69] Loss_D: 0.0322 Loss_G: 8.5701\n",
            "[296/25][47/69] Loss_D: 0.0008 Loss_G: 8.6552\n",
            "[296/25][48/69] Loss_D: 0.0069 Loss_G: 7.7160\n",
            "[296/25][49/69] Loss_D: 0.0116 Loss_G: 9.2773\n",
            "[296/25][50/69] Loss_D: 0.0032 Loss_G: 8.6541\n",
            "[296/25][51/69] Loss_D: 0.0008 Loss_G: 9.9613\n",
            "[296/25][52/69] Loss_D: 0.0014 Loss_G: 9.2863\n",
            "[296/25][53/69] Loss_D: 0.0018 Loss_G: 9.1398\n",
            "[296/25][54/69] Loss_D: 0.0983 Loss_G: 8.1409\n",
            "[296/25][55/69] Loss_D: 0.0051 Loss_G: 6.5995\n",
            "[296/25][56/69] Loss_D: 0.0057 Loss_G: 7.8624\n",
            "[296/25][57/69] Loss_D: 0.0700 Loss_G: 7.2481\n",
            "[296/25][58/69] Loss_D: 0.0017 Loss_G: 9.2327\n",
            "[296/25][59/69] Loss_D: 0.0011 Loss_G: 9.6156\n",
            "[296/25][60/69] Loss_D: 0.0009 Loss_G: 10.8602\n",
            "[296/25][61/69] Loss_D: 0.0002 Loss_G: 13.2861\n",
            "[296/25][62/69] Loss_D: 0.0024 Loss_G: 12.9763\n",
            "[296/25][63/69] Loss_D: 0.0003 Loss_G: 11.9621\n",
            "[296/25][64/69] Loss_D: 0.0257 Loss_G: 12.3694\n",
            "[296/25][65/69] Loss_D: 0.0026 Loss_G: 11.4035\n",
            "[296/25][66/69] Loss_D: 0.0028 Loss_G: 12.5939\n",
            "[296/25][67/69] Loss_D: 0.0012 Loss_G: 10.8969\n",
            "[296/25][68/69] Loss_D: 0.0097 Loss_G: 13.0387\n",
            "[297/25][0/69] Loss_D: 0.0008 Loss_G: 11.9228\n",
            "[297/25][1/69] Loss_D: 0.0029 Loss_G: 10.7642\n",
            "[297/25][2/69] Loss_D: 0.0011 Loss_G: 12.2957\n",
            "[297/25][3/69] Loss_D: 0.0030 Loss_G: 9.3412\n",
            "[297/25][4/69] Loss_D: 0.0025 Loss_G: 9.7787\n",
            "[297/25][5/69] Loss_D: 0.0026 Loss_G: 9.8236\n",
            "[297/25][6/69] Loss_D: 0.0029 Loss_G: 9.6308\n",
            "[297/25][7/69] Loss_D: 0.0010 Loss_G: 9.6904\n",
            "[297/25][8/69] Loss_D: 0.0020 Loss_G: 9.1575\n",
            "[297/25][9/69] Loss_D: 0.0018 Loss_G: 9.2528\n",
            "[297/25][10/69] Loss_D: 0.0004 Loss_G: 10.9153\n",
            "[297/25][11/69] Loss_D: 0.0010 Loss_G: 9.3865\n",
            "[297/25][12/69] Loss_D: 0.0022 Loss_G: 8.4058\n",
            "[297/25][13/69] Loss_D: 0.0014 Loss_G: 9.5167\n",
            "[297/25][14/69] Loss_D: 0.0101 Loss_G: 9.1671\n",
            "[297/25][15/69] Loss_D: 0.0029 Loss_G: 7.9772\n",
            "[297/25][16/69] Loss_D: 0.0116 Loss_G: 7.4502\n",
            "[297/25][17/69] Loss_D: 0.0028 Loss_G: 7.2547\n",
            "[297/25][18/69] Loss_D: 0.0014 Loss_G: 7.7144\n",
            "[297/25][19/69] Loss_D: 0.0039 Loss_G: 6.8131\n",
            "[297/25][20/69] Loss_D: 0.0058 Loss_G: 7.0180\n",
            "[297/25][21/69] Loss_D: 0.0037 Loss_G: 7.1623\n",
            "[297/25][22/69] Loss_D: 0.0046 Loss_G: 6.8124\n",
            "[297/25][23/69] Loss_D: 0.0018 Loss_G: 7.3237\n",
            "[297/25][24/69] Loss_D: 0.0047 Loss_G: 7.1789\n",
            "[297/25][25/69] Loss_D: 0.0011 Loss_G: 7.6671\n",
            "[297/25][26/69] Loss_D: 0.0019 Loss_G: 7.3989\n",
            "[297/25][27/69] Loss_D: 0.0135 Loss_G: 7.5753\n",
            "[297/25][28/69] Loss_D: 0.0013 Loss_G: 8.0150\n",
            "[297/25][29/69] Loss_D: 0.0021 Loss_G: 7.6876\n",
            "[297/25][30/69] Loss_D: 0.0006 Loss_G: 8.2470\n",
            "[297/25][31/69] Loss_D: 0.0019 Loss_G: 7.3345\n",
            "[297/25][32/69] Loss_D: 0.0007 Loss_G: 8.5223\n",
            "[297/25][33/69] Loss_D: 0.0004 Loss_G: 9.0378\n",
            "[297/25][34/69] Loss_D: 0.0003 Loss_G: 10.3068\n",
            "[297/25][35/69] Loss_D: 0.0011 Loss_G: 7.7299\n",
            "[297/25][36/69] Loss_D: 0.0015 Loss_G: 7.4872\n",
            "[297/25][37/69] Loss_D: 0.0002 Loss_G: 9.6101\n",
            "[297/25][38/69] Loss_D: 0.0006 Loss_G: 8.2673\n",
            "[297/25][39/69] Loss_D: 0.0011 Loss_G: 7.7694\n",
            "[297/25][40/69] Loss_D: 0.0043 Loss_G: 8.6280\n",
            "[297/25][41/69] Loss_D: 0.0024 Loss_G: 7.5272\n",
            "[297/25][42/69] Loss_D: 0.0008 Loss_G: 8.6787\n",
            "[297/25][43/69] Loss_D: 0.0012 Loss_G: 7.7987\n",
            "[297/25][44/69] Loss_D: 0.0008 Loss_G: 8.0408\n",
            "[297/25][45/69] Loss_D: 0.0024 Loss_G: 6.7443\n",
            "[297/25][46/69] Loss_D: 0.0007 Loss_G: 10.2917\n",
            "[297/25][47/69] Loss_D: 0.0011 Loss_G: 7.7013\n",
            "[297/25][48/69] Loss_D: 0.0016 Loss_G: 7.6619\n",
            "[297/25][49/69] Loss_D: 0.0024 Loss_G: 7.1211\n",
            "[297/25][50/69] Loss_D: 0.0019 Loss_G: 8.9702\n",
            "[297/25][51/69] Loss_D: 0.0055 Loss_G: 7.5500\n",
            "[297/25][52/69] Loss_D: 0.0011 Loss_G: 7.6093\n",
            "[297/25][53/69] Loss_D: 0.0007 Loss_G: 8.3501\n",
            "[297/25][54/69] Loss_D: 0.0015 Loss_G: 7.4288\n",
            "[297/25][55/69] Loss_D: 0.0019 Loss_G: 7.0006\n",
            "[297/25][56/69] Loss_D: 0.0013 Loss_G: 7.4200\n",
            "[297/25][57/69] Loss_D: 0.0014 Loss_G: 8.1749\n",
            "[297/25][58/69] Loss_D: 0.0026 Loss_G: 7.7215\n",
            "[297/25][59/69] Loss_D: 0.0066 Loss_G: 6.6344\n",
            "[297/25][60/69] Loss_D: 0.0003 Loss_G: 8.8107\n",
            "[297/25][61/69] Loss_D: 0.0015 Loss_G: 7.1020\n",
            "[297/25][62/69] Loss_D: 0.0008 Loss_G: 8.1772\n",
            "[297/25][63/69] Loss_D: 0.0370 Loss_G: 5.9111\n",
            "[297/25][64/69] Loss_D: 0.0038 Loss_G: 5.8310\n",
            "[297/25][65/69] Loss_D: 0.0043 Loss_G: 5.9774\n",
            "[297/25][66/69] Loss_D: 0.0230 Loss_G: 5.1133\n",
            "[297/25][67/69] Loss_D: 0.0089 Loss_G: 6.1202\n",
            "[297/25][68/69] Loss_D: 0.0024 Loss_G: 8.1584\n",
            "[298/25][0/69] Loss_D: 0.0057 Loss_G: 6.0558\n",
            "[298/25][1/69] Loss_D: 0.0211 Loss_G: 5.6275\n",
            "[298/25][2/69] Loss_D: 0.0056 Loss_G: 7.0110\n",
            "[298/25][3/69] Loss_D: 0.0004 Loss_G: 9.2265\n",
            "[298/25][4/69] Loss_D: 0.0089 Loss_G: 8.1616\n",
            "[298/25][5/69] Loss_D: 0.0113 Loss_G: 9.2037\n",
            "[298/25][6/69] Loss_D: 0.0003 Loss_G: 10.1247\n",
            "[298/25][7/69] Loss_D: 0.0009 Loss_G: 10.9370\n",
            "[298/25][8/69] Loss_D: 0.0028 Loss_G: 10.7534\n",
            "[298/25][9/69] Loss_D: 0.0019 Loss_G: 9.9244\n",
            "[298/25][10/69] Loss_D: 0.0016 Loss_G: 9.1298\n",
            "[298/25][11/69] Loss_D: 0.0015 Loss_G: 10.6643\n",
            "[298/25][12/69] Loss_D: 0.0270 Loss_G: 8.7387\n",
            "[298/25][13/69] Loss_D: 0.0003 Loss_G: 11.0266\n",
            "[298/25][14/69] Loss_D: 0.0032 Loss_G: 8.3574\n",
            "[298/25][15/69] Loss_D: 0.0014 Loss_G: 9.1567\n",
            "[298/25][16/69] Loss_D: 0.0010 Loss_G: 9.4476\n",
            "[298/25][17/69] Loss_D: 0.0030 Loss_G: 7.8846\n",
            "[298/25][18/69] Loss_D: 0.0012 Loss_G: 8.7101\n",
            "[298/25][19/69] Loss_D: 0.0011 Loss_G: 8.5930\n",
            "[298/25][20/69] Loss_D: 0.0006 Loss_G: 9.0117\n",
            "[298/25][21/69] Loss_D: 0.0006 Loss_G: 8.6647\n",
            "[298/25][22/69] Loss_D: 0.0013 Loss_G: 8.3640\n",
            "[298/25][23/69] Loss_D: 0.0018 Loss_G: 7.8757\n",
            "[298/25][24/69] Loss_D: 0.0009 Loss_G: 8.7840\n",
            "[298/25][25/69] Loss_D: 0.0004 Loss_G: 9.6786\n",
            "[298/25][26/69] Loss_D: 0.0017 Loss_G: 8.3973\n",
            "[298/25][27/69] Loss_D: 0.0017 Loss_G: 8.2393\n",
            "[298/25][28/69] Loss_D: 0.0006 Loss_G: 9.3198\n",
            "[298/25][29/69] Loss_D: 0.0006 Loss_G: 8.8229\n",
            "[298/25][30/69] Loss_D: 0.0011 Loss_G: 8.3465\n",
            "[298/25][31/69] Loss_D: 0.0051 Loss_G: 8.1166\n",
            "[298/25][32/69] Loss_D: 0.0002 Loss_G: 9.9287\n",
            "[298/25][33/69] Loss_D: 0.0004 Loss_G: 8.8972\n",
            "[298/25][34/69] Loss_D: 0.0015 Loss_G: 8.0267\n",
            "[298/25][35/69] Loss_D: 0.0004 Loss_G: 9.5064\n",
            "[298/25][36/69] Loss_D: 0.0016 Loss_G: 8.0507\n",
            "[298/25][37/69] Loss_D: 0.0005 Loss_G: 8.7106\n",
            "[298/25][38/69] Loss_D: 0.0008 Loss_G: 8.7470\n",
            "[298/25][39/69] Loss_D: 0.0076 Loss_G: 8.1035\n",
            "[298/25][40/69] Loss_D: 0.0112 Loss_G: 7.2937\n",
            "[298/25][41/69] Loss_D: 0.0015 Loss_G: 6.9548\n",
            "[298/25][42/69] Loss_D: 0.0039 Loss_G: 7.0168\n",
            "[298/25][43/69] Loss_D: 0.0018 Loss_G: 7.8211\n",
            "[298/25][44/69] Loss_D: 0.0078 Loss_G: 6.9734\n",
            "[298/25][45/69] Loss_D: 0.0047 Loss_G: 7.7614\n",
            "[298/25][46/69] Loss_D: 0.0056 Loss_G: 7.6449\n",
            "[298/25][47/69] Loss_D: 0.0011 Loss_G: 7.8182\n",
            "[298/25][48/69] Loss_D: 0.0049 Loss_G: 7.2431\n",
            "[298/25][49/69] Loss_D: 0.0025 Loss_G: 7.0587\n",
            "[298/25][50/69] Loss_D: 0.0011 Loss_G: 8.5098\n",
            "[298/25][51/69] Loss_D: 0.0038 Loss_G: 7.7512\n",
            "[298/25][52/69] Loss_D: 0.0015 Loss_G: 7.8799\n",
            "[298/25][53/69] Loss_D: 0.0005 Loss_G: 8.2230\n",
            "[298/25][54/69] Loss_D: 0.0006 Loss_G: 8.4923\n",
            "[298/25][55/69] Loss_D: 0.0005 Loss_G: 9.2329\n",
            "[298/25][56/69] Loss_D: 0.0187 Loss_G: 7.8908\n",
            "[298/25][57/69] Loss_D: 0.3823 Loss_G: 3.1657\n",
            "[298/25][58/69] Loss_D: 0.2973 Loss_G: 3.9351\n",
            "[298/25][59/69] Loss_D: 0.0460 Loss_G: 6.5209\n",
            "[298/25][60/69] Loss_D: 0.0159 Loss_G: 8.5316\n",
            "[298/25][61/69] Loss_D: 0.0089 Loss_G: 10.2209\n",
            "[298/25][62/69] Loss_D: 0.0012 Loss_G: 12.6235\n",
            "[298/25][63/69] Loss_D: 0.0003 Loss_G: 14.1843\n",
            "[298/25][64/69] Loss_D: 0.0003 Loss_G: 14.8811\n",
            "[298/25][65/69] Loss_D: 0.0053 Loss_G: 15.4196\n",
            "[298/25][66/69] Loss_D: 0.1309 Loss_G: 14.8365\n",
            "[298/25][67/69] Loss_D: 0.0001 Loss_G: 16.3680\n",
            "[298/25][68/69] Loss_D: 0.3912 Loss_G: 13.7236\n",
            "[299/25][0/69] Loss_D: 0.0099 Loss_G: 11.8804\n",
            "[299/25][1/69] Loss_D: 0.0011 Loss_G: 10.7870\n",
            "[299/25][2/69] Loss_D: 0.0016 Loss_G: 8.5280\n",
            "[299/25][3/69] Loss_D: 0.0007 Loss_G: 7.8348\n",
            "[299/25][4/69] Loss_D: 0.0024 Loss_G: 7.5014\n",
            "[299/25][5/69] Loss_D: 0.0278 Loss_G: 6.9258\n",
            "[299/25][6/69] Loss_D: 0.1060 Loss_G: 8.6445\n",
            "[299/25][7/69] Loss_D: 0.0004 Loss_G: 11.2248\n",
            "[299/25][8/69] Loss_D: 0.0003 Loss_G: 11.4061\n",
            "[299/25][9/69] Loss_D: 0.0000 Loss_G: 14.4578\n",
            "[299/25][10/69] Loss_D: 0.0000 Loss_G: 15.6322\n",
            "[299/25][11/69] Loss_D: 0.0000 Loss_G: 15.5943\n",
            "[299/25][12/69] Loss_D: 0.0007 Loss_G: 15.0541\n",
            "[299/25][13/69] Loss_D: 0.0000 Loss_G: 18.3317\n",
            "[299/25][14/69] Loss_D: 0.0001 Loss_G: 16.8561\n",
            "[299/25][15/69] Loss_D: 0.0003 Loss_G: 17.4946\n",
            "[299/25][16/69] Loss_D: 0.0000 Loss_G: 18.0442\n",
            "[299/25][17/69] Loss_D: 0.0001 Loss_G: 17.4924\n",
            "[299/25][18/69] Loss_D: 0.0001 Loss_G: 18.6806\n",
            "[299/25][19/69] Loss_D: 0.0003 Loss_G: 17.8844\n",
            "[299/25][20/69] Loss_D: 0.0003 Loss_G: 18.8538\n",
            "[299/25][21/69] Loss_D: 0.0378 Loss_G: 16.4558\n",
            "[299/25][22/69] Loss_D: 0.0003 Loss_G: 15.5497\n",
            "[299/25][23/69] Loss_D: 0.0001 Loss_G: 14.5836\n",
            "[299/25][24/69] Loss_D: 0.0007 Loss_G: 14.5349\n",
            "[299/25][25/69] Loss_D: 0.0002 Loss_G: 13.4489\n",
            "[299/25][26/69] Loss_D: 0.0002 Loss_G: 14.0708\n",
            "[299/25][27/69] Loss_D: 0.0005 Loss_G: 11.7576\n",
            "[299/25][28/69] Loss_D: 0.0003 Loss_G: 11.1416\n",
            "[299/25][29/69] Loss_D: 0.0049 Loss_G: 10.5995\n",
            "[299/25][30/69] Loss_D: 0.0064 Loss_G: 9.4400\n",
            "[299/25][31/69] Loss_D: 0.0181 Loss_G: 9.6724\n",
            "[299/25][32/69] Loss_D: 0.0016 Loss_G: 11.2364\n",
            "[299/25][33/69] Loss_D: 0.0022 Loss_G: 12.4237\n",
            "[299/25][34/69] Loss_D: 0.0006 Loss_G: 12.9294\n",
            "[299/25][35/69] Loss_D: 0.0007 Loss_G: 11.1923\n",
            "[299/25][36/69] Loss_D: 0.0003 Loss_G: 11.9564\n",
            "[299/25][37/69] Loss_D: 0.0005 Loss_G: 10.7950\n",
            "[299/25][38/69] Loss_D: 0.0002 Loss_G: 11.0489\n",
            "[299/25][39/69] Loss_D: 0.0001 Loss_G: 11.3998\n",
            "[299/25][40/69] Loss_D: 0.0021 Loss_G: 13.1561\n",
            "[299/25][41/69] Loss_D: 0.0002 Loss_G: 11.1828\n",
            "[299/25][42/69] Loss_D: 0.0003 Loss_G: 10.6968\n",
            "[299/25][43/69] Loss_D: 0.0223 Loss_G: 9.2806\n",
            "[299/25][44/69] Loss_D: 0.0018 Loss_G: 9.3693\n",
            "[299/25][45/69] Loss_D: 0.0003 Loss_G: 8.9854\n",
            "[299/25][46/69] Loss_D: 0.0011 Loss_G: 7.9989\n",
            "[299/25][47/69] Loss_D: 0.0025 Loss_G: 7.6022\n",
            "[299/25][48/69] Loss_D: 0.0009 Loss_G: 8.8146\n",
            "[299/25][49/69] Loss_D: 0.0177 Loss_G: 6.7137\n",
            "[299/25][50/69] Loss_D: 0.0175 Loss_G: 7.7811\n",
            "[299/25][51/69] Loss_D: 0.0019 Loss_G: 8.3941\n",
            "[299/25][52/69] Loss_D: 0.0008 Loss_G: 9.1413\n",
            "[299/25][53/69] Loss_D: 0.0047 Loss_G: 8.8006\n",
            "[299/25][54/69] Loss_D: 0.0009 Loss_G: 9.1888\n",
            "[299/25][55/69] Loss_D: 0.0004 Loss_G: 9.5136\n",
            "[299/25][56/69] Loss_D: 0.0008 Loss_G: 9.2805\n",
            "[299/25][57/69] Loss_D: 0.1223 Loss_G: 9.5533\n",
            "[299/25][58/69] Loss_D: 0.0007 Loss_G: 9.0138\n",
            "[299/25][59/69] Loss_D: 0.0013 Loss_G: 7.5903\n",
            "[299/25][60/69] Loss_D: 0.0019 Loss_G: 7.4487\n",
            "[299/25][61/69] Loss_D: 0.0041 Loss_G: 6.5517\n",
            "[299/25][62/69] Loss_D: 0.0010 Loss_G: 7.5046\n",
            "[299/25][63/69] Loss_D: 0.0018 Loss_G: 7.7538\n",
            "[299/25][64/69] Loss_D: 0.0229 Loss_G: 6.2505\n",
            "[299/25][65/69] Loss_D: 0.0036 Loss_G: 7.4843\n",
            "[299/25][66/69] Loss_D: 0.0019 Loss_G: 7.6366\n",
            "[299/25][67/69] Loss_D: 0.0015 Loss_G: 7.8319\n",
            "[299/25][68/69] Loss_D: 0.0023 Loss_G: 7.8856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HPlZOdlvonn"
      },
      "source": [
        "noise = Variable(torch.randn((1, 100, 1, 1))).to(device)\n",
        "fake = generator(noise)\n",
        "vutils.save_image(fake.data, 'image.jpg', normalize = True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "28fFLZrnis_9",
        "outputId": "2f2a7c7f-775a-4c54-da1a-10a226de368a"
      },
      "source": [
        "discriminator_state_dict = torch.load(\"drive/MyDrive/SmokeGAN/discriminator\")\n",
        "discriminator.load_state_dict(discriminator_state_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2ebef2a225fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdiscriminator_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drive/MyDrive/SmokeGAN/discriminator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator_state_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# copy state_dict so _load_from_state_dict can modify it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_metadata'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'copy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0R-dXUYiv8j"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o09oOQGRFvs-"
      },
      "source": [
        "torch.save(discriminator.state_dict(), \"drive/MyDrive/SmokeGAN/discriminator2\")\n",
        "torch.save(generator.state_dict(), \"drive/MyDrive/SmokeGAN/generator2\")\n",
        "torch.save(optimizerDiscriminator.state_dict(), \"drive/MyDrive/SmokeGAN/optimDiscriminator2\")\n",
        "torch.save(optimizerGenerator.state_dict(), \"drive/MyDrive/SmokeGAN/optimGenerator2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "kvy4q3JSvivG",
        "outputId": "a37da829-0569-4c44-b200-123e8c60c525"
      },
      "source": [],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-30f86c2097bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0merrD_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Training the discriminator with a fake image generated by the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2517\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2518\u001b[0m         raise ValueError(\"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\n\u001b[0;32m-> 2519\u001b[0;31m                          \"Please ensure they have the same size.\".format(target.size(), input.size()))\n\u001b[0m\u001b[1;32m   2520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2521\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1, 9, 9])) is deprecated. Please ensure they have the same size."
          ]
        }
      ]
    }
  ]
}